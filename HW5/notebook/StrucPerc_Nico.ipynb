{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data_cap.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train_cap = data['input_matrix_train_cap']\n",
    "input_matrix_dev_cap = data['input_matrix_dev_cap']\n",
    "input_matrix_test_cap = data['input_matrix_test_cap']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train = data['input_matrix_train']\n",
    "input_matrix_train_embed = data['input_matrix_train_embed']\n",
    "input_matrix_dev = data['input_matrix_dev']\n",
    "input_matrix_dev_embed = data['input_matrix_dev_embed']\n",
    "input_matrix_test = data['input_matrix_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/sent_start.hdf5','r')\n",
    "data = myFile:all()\n",
    "sent = data['sent_start']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwords = input_matrix_train_cap:size(1)\n",
    "train_input = torch.Tensor(nwords-1,10)\n",
    "train_input:narrow(2,1,1):copy(input_matrix_train_cap:narrow(2,1,1):narrow(1,2,nwords-1))\n",
    "train_input:narrow(2,2,9):copy(input_matrix_train_cap:narrow(2,2,9):narrow(1,1,nwords-1))\n",
    "train_output = input_matrix_train_cap:narrow(2,16,1):narrow(1,2,nwords-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data/embeddings.hdf5','r')\n",
    "data2 = myFile:all()\n",
    "embeddings = data2['embeddings']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_logscore(observations, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C)\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        y:narrow(1,j,1):copy(model:forward({observations[i]:view(1,1),hot_1:view(1,9)}))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function viterbi(observations, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{8,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + compute_logscore(observations, 1, model, C)[8]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore(observations, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end\n",
    "\n",
    "function train_model(train_input, sent, train_output, observations_dev, model, din, nclass, eta, nEpochs)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- For the verbose print\n",
    "    observations = observations_dev:narrow(2,1,1):narrow(1,1,1000):clone()\n",
    "    true_classes = observations_dev:narrow(2,16,1):narrow(1,1,1000):squeeze()\n",
    "    \n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(100, din)\n",
    "    gold_sequence = torch.DoubleTensor(100)\n",
    "    high_score_seq = torch.DoubleTensor(100)\n",
    "    grad_pos = torch.zeros(9)\n",
    "    grad_neg = torch.zeros(9)\n",
    "    pr1 = torch.zeros(9)\n",
    "    pr2 = torch.zeros(9)\n",
    "    \n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 2, sent:size(1)-1 do\n",
    "            -- Mini batch data\n",
    "            sent_size = sent[{t,2}]\n",
    "--             print('here1')\n",
    "            \n",
    "            inputs_batch:narrow(1,1,sent_size+1):copy(train_input:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here2')\n",
    "            \n",
    "            gold_sequence:narrow(1,1,sent_size+1):copy(train_output:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass on a batch subsequence:\n",
    "            high_score_seq:narrow(1,1,sent_size+1):copy(viterbi(inputs_batch:narrow(1,1,sent_size+1):narrow(2,1,1), \n",
    "                                                                compute_logscore, model, nclass))\n",
    "--             print('here4')\n",
    "            \n",
    "            \n",
    "            for ii = 1, sent_size+1 do\n",
    "                grad_pos:zero()\n",
    "                if high_score_seq[ii] ~= gold_sequence[ii] then\n",
    "                    -- WARNING: Need to call backward right after the forward with the same input to compute correct gradients\n",
    "                    \n",
    "                    -- Use of a single gradient (grad_pos) with a penalization on the wrong class predicted (1)\n",
    "                    -- and a valorisation (-1) on the correct class to predict\n",
    "                    model:forward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)})\n",
    "                    grad_pos[gold_sequence[ii]] = -1\n",
    "                    grad_pos[high_score_seq[ii]] = 1\n",
    "                    model:backward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)}, grad_pos:view(1,9))\n",
    "                    \n",
    "                    \n",
    "                end\n",
    "            end\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        -- Print the f-score on a the first 1000 words to follow the improvement of the model\n",
    "        cl = viterbi(observations, compute_logscore, model, 9)\n",
    "        print (f_score(cl, true_classes))\n",
    "       \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 645\n",
       "   0\n",
       "   0\n",
       "   0\n",
       "   0\n",
       "   0\n",
       "   0\n",
       "   0\n",
       "   1\n",
       "   0\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs_batch = torch.DoubleTensor(100, 10)\n",
    "gold_sequence = torch.DoubleTensor(100)\n",
    "high_score_seq = torch.DoubleTensor(100)\n",
    "grad_pos = torch.zeros(9)\n",
    "grad_neg = torch.zeros(9)\n",
    "pr1 = torch.zeros(9)\n",
    "pr2 = torch.zeros(9)\n",
    "\n",
    "t = 4\n",
    "\n",
    "sent_size = sent[{t,2}]\n",
    "--             print('here1')\n",
    "\n",
    "inputs_batch:narrow(1,1,sent_size+1):copy(train_input:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here2')\n",
    "\n",
    "gold_sequence:narrow(1,1,sent_size+1):copy(train_output:narrow(1,sent[{t,1}]-1,sent_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_score(predicted_classes, true_classes)\n",
    "    local n = predicted_classes:size(1)\n",
    "    local right_pred = 0\n",
    "    local positive_true = 0\n",
    "    local positive_pred = 0\n",
    "    for i=1,n do\n",
    "        if predicted_classes[i] > 1 then\n",
    "            positive_pred = positive_pred + 1\n",
    "        end\n",
    "        if true_classes[i] > 1 then\n",
    "            positive_true = positive_true + 1\n",
    "        end\n",
    "        if (true_classes[i] == predicted_classes[i]) and true_classes[i] > 1 then\n",
    "            right_pred = right_pred + 1\n",
    "        end\n",
    "    end\n",
    "    print(positive_true)\n",
    "    print(positive_pred)\n",
    "    print(right_pred)\n",
    "    local precision = right_pred/positive_pred\n",
    "    local recall = right_pred/positive_true\n",
    "    return precision, recall\n",
    "end\n",
    "        \n",
    "function f_score(predicted_classes, true_classes)\n",
    "    local p,r = compute_score(predicted_classes, true_classes)\n",
    "    return 2*p*r/(p+r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LT = nn.LookupTable(400002,50)\n",
    "LT.weight:narrow(1, 1, 400000):copy(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "t1 = nn.ParallelTable()\n",
    "\n",
    "t1_1 = nn.Sequential()\n",
    "t1_1:add(LT)\n",
    "t1_1:add(nn.View(-1,50))\n",
    "\n",
    "t1_2 = nn.Identity()\n",
    "\n",
    "t1:add(t1_1)\n",
    "t1:add(t1_2)\n",
    "\n",
    "model:add(t1)\n",
    "model:add(nn.JoinTable(2))\n",
    "\n",
    "lin = nn.Linear(59,9)\n",
    "model:add(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 26\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 27 to 52\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 53 to 59\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 9x59]\n",
       "\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight:zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 286.32151603699\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "310\t\n",
       "275\t\n",
       "219\t\n",
       "0.74871794871795\t\n",
       "\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_input, sent, train_output, input_matrix_dev_cap, model, 10, 9, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 282.00321102142\t\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "310\t\n",
       "265\t\n",
       "209\t\n",
       "0.72695652173913\t\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 275.57887911797\t\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "310\t\n",
       "256\t\n",
       "201\t\n",
       "0.71024734982332\t\n",
       "\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_input, sent, train_output, input_matrix_dev_cap, model, 10, 9, 0.0001, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 300.87341284752\t\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "310\t\n",
       "262\t\n",
       "203\t\n",
       "0.70979020979021\t\n",
       "\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_input, sent, train_output, input_matrix_dev_cap, model, 10, 9, 0.0001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Testing the model\n",
    "\n",
    "sample_size = 1000\n",
    "observations = input_matrix_dev_cap:narrow(2,1,1):narrow(1,1,sample_size):clone()\n",
    "true_classes = input_matrix_dev_cap:narrow(2,16,1):narrow(1,1,sample_size):squeeze()\n",
    "cl = viterbi(observations, compute_logscore, model, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310\t\n",
       "235\t\n",
       "199\t\n",
       "0.7302752293578\t\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (f_score(cl, true_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_model(train_input, sent, train_output, model, 10, 9, 0.0001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 221.76510286331\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 207.53778505325\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 207.11648917198\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 206.85414910316\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 206.79605603218\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 206.66228604317\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 209.88998413086\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 208.36630487442\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 208.08896303177\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 208.07652997971\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 208.46472096443\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 208.36824584007\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 208.67321109772\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 208.48747014999\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 208.32903504372\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 208.4190120697\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 208.35225486755\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 208.25149393082\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 208.52996706963\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 208.72843790054\t\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_input, sent, train_output, model, 10, 9, 0.0001, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations_test = input_matrix_test:view(input_matrix_test:size(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_seq_test = viterbi(observations_test, compute_logscore, model, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving predicted sequence on test\n",
    "myFile = hdf5.open('../submission/v_seq_test_sp', 'w')\n",
    "myFile:write('v_seq_test', v_seq_test)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
