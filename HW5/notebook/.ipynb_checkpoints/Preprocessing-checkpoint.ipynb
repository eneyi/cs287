{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "import h5py\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-LOC': 3, '<\\t>': 9, 'I-PER': 2, '<t>': 8, 'O': 1, 'I-MISC': 5, 'B-MISC': 6, 'I-ORG': 4, 'B-LOC': 7}\n"
     ]
    }
   ],
   "source": [
    "# Tags mapping\n",
    "tag2index = {}\n",
    "\n",
    "with open('../data/tags.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line[:-1].split(' ')\n",
    "        tag2index[line_split[0]] = int(line_split[1])\n",
    "\n",
    "# Adding tags for end/start of sentence\n",
    "tag2index['<t>'] = 8\n",
    "tag2index['<\\t>'] = 9\n",
    "print(tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_elements(filename, tags=True):\n",
    "    # Counting the number of elements to stored (ie num_words + 2*num_sentences)\n",
    "    num_words = 0\n",
    "    num_sentences = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            # Case blank\n",
    "            if len(line_split) == 1:\n",
    "                num_sentences += 1\n",
    "            else:\n",
    "                num_words += 1\n",
    "\n",
    "    return num_words, num_sentences\n",
    "\n",
    "def get_cap_feature(word):\n",
    "    # Return the caps feature for the given word\n",
    "    # 1 - low caps; 2 - all caps; 3 - first cap; 4 - one cap; 5 - other\n",
    "    if len(word) == 0 or word.islower() or re.search('[.?\\-\",]+', word):\n",
    "        feature = 1\n",
    "    elif word.isupper():\n",
    "        feature = 2\n",
    "    elif len(word) and word[0].isupper():\n",
    "        feature = 3\n",
    "    elif sum([w.isupper() for w in word]):\n",
    "        feature = 4\n",
    "    else:\n",
    "        feature = 5\n",
    "    return feature\n",
    "    \n",
    "\n",
    "def build_input_matrix(filename ,num_rows, tag2index, tags=True, word2index=None):\n",
    "    # Building input matrix with columns: (id, id_in_sentence, id_word, id_caps, id_tag)\n",
    "    # caps feature:\n",
    "    # 1 - low caps; 2 - all caps; 3 - first cap; 4 - one cap; 5 - other\n",
    "    # Tags: if correct solution given (ie 4th column)\n",
    "    # word2index: if use of previously built word2index mapping\n",
    "    \n",
    "    # Features for starting/ending of sentence (3 last columns)\n",
    "    start = [1,1,8]\n",
    "    end = [2,1,9]\n",
    "    \n",
    "    # initialization\n",
    "    input_matrix = np.zeros((num_rows, 5), dtype=int)\n",
    "    input_matrix[0] = [1,1,1,1,8]\n",
    "    row = 1\n",
    "    \n",
    "    # Boolean to indicate if a sentence is starting\n",
    "    starting = False\n",
    "    # Boolean if a mapping is defined (last element of the mapping is for unknown words)\n",
    "    if word2index==None:\n",
    "        test = False\n",
    "        word2index = {'<s>': 1, '<\\s>': 2}\n",
    "        id_word = 3\n",
    "    else:\n",
    "        test = True\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            if starting == True:\n",
    "                # Start of sentence\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = 1\n",
    "                input_matrix[row, 2:] = start\n",
    "                row+=1\n",
    "                starting = False\n",
    "            if len(line_split) == 1:\n",
    "                # End of sentence\n",
    "                input_matrix[row, :2] = input_matrix[row-1, :2] + 1\n",
    "                input_matrix[row, 2:] = end\n",
    "                row+=1\n",
    "                starting = True\n",
    "            else:\n",
    "                # Indexing\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = int(line_split[1]) + 1\n",
    "                # Build cap feature\n",
    "                word = line_split[2]\n",
    "                input_matrix[row, 3] = get_cap_feature(word)\n",
    "                # Build word count feature\n",
    "                word_clean = word.lower()\n",
    "                if not test:\n",
    "                    if word_clean not in word2index:\n",
    "                        word2index[word_clean] = id_word\n",
    "                        id_word += 1\n",
    "                    input_matrix[row, 2] = word2index[word_clean]\n",
    "                else:\n",
    "                    # Unseen word during train\n",
    "                    if word_clean not in word2index:\n",
    "                        input_matrix[row, 2] = len(word2index)\n",
    "                    else:\n",
    "                        input_matrix[row, 2] = word2index[word_clean]\n",
    "                if tags:\n",
    "                    input_matrix[row, 4] = tag2index[line_split[3]]\n",
    "                row += 1\n",
    "    # Add special word if training\n",
    "    if not test:\n",
    "        word2index['<unk>'] = len(word2index)+1\n",
    "    if tags:\n",
    "        return input_matrix, word2index\n",
    "    else:\n",
    "        return input_matrix[:,:4], word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_hmm(input_matrix, num_features, num_tags):\n",
    "    # Emission word_count matrix:\n",
    "    # size (num_words, num_tags)\n",
    "    # row: observation / colum: tag\n",
    "    # (un-normalized if smoothing required)\n",
    "    emission_w = np.zeros((num_features, num_tags), dtype=int)\n",
    "        \n",
    "    # Emission word_count matrix:\n",
    "    # size (5, num_tags)\n",
    "    # row: observation / colum: tag\n",
    "    # (un-normalized if smoothing required)\n",
    "    emission_c = np.zeros((5, num_tags), dtype=int)\n",
    "    \n",
    "    # Building\n",
    "    for r in input_matrix:\n",
    "        emission_w[r[2]-1, r[4]-1] += 1\n",
    "        emission_c[r[3]-1, r[4]-1] += 1\n",
    "\n",
    "    # Transition matrix\n",
    "    # size (num_tags, num_tags)\n",
    "    # row: to / colum: from\n",
    "    # (un-normalized if smoothing required)\n",
    "    transition = np.zeros((num_tags, num_tags), dtype=int)\n",
    "    for i in xrange(input_matrix.shape[0] - 1):\n",
    "        transition[input_matrix[i+1,4]-1, input_matrix[i,4]-1] += 1\n",
    "        \n",
    "    return emission_w, emission_c, transition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "num_words, num_sentences = count_elements('../data/train.num.txt')\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_train, word2index = build_input_matrix('../data/train.num.txt', num_rows, tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the count matrix\n",
    "num_tags = len(tag2index)\n",
    "num_features = len(word2index)\n",
    "emission_w, emission_c, transition = train_hmm(input_matrix_train, num_features, num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    1,    1,    1],\n",
       "       [   2,    2, 9137,    3],\n",
       "       [   3,    3, 9137,    3],\n",
       "       [   4,    4,  638,    1],\n",
       "       [   5,    5, 9137,    1],\n",
       "       [   6,    6, 5750,    1],\n",
       "       [   7,    7, 5190,    1],\n",
       "       [   8,    8,   11,    1],\n",
       "       [   9,    9,    2,    1],\n",
       "       [  10,    1,    1,    1],\n",
       "       [  11,    2, 5748,    2],\n",
       "       [  12,    3, 9137,    1],\n",
       "       [  13,    4,    2,    1],\n",
       "       [  14,    1,    1,    1],\n",
       "       [  15,    2,  994,    3],\n",
       "       [  16,    3,  991,    1],\n",
       "       [  17,    4,    7,    1],\n",
       "       [  18,    5, 1587,    3],\n",
       "       [  19,    6, 1315,    5],\n",
       "       [  20,    7,   71,    1],\n",
       "       [  21,    8,  456,    5],\n",
       "       [  22,    9,    2,    1],\n",
       "       [  23,    1,    1,    1],\n",
       "       [  24,    2,  130,    5],\n",
       "       [  25,    3,  231,    1],\n",
       "       [  26,    4, 5751,    1],\n",
       "       [  27,    5,  161,    1],\n",
       "       [  28,    6, 5752,    1],\n",
       "       [  29,    7, 1666,    1],\n",
       "       [  30,    8, 5753,    1]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_test[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<\\t>': 9,\n",
       " '<t>': 8,\n",
       " 'B-LOC': 7,\n",
       " 'B-MISC': 6,\n",
       " 'I-LOC': 3,\n",
       " 'I-MISC': 5,\n",
       " 'I-ORG': 4,\n",
       " 'I-PER': 2,\n",
       " 'O': 1}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dev & test\n",
    "num_words, num_sentences = count_elements('../data/dev.num.txt')\n",
    "# Miss 1 blank line at the end of the file for the dev set\n",
    "num_rows = num_words + 2*num_sentences + 1\n",
    "input_matrix_dev, word2index = build_input_matrix('../data/dev.num.txt', num_rows, tag2index, word2index=word2index)\n",
    "\n",
    "num_words, num_sentences = count_elements('../data/test.num.txt', tags=False)\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_test, word2index = build_input_matrix('../data/test.num.txt', num_rows, tag2index, tags=False, word2index=word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(55961, 4)\n",
      "(29105, 4)\n",
      "(28677, 3)\n"
     ]
    }
   ],
   "source": [
    "# Should be 0, ie p(<\\t>|<t>)\n",
    "print transition[9-1, 8-1]\n",
    "print input_matrix_train.shape\n",
    "print input_matrix_dev.shape\n",
    "print input_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving pre-processing\n",
    "filename = '../data/words_caps_feature.hdf5'\n",
    "with h5py.File(filename, \"w\") as f:\n",
    "    # Model\n",
    "    f['emission_w'] = emission_w\n",
    "    f['emission_c'] = emission_c\n",
    "    f['transition'] = transition\n",
    "    \n",
    "    f['input_matrix_train'] = input_matrix_train\n",
    "    f['input_matrix_dev'] = input_matrix_dev\n",
    "    f['input_matrix_test'] = input_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transision to I-LOC\n",
      "[ 1654.     0.   271.     0.     2.     0.     0.   406.     0.]\n",
      "Transision to <\t>\n",
      "[ 3159.    84.    43.    27.    32.     0.     0.     0.     0.]\n",
      "Transision to I-PER\n",
      "[ 1379.  1309.     0.     4.    20.     0.     0.   351.     0.]\n",
      "Transision to <t>\n",
      "[    0.     0.     0.     0.     0.     0.     0.     0.  3344.]\n",
      "Transision to O\n",
      "[  3.28530000e+04   1.66900000e+03   2.00400000e+03   1.16000000e+03\n",
      "   8.49000000e+02   3.00000000e+00   1.00000000e+00   2.11100000e+03\n",
      "   0.00000000e+00]\n",
      "Transision to I-MISC\n",
      "[ 783.    1.   10.    3.  309.    5.    0.  120.    0.]\n",
      "Transision to B-MISC\n",
      "[ 0.  0.  0.  0.  8.  0.  0.  0.  0.]\n",
      "Transision to I-ORG\n",
      "[ 822.    0.    4.  791.   11.    0.    0.  357.    0.]\n",
      "Transision to B-LOC\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for k,v in tag2index.iteritems():\n",
    "    print 'Transision to '+k\n",
    "    print transition[v-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
