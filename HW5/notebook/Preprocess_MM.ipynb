{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as p\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "with open('../data/glove.6B.50d.txt') as f:\n",
    "    for l in f:\n",
    "        words.append(l.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_ind = dict(zip(words, [x+1 for x in range(len(words))]))\n",
    "word_ind['<s>'] = len(words) + 1\n",
    "word_ind['<\\s>'] = len(words) + 2\n",
    "ind_word = {}\n",
    "for k,v in word_ind.items():\n",
    "    ind_word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(words),50))\n",
    "i = 0\n",
    "with open('../data/glove.6B.50d.txt') as f:\n",
    "    for l in f:\n",
    "        emb = [float(c) for c in l.split()[1:]]\n",
    "        embeddings[i] = emb\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings_ = np.zeros((len(words)+2,50))\n",
    "embeddings_[:len(words),:] = embeddings\n",
    "embeddings_[400000,:] = embeddings[word_ind['.']] + np.random.normal(0,0.001,50)\n",
    "embeddings_[400001,:] = embeddings[word_ind['.']] + np.random.normal(0,0.001,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-LOC': 3, '<\\t>': 9, 'I-PER': 2, '<t>': 8, 'O': 1, 'I-MISC': 5, 'B-MISC': 6, 'I-ORG': 4, 'B-LOC': 7}\n"
     ]
    }
   ],
   "source": [
    "# Tags mapping\n",
    "tag2index = {}\n",
    "\n",
    "with open('../data/tags.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line_split = line[:-1].split(' ')\n",
    "        tag2index[line_split[0]] = int(line_split[1])\n",
    "\n",
    "# Adding tags for end/start of sentence\n",
    "tag2index['<t>'] = 8\n",
    "tag2index['<\\t>'] = 9\n",
    "print(tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70808726,  0.570312  , -0.4699188 ,  0.17873327,  0.54282193,\n",
       "        0.72641014,  0.18071378, -0.52278846,  0.10434391, -0.17651015,\n",
       "        0.07872373, -0.36301821, -0.11876748, -0.83267948,  0.11833908,\n",
       "       -0.16743652,  0.06052769, -0.01320265, -0.56591652,  0.01239596,\n",
       "        0.2286612 , -0.14386772, -0.06802176, -0.38141981, -0.23626355,\n",
       "       -1.70160089, -0.86701506, -0.26599092, -0.25720381,  0.17526465,\n",
       "        3.86777287, -0.16281838, -0.13381515, -0.6882982 ,  0.18437706,\n",
       "        0.00619479, -0.33774413, -0.07871775,  0.24368503,  0.36629811,\n",
       "       -0.34840807,  0.28469391,  0.07581127, -0.060944  , -0.39140224,\n",
       "        0.22796707, -0.21601652, -0.22596162, -0.09260529, -0.80184728])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_[word_ind['<\\s>']-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_elements(filename, tags=True):\n",
    "    # Counting the number of elements to stored (ie num_words + 2*num_sentences)\n",
    "    num_words = 0\n",
    "    num_sentences = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            # Case blank\n",
    "            if len(line_split) == 1:\n",
    "                num_sentences += 1\n",
    "            else:\n",
    "                num_words += 1\n",
    "\n",
    "    return num_words, num_sentences\n",
    "\n",
    "def build_input_matrix(filename ,num_rows, tag2index, tags=True, word2index=None):\n",
    "    # Building input matrix with columns: (id, id_in_sentence, id_word, id_tag)\n",
    "    # Tags: if correct solution given (ie 4th column)\n",
    "    # word2index: if use of previously built word2index mapping\n",
    "    input_matrix = np.zeros((num_rows, 4), dtype=int)\n",
    "    input_matrix[0] = [1,1,word2index['<s>'],1,8]\n",
    "    row = 1\n",
    "    \n",
    "    start = [word2index['<s>'],8]\n",
    "    end = [word2index['</s>'],9]\n",
    "    \n",
    "    # Boolean to indicate if a sentence is starting\n",
    "    starting = False\n",
    "    # Boolean if a mapping is defined (last element of the mapping is for unknown words)\n",
    "    if word2index==None:\n",
    "        test = False\n",
    "        word2index = {'<s>': 1, '<\\s>': 2}\n",
    "        id_word = 3\n",
    "    else:\n",
    "        test = True\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            if starting == True:\n",
    "                # Start of sentence\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = 1\n",
    "                input_matrix[row, 2:] = start\n",
    "                row+=1\n",
    "                starting = False\n",
    "            if len(line_split) == 1:\n",
    "                # End of sentence\n",
    "                input_matrix[row, :2] = input_matrix[row-1, :2] + 1\n",
    "                input_matrix[row, 2:] = end\n",
    "                row+=1\n",
    "                starting = True\n",
    "            else:\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = int(line_split[1]) + 1\n",
    "                # Build cap feature\n",
    "                word = line_split[2]\n",
    "                input_matrix[row, 3] = get_cap_feature(word)\n",
    "                word_clean = line_split[2].lower()\n",
    "                if not test:\n",
    "                    if word_clean not in word2index:\n",
    "                        word2index[word_clean] = id_word\n",
    "                        id_word += 1\n",
    "                    input_matrix[row, 2] = word2index[word_clean]\n",
    "                else:\n",
    "                    # Unseen word during train\n",
    "                    if word_clean not in word2index:\n",
    "                        input_matrix[row, 2] = len(word2index)\n",
    "                    else:\n",
    "                        input_matrix[row, 2] = word2index[word_clean]\n",
    "                if tags:\n",
    "                    input_matrix[row, 3] = tag2index[line_split[3]]\n",
    "                row += 1\n",
    "    # Add special word if training\n",
    "    if not test:\n",
    "        word2index['<unk>'] = len(word2index)+1\n",
    "    if tags:\n",
    "        return input_matrix, word2index\n",
    "    else:\n",
    "        return input_matrix[:,:3], word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_mm(matrix):\n",
    "    \n",
    "    nwords = matrix.shape[0]\n",
    "    \n",
    "    res = np.zeros((nwords,10),dtype = int)\n",
    "    \n",
    "    res[:,0] = matrix[:,2]\n",
    "    \n",
    "    for i in range(nwords):\n",
    "        tag_1_hot = np.zeros(9)\n",
    "        tag_1_hot[matrix[i,3]-1] = 1\n",
    "        res[i,1:] = tag_1_hot\n",
    "    \n",
    "    return res\n",
    "\n",
    "def input_mm_embed(matrix, embed):\n",
    "    \n",
    "    nwords = matrix.shape[0]\n",
    "    \n",
    "    res = np.zeros((nwords,50+9+1))\n",
    "    \n",
    "    res[:,0] = matrix[:,2]\n",
    "    \n",
    "    for i in range(nwords):\n",
    "        res[i,:50] = embed[matrix[i,2]-1,:]\n",
    "        tag_1_hot = np.zeros(9)\n",
    "        tag_1_hot[matrix[i,3]-1] = 1\n",
    "        res[i,50:59] = tag_1_hot\n",
    "    \n",
    "    res[:,59] = matrix[:,3]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_words, num_sentences = count_elements('../data/train.num.txt')\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_train, word2index = build_input_matrix('../data/train.num.txt', num_rows, tag2index, word2index = word_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_matrix_train_ = input_mm(input_matrix_train)\n",
    "input_matrix_train_embed = input_mm_embed(input_matrix_train, embeddings_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([400001,      0,      0,      0,      0,      0,      0,      0,\n",
       "            1,      0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dev & test\n",
    "num_words, num_sentences = count_elements('../data/dev.num.txt')\n",
    "# Miss 1 blank line at the end of the file for the dev set\n",
    "num_rows = num_words + 2*num_sentences + 1\n",
    "input_matrix_dev, word2index = build_input_matrix('../data/dev.num.txt', num_rows, tag2index, word2index = word_ind)\n",
    "\n",
    "num_words, num_sentences = count_elements('../data/test.num.txt', tags=False)\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_test, word2index = build_input_matrix('../data/test.num.txt', num_rows, tag2index, tags=False, word2index = word_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_matrix_dev_ = input_mm(input_matrix_dev)\n",
    "input_matrix_dev_embed = input_mm_embed(input_matrix_dev, embeddings_)\n",
    "input_matrix_test_ = input_matrix_test[:,2]\n",
    "input_matrix_test_embed = np.zeros((input_matrix_test_.shape[0],50))\n",
    "for i in range(input_matrix_test_.shape[0]):\n",
    "    input_matrix_test_embed[i,:] = embeddings_[input_matrix_test_[i]-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29104, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_dev_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving pre-processing\n",
    "filename = '../data/MM_data.hdf5'\n",
    "with p.File(filename, \"w\") as f:\n",
    "    # Model\n",
    "    f['input_matrix_train'] = input_matrix_train_\n",
    "    f['input_matrix_train_embed'] = input_matrix_train_embed\n",
    "    f['input_matrix_dev'] = input_matrix_dev_\n",
    "    f['input_matrix_dev_embed'] = input_matrix_dev_embed\n",
    "    f['input_matrix_test'] = input_matrix_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving pre-processing\n",
    "filename = '../data/embeddings.hdf5'\n",
    "with p.File(filename, \"w\") as f:\n",
    "    # Model\n",
    "    f['embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400001,      0,      0,      0,      0,      0,      0,      0,\n",
       "             1,      0],\n",
       "       [   645,      0,      0,      0,      1,      0,      0,      0,\n",
       "             0,      0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train_[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess with caps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_elements(filename, tags=True):\n",
    "    # Counting the number of elements to stored (ie num_words + 2*num_sentences)\n",
    "    num_words = 0\n",
    "    num_sentences = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            # Case blank\n",
    "            if len(line_split) == 1:\n",
    "                num_sentences += 1\n",
    "            else:\n",
    "                num_words += 1\n",
    "\n",
    "    return num_words, num_sentences\n",
    "\n",
    "def get_cap_feature(word):\n",
    "    # Return the caps feature for the given word\n",
    "    # 1 - low caps; 2 - all caps; 3 - first cap; 4 - one cap; 5 - other\n",
    "    if len(word) == 0 or word.islower() or re.search('[.?\\-\",]+', word):\n",
    "        feature = 1\n",
    "    elif word.isupper():\n",
    "        feature = 2\n",
    "    elif len(word) and word[0].isupper():\n",
    "        feature = 3\n",
    "    elif sum([w.isupper() for w in word]):\n",
    "        feature = 4\n",
    "    else:\n",
    "        feature = 5\n",
    "    return feature\n",
    "    \n",
    "\n",
    "def build_input_matrix_cap(filename ,num_rows, tag2index, tags=True, word2index=None):\n",
    "    # Building input matrix with columns: (id, id_in_sentence, id_word, id_caps, id_tag)\n",
    "    # caps feature:\n",
    "    # 1 - low caps; 2 - all caps; 3 - first cap; 4 - one cap; 5 - other\n",
    "    # Tags: if correct solution given (ie 4th column)\n",
    "    # word2index: if use of previously built word2index mapping\n",
    "        \n",
    "    # initialization\n",
    "    input_matrix = np.zeros((num_rows, 5), dtype=int)\n",
    "    input_matrix[0] = [1,1,word2index['<s>'],1,8]\n",
    "    row = 1\n",
    "    \n",
    "    # Features for starting/ending of sentence (3 last columns)\n",
    "    start = [word2index['<s>'],1,8]\n",
    "    end = [word2index['<\\s>'],1,9]\n",
    "    \n",
    "    # Boolean to indicate if a sentence is starting\n",
    "    starting = False\n",
    "    # Boolean if a mapping is defined (last element of the mapping is for unknown words)\n",
    "    if word2index==None:\n",
    "        test = False\n",
    "        word2index = {'<s>': 1, '<\\s>': 2}\n",
    "        id_word = 3\n",
    "    else:\n",
    "        test = True\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if tags:\n",
    "                line_split = line[:-1].split('\\t')\n",
    "            else:\n",
    "                line_split = line[:-1].split(' ')\n",
    "            if starting == True:\n",
    "                # Start of sentence\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = 1\n",
    "                input_matrix[row, 2:] = start\n",
    "                row+=1\n",
    "                starting = False\n",
    "            if len(line_split) == 1:\n",
    "                # End of sentence\n",
    "                input_matrix[row, :2] = input_matrix[row-1, :2] + 1\n",
    "                input_matrix[row, 2:] = end\n",
    "                row+=1\n",
    "                starting = True\n",
    "            else:\n",
    "                # Indexing\n",
    "                input_matrix[row, 0] = input_matrix[row-1, 0] + 1\n",
    "                input_matrix[row, 1] = int(line_split[1]) + 1\n",
    "                # Build cap feature\n",
    "                word = line_split[2]\n",
    "                input_matrix[row, 3] = get_cap_feature(word)\n",
    "                # Build word count feature\n",
    "                word_clean = word.lower()\n",
    "                if not test:\n",
    "                    if word_clean not in word2index:\n",
    "                        word2index[word_clean] = id_word\n",
    "                        id_word += 1\n",
    "                    input_matrix[row, 2] = word2index[word_clean]\n",
    "                else:\n",
    "                    # Unseen word during train\n",
    "                    if word_clean not in word2index:\n",
    "                        input_matrix[row, 2] = len(word2index)\n",
    "                    else:\n",
    "                        input_matrix[row, 2] = word2index[word_clean]\n",
    "                if tags:\n",
    "                    input_matrix[row, 4] = tag2index[line_split[3]]\n",
    "                row += 1\n",
    "    # Add special word if training\n",
    "    if not test:\n",
    "        word2index['<unk>'] = len(word2index)+1\n",
    "    if tags:\n",
    "        return input_matrix, word2index\n",
    "    else:\n",
    "        return input_matrix[:,:4], word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tttt = np.array([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tttt[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_mm_cap(matrix):\n",
    "    \n",
    "    nwords = matrix.shape[0]\n",
    "    \n",
    "    res = np.zeros((nwords,16),dtype = int)\n",
    "    \n",
    "    res[:,0] = matrix[:,2]\n",
    "    \n",
    "    for i in range(nwords):\n",
    "        tag_1_hot = np.zeros(9)\n",
    "        tag_1_hot[matrix[i,4]-1] = 1\n",
    "        tag_1_hot_cap = np.zeros(5)\n",
    "        tag_1_hot_cap[matrix[i,3]-1] = 1\n",
    "        res[i,1:10] = tag_1_hot\n",
    "        res[i,10:15] = tag_1_hot_cap\n",
    "    res[:,15] = matrix[:,4]\n",
    "    return res\n",
    "\n",
    "def input_mm_embed_cap(matrix, embed):\n",
    "    \n",
    "    nwords = matrix.shape[0]\n",
    "    \n",
    "    res = np.zeros((nwords,50+9+1))\n",
    "    \n",
    "    res[:,0] = matrix[:,2]\n",
    "    \n",
    "    for i in range(nwords):\n",
    "        res[i,:50] = embed[matrix[i,2]-1,:]\n",
    "        tag_1_hot = np.zeros(9)\n",
    "        tag_1_hot[matrix[i,3]-1] = 1\n",
    "        res[i,50:59] = tag_1_hot\n",
    "    \n",
    "    res[:,59] = matrix[:,3]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_words, num_sentences = count_elements('../data/train.num.txt')\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_train_cap_, word2index = build_input_matrix_cap('../data/train.num.txt', num_rows, tag2index, word2index = word_ind)\n",
    "input_matrix_train_cap = input_mm_cap(input_matrix_train_cap_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dev & test\n",
    "num_words, num_sentences = count_elements('../data/dev.num.txt')\n",
    "# Miss 1 blank line at the end of the file for the dev set\n",
    "num_rows = num_words + 2*num_sentences + 1\n",
    "input_matrix_dev_cap_, word2index = build_input_matrix_cap('../data/dev.num.txt', num_rows, tag2index, word2index = word_ind)\n",
    "\n",
    "num_words, num_sentences = count_elements('../data/test.num.txt', tags=False)\n",
    "num_rows = num_words + 2*num_sentences\n",
    "input_matrix_test_cap_, word2index = build_input_matrix_cap('../data/test.num.txt', num_rows, tag2index, tags=False, word2index = word_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_matrix_dev_cap = input_mm_cap(input_matrix_dev_cap_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400001,      0,      0,      0,      0,      0,      0,      0,\n",
       "             1,      0,      1,      0,      0,      0,      0,      8],\n",
       "       [   645,      0,      0,      0,      1,      0,      0,      0,\n",
       "             0,      0,      0,      1,      0,      0,      0,      4],\n",
       "       [  7579,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1],\n",
       "       [   515,      0,      0,      0,      0,      1,      0,      0,\n",
       "             0,      0,      0,      0,      1,      0,      0,      5],\n",
       "       [   581,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1],\n",
       "       [     5,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1],\n",
       "       [  5261,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1],\n",
       "       [   298,      0,      0,      0,      0,      1,      0,      0,\n",
       "             0,      0,      0,      0,      1,      0,      0,      5],\n",
       "       [ 10239,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1],\n",
       "       [     3,      1,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      1,      0,      0,      0,      0,      1]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train_cap[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_matrix_test_cap = np.zeros((input_matrix_test_cap_.shape[0],6))\n",
    "input_matrix_test_cap[:,0] = input_matrix_test_cap_[:,2]\n",
    "for i in range(input_matrix_test_cap_.shape[0]):\n",
    "    tag_1_hot_cap = np.zeros(5)\n",
    "    tag_1_hot_cap[input_matrix_test_cap_[i,3]-1] = 1\n",
    "    input_matrix_test_cap[i,1:] = tag_1_hot_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saving pre-processing\n",
    "filename = '../data/MM_data_cap.hdf5'\n",
    "with p.File(filename, \"w\") as f:\n",
    "    # Model\n",
    "    f['input_matrix_train_cap'] = input_matrix_train_cap\n",
    "    f['input_matrix_dev_cap'] = input_matrix_dev_cap\n",
    "    f['input_matrix_test_cap'] = input_matrix_test_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentences(matrix):\n",
    "    res = []\n",
    "    start  = 1\n",
    "    length = 2\n",
    "    \n",
    "    for i in range(1,len(matrix)):\n",
    "        if matrix[i,1] == 1:\n",
    "            res.append([start,length-1])\n",
    "            start = matrix[i,0]\n",
    "            length = 1\n",
    "        if i == (len(matrix) - 1):\n",
    "            res.append([start,length])\n",
    "        length += 1\n",
    "    \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = sentences(input_matrix_train_cap_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving pre-processing\n",
    "filename = '../data/sent_start.hdf5'\n",
    "with p.File(filename, \"w\") as f:\n",
    "    # Model\n",
    "    f['sent_start'] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 11],\n",
       "       [12,  4],\n",
       "       [16,  4],\n",
       "       [20, 32],\n",
       "       [52, 33]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,      1, 400001,      1,      8],\n",
       "       [     2,      2,    645,      2,      4],\n",
       "       [     3,      3,   7579,      1,      1],\n",
       "       [     4,      4,    515,      3,      5],\n",
       "       [     5,      5,    581,      1,      1],\n",
       "       [     6,      6,      5,      1,      1],\n",
       "       [     7,      7,   5261,      1,      1],\n",
       "       [     8,      8,    298,      3,      5],\n",
       "       [     9,      9,  10239,      1,      1],\n",
       "       [    10,     10,      3,      1,      1],\n",
       "       [    11,     11, 400002,      1,      9],\n",
       "       [    12,      1, 400001,      1,      8],\n",
       "       [    13,      2,   1295,      3,      2],\n",
       "       [    14,      3,   9004,      3,      2],\n",
       "       [    15,      4, 400002,      1,      9],\n",
       "       [    16,      1, 400001,      1,      8],\n",
       "       [    17,      2,   3880,      2,      3],\n",
       "       [    18,      3, 400002,      1,      1],\n",
       "       [    19,      4, 400002,      1,      9],\n",
       "       [    20,      1, 400001,      1,      8]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train_cap_[:20,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
