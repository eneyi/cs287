{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train = data['input_matrix_train']\n",
    "input_matrix_train_embed = data['input_matrix_train_embed']\n",
    "input_matrix_dev = data['input_matrix_dev']\n",
    "input_matrix_dev_embed = data['input_matrix_dev_embed']\n",
    "input_matrix_test = data['input_matrix_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data/embeddings.hdf5','r')\n",
    "data2 = myFile:all()\n",
    "embeddings = data2['embeddings']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_output = input_matrix_train_embed:narrow(2,60,1)\n",
    "nwords = train_output:size(1)\n",
    "train_output = train_output:narrow(1,2,nwords-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = torch.Tensor(nwords-1,10)\n",
    "train_input:narrow(2,1,1):copy(input_matrix_train:narrow(2,1,1):narrow(1,2,nwords-1))\n",
    "train_input:narrow(2,2,9):copy(input_matrix_train:narrow(2,2,9):narrow(1,1,nwords-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 400001       0       0       0       0       0       0       0       1       0\n",
       "    645       0       0       0       1       0       0       0       0       0\n",
       "   7579       1       0       0       0       0       0       0       0       0\n",
       "    515       0       0       0       0       1       0       0       0       0\n",
       "    581       1       0       0       0       0       0       0       0       0\n",
       "[torch.LongTensor of size 5x10]\n",
       "\n"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train:narrow(1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 1\n",
       " 5\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 5x1]\n",
       "\n"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output:narrow(1,1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear = nn.Sequential()\n",
    "linear:add(nn.Linear(59,9))\n",
    "linear:add(nn.SoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 0.60036301612854\t\n",
       "Average Loss: -0.66707073234158\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 0.59119391441345\t\n",
       "Average Loss: -0.71237675728118\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 0.59684014320374\t\n",
       "Average Loss: -0.72320236849443\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 0.590656042099\t"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Average Loss: -0.73588772172317\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 0.56508302688599\t\n",
       "Average Loss: -0.74539773380658\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 0.67143487930298\t\n",
       "Average Loss: -0.74993896083398\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 0.61443495750427\t\n",
       "Average Loss: -0.75263520138745\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 0.6673469543457\t\n",
       "Average Loss: -0.7544792526886\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 0.71698307991028\t\n",
       "Average Loss: -0.75584355786741\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 0.6067168712616\t\n",
       "Average Loss: -0.75691302943844\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 0.59539985656738\t\n",
       "Average Loss: -0.7577874990524\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 0.59084010124207\t\n",
       "Average Loss: -0.7585249515219\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 0.71736478805542\t\n",
       "Average Loss: -0.75916124762465\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 0.60998511314392\t\n",
       "Average Loss: -0.75971934961499\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 0.62633204460144\t\n",
       "Average Loss: -0.76021487546977\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 0.70232391357422\t\n",
       "Average Loss: -0.76065918617728\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 0.64208316802979\t\n",
       "Average Loss: -0.76106153387546\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 0.73686122894287\t\n",
       "Average Loss: -0.76142982197363\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 0.56427597999573\t\n",
       "Average Loss: -0.7617710446001\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 0.59289908409119\t\n",
       "Average Loss: -0.76209164453552\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_input, train_output, linear, criterion, 59, 9, 0.01, 20, 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model(train_input, train_output, model, criterion, din, nclass, eta, nEpochs, batchSize)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    loss = torch.Tensor(nEpochs)\n",
    "\n",
    "    -- To store the loss\n",
    "    av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(batchSize, din)\n",
    "    targets_batch = torch.DoubleTensor(batchSize)\n",
    "    outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "--             print('here1')\n",
    "            \n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "--             print('here2')\n",
    "            \n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(model:forward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1),\n",
    "                                                                        inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,9)}))\n",
    "--             print('here4')\n",
    "            -- Average loss computation\n",
    "            f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            \n",
    "--             print('here5')\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "--             print('here6')\n",
    "            model:backward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1), inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,9)}, \n",
    "                            df_do:narrow(1,1,current_batch_size))\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        loss[i] = av_L/math.floor(train_input:size(1)/batchSize)\n",
    "        print('Average Loss: '.. loss[i])\n",
    "       \n",
    "    end\n",
    "    \n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LT = nn.LookupTable(400002,embed_dim)\n",
    "LT.weight:narrow(1, 1, 400000):copy(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ultimate_t = nn.Sequential()\n",
    "t1 = nn.ParallelTable()\n",
    "\n",
    "t1_1 = nn.Sequential()\n",
    "t1_1:add(LT)\n",
    "t1_1:add(nn.View(-1,50))\n",
    "\n",
    "t1_2 = nn.Identity()\n",
    "\n",
    "t1:add(t1_1)\n",
    "t1:add(t1_2)\n",
    "\n",
    "ultimate_t:add(t1)\n",
    "ultimate_t:add(nn.JoinTable(2))\n",
    "\n",
    "ultimate_t:add(nn.Linear(59,9))\n",
    "ultimate_t:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Sanity check:\n",
    "pred = ultimate_t:forward{train_input:narrow(1,1,2):narrow(2,1,1),train_input:narrow(1,1,2):narrow(2,2,9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = criterion:forward(pred,torch.Tensor({4,1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4896723788842\t\n"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0000  0.0000  0.0000 -0.5000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.5000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.DoubleTensor of size 2x9]\n",
       "\n"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "WARNING: comm_open not handled yet\t\n"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion:backward(pred,torch.Tensor({4,1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 645\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input:narrow(1,1,1):narrow(2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 78.489984989166\t\n",
       "Average Loss: 0.52836980165634\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 79.068855047226\t\n",
       "Average Loss: 0.36818426410206\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 77.054080963135\t\n",
       "Average Loss: 0.33124513835614\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 77.238839149475\t\n",
       "Average Loss: 0.31238815111166\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 72.342820882797\t\n",
       "Average Loss: 0.30003632712975\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 70.415271997452\t\n",
       "Average Loss: 0.29088708722022\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 70.625241041183\t\n",
       "Average Loss: 0.28363107520592\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 70.360852956772\t\n",
       "Average Loss: 0.27762934497109\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 71.356517076492\t\n",
       "Average Loss: 0.27252198941696\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 70.386086940765\t\n",
       "Average Loss: 0.26808446229597\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 70.394453048706\t\n",
       "Average Loss: 0.26416596564707\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 71.304543018341\t\n",
       "Average Loss: 0.2606596815003\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 70.782297134399\t\n",
       "Average Loss: 0.25748693353588\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 328.22478914261\t\n",
       "Average Loss: 0.2545880959194\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 70.82666683197\t\n",
       "Average Loss: 0.25191692964002\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 72.322520971298\t\n",
       "Average Loss: 0.24943696050847\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 70.433362960815\t\n",
       "Average Loss: 0.2471189986981\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 70.505609989166\t\n",
       "Average Loss: 0.24493939147794\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 70.802218914032\t\n",
       "Average Loss: 0.24287882398742\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 70.813380002975\t\n",
       "Average Loss: 0.24092130150087\t\n"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_1 = train_model(train_input, train_output, ultimate_t, criterion, 10, 9, 0.01, 20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 72.436408996582\t\n",
       "Average Loss: 0.23905349760884\t\n"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 70.821997880936\t\n",
       "Average Loss: 0.23726421572767\t\n"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 71.64350605011\t\n",
       "Average Loss: 0.23554399788073\t\n"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 70.697922945023\t\n",
       "Average Loss: 0.23388478192972\t\n"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 70.485579967499\t\n",
       "Average Loss: 0.23227964487719\t\n"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_2 = train_model(train_input, train_output, ultimate_t, criterion, 10, 9, 0.01, 5, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_logscore(observations, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C)\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        y:narrow(1,j,1):copy(model:forward({observations[i]:view(1,1),hot_1:view(1,9)}))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function viterbi(observations, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{8,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + compute_logscore(observations, 1, model, C)[8]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore(observations, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_score(predicted_classes, true_classes)\n",
    "    local n = predicted_classes:size(1)\n",
    "    local right_pred = 0\n",
    "    local positive_true = 0\n",
    "    local positive_pred = 0\n",
    "    for i=1,n do\n",
    "        if predicted_classes[i] > 1 then\n",
    "            positive_pred = positive_pred + 1\n",
    "        end\n",
    "        if true_classes[i] > 1 then\n",
    "            positive_true = positive_true + 1\n",
    "        end\n",
    "        if (true_classes[i] == predicted_classes[i]) and true_classes[i] > 1 then\n",
    "            right_pred = right_pred + 1\n",
    "        end\n",
    "    end\n",
    "    local precision = right_pred/positive_pred\n",
    "    local recall = right_pred/positive_true\n",
    "    return precision, recall\n",
    "end\n",
    "        \n",
    "function f_score(predicted_classes, true_classes)\n",
    "    local p,r = compute_score(predicted_classes, true_classes)\n",
    "    print('Precision: '..p)\n",
    "    print ('Recall: '..r)\n",
    "    print ('f-score: '..2*p*r/(p+r))\n",
    "    return 2*p*r/(p+r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations = input_matrix_dev:narrow(2,1,1):clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_classes = input_matrix_dev_embed:narrow(2,60,1):squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "here\t\n"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = viterbi(observations, compute_logscore, ultimate_t, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7016\t\n",
       "6528\t\n",
       "5497\t\n",
       "0.84206495098039\t\n",
       "0.78349486887115\t\n",
       "0.81172474896633\t\n",
       "0.81172474896633\t\n"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tensor = f_score(cl, true_classes)\n",
    "print(f_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations_test = input_matrix_test:view(input_matrix_test:size(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "here\t\n"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_seq_test = viterbi(observations_test, compute_logscore, ultimate_t, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving predicted sequence on test\n",
    "myFile = hdf5.open('../submission/v_seq_test_mem', 'w')\n",
    "myFile:write('v_seq_test', v_seq_test)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data_cap.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train_cap = data['input_matrix_train_cap']\n",
    "input_matrix_dev_cap = data['input_matrix_dev_cap']\n",
    "input_matrix_test_cap = data['input_matrix_test_cap']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = train_output:size(1)\n",
    "train_input_cap = torch.Tensor(nwords-1,15)\n",
    "train_input_cap:narrow(2,1,1):copy(input_matrix_train_cap:narrow(2,1,1):narrow(1,2,nwords-1))\n",
    "train_input_cap:narrow(2,2,9):copy(input_matrix_train_cap:narrow(2,2,9):narrow(1,1,nwords-1))\n",
    "train_input_cap:narrow(2,11,5):copy(input_matrix_train_cap:narrow(2,11,5):narrow(1,1,nwords-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ultimate_t_cap = nn.Sequential()\n",
    "t1_cap = nn.ParallelTable()\n",
    "\n",
    "t1_cap_1 = nn.Sequential()\n",
    "t1_cap_1:add(LT)\n",
    "t1_cap_1:add(nn.View(-1,50))\n",
    "\n",
    "t1_cap_2 = nn.Identity()\n",
    "\n",
    "t1_cap:add(t1_cap_1)\n",
    "t1_cap:add(t1_cap_2)\n",
    "\n",
    "ultimate_t_cap:add(t1_cap)\n",
    "ultimate_t_cap:add(nn.JoinTable(2))\n",
    "\n",
    "ultimate_t_cap:add(nn.Linear(64,9))\n",
    "ultimate_t_cap:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3609 -2.3948 -1.7501 -2.2660 -2.1834 -2.4742 -1.9729 -1.9689 -2.7898\n",
       "[torch.DoubleTensor of size 1x9]\n",
       "\n"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultimate_t_cap:forward{train_input_cap:narrow(1,1,1):narrow(2,1,1),train_input_cap:narrow(1,1,1):narrow(2,2,14)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model_cap(train_input, train_output, model, criterion, din, nclass, eta, nEpochs, batchSize)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    loss = torch.Tensor(nEpochs)\n",
    "\n",
    "    -- To store the loss\n",
    "    av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(batchSize, din)\n",
    "    targets_batch = torch.DoubleTensor(batchSize)\n",
    "    outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "--             print('here1')\n",
    "            \n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "--             print('here2')\n",
    "            \n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(model:forward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1),\n",
    "                                                                        inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,14)}))\n",
    "--             print('here4')\n",
    "            -- Average loss computation\n",
    "            f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            \n",
    "--             print('here5')\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "--             print('here6')\n",
    "            model:backward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1), inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,14)}, \n",
    "                            df_do:narrow(1,1,current_batch_size))\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        loss[i] = av_L/math.floor(train_input:size(1)/batchSize)\n",
    "        print('Average Loss: '.. loss[i])\n",
    "       \n",
    "    end\n",
    "    \n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 70.712356090546\t\n",
       "Average Loss: 0.50310520465441\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 70.425627946854\t\n",
       "Average Loss: 0.34053567456718\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 70.346951007843\t\n",
       "Average Loss: 0.30468165034808\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 71.26979804039\t\n",
       "Average Loss: 0.28644514853156\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 70.6217648983\t\n",
       "Average Loss: 0.27451383334762\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 71.00425195694\t\n",
       "Average Loss: 0.26573108621283\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 71.473427057266\t\n",
       "Average Loss: 0.25883494101703\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 70.498846054077\t\n",
       "Average Loss: 0.25319547950636\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 70.506222009659\t\n",
       "Average Loss: 0.24844942114158\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 70.554450035095\t\n",
       "Average Loss: 0.24436644474503\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 70.729074954987\t\n",
       "Average Loss: 0.24079091707126\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 70.404722929001\t\n",
       "Average Loss: 0.23761293670641\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 70.325660943985\t\n",
       "Average Loss: 0.23475233187037\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 70.96702003479\t\n",
       "Average Loss: 0.23214912031482\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 70.289011001587\t\n",
       "Average Loss: 0.22975747645261\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 70.745599031448\t\n",
       "Average Loss: 0.22754180283866\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 70.9817070961\t\n",
       "Average Loss: 0.22547400392261\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 71.781083106995\t\n",
       "Average Loss: 0.22353160058383\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 70.286765098572\t\n",
       "Average Loss: 0.22169641716466\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 70.86462688446\t\n",
       "Average Loss: 0.21995358255235\t\n"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cap = train_model_cap(train_input_cap, train_output, ultimate_t_cap, criterion, 15, 9, 0.01, 20, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 71.504629850388\t\n",
       "Average Loss: 0.21981077053702\t\n"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 79.878816127777\t\n",
       "Average Loss: 0.21949923248368\t\n"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 73.816610097885\t\n",
       "Average Loss: 0.21927489435913\t\n"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cap_2 = train_model_cap(train_input_cap, train_output, ultimate_t_cap, criterion, 15, 9, 0.001, 3, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 72.5975689888\t\n",
       "Average Loss: 0.20909823798932\t\n"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 70.560930013657\t\n",
       "Average Loss: 0.19788823075198\t\n"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cap_3 = train_model_cap(train_input_cap, train_output, ultimate_t_cap, criterion, 15, 9, 0.1, 2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 71.19276714325\t\n",
       "Average Loss: 0.18782437035191\t\n"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 70.893792867661\t\n",
       "Average Loss: 0.17851937297793\t\n"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 70.709676980972\t\n",
       "Average Loss: 0.16980573348033\t\n"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 72.024089097977\t\n",
       "Average Loss: 0.1616779017535\t\n"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 70.403036117554\t\n",
       "Average Loss: 0.154168990045\t\n"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cap_4 = train_model_cap(train_input_cap, train_output, ultimate_t_cap, criterion, 15, 9, 0.1, 5, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 72.541322946548\t\n",
       "Average Loss: 0.14732098656081\t\n"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 70.828729867935\t\n",
       "Average Loss: 0.14119754426576\t\n"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 72.119047164917\t\n",
       "Average Loss: 0.1358135003866\t\n"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 70.52068901062\t\n",
       "Average Loss: 0.13108787825574\t\n"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 72.093950033188\t\n",
       "Average Loss: 0.12692133195558\t\n"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cap_5 = train_model_cap(train_input_cap, train_output, ultimate_t_cap, criterion, 15, 9, 0.1, 5, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_logscore_cap(observations, caps, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C+5)\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        hot_1:narrow(1,10,5):copy(caps:narrow(1,i,1))\n",
    "        y:narrow(1,j,1):copy(model:forward({observations[i]:view(1,1),hot_1:view(1,C+5)}))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function viterbi_cap(observations, caps, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{8,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + compute_logscore_cap(observations, caps, 1, model, C)[8]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore_cap(observations, caps, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations_dev = input_matrix_dev_cap:narrow(2,1,1):clone()\n",
    "dev_cap = input_matrix_dev_cap:narrow(2,11,5)\n",
    "dev_true_classes = input_matrix_dev_cap:narrow(2,16,1):squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl_caps = viterbi_cap(observations_dev, dev_cap, compute_logscore_cap, ultimate_t_cap, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7016\t\n",
       "6594\t\n",
       "5630\t\n",
       "0.82733284349743\t\n"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tensor_caps = f_score(cl_caps, dev_true_classes)\n",
    "print(f_tensor_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_caps_ = viterbi_cap(observations_dev, dev_cap, compute_logscore_cap, ultimate_t_cap, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7016\t\n",
       "6594\t\n",
       "5630\t\n",
       "0.85380649074917\t\n",
       "0.80245153933865\t\n",
       "0.82733284349743\t\n",
       "0.82733284349743\t\n"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_tensor_caps_ = f_score(cl_caps, dev_true_classes)\n",
    "print(f_tensor_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations_test_cap = input_matrix_test_cap:narrow(2,1,1)\n",
    "observations_test_caps = input_matrix_test_cap:narrow(2,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_seq_test_cap = viterbi_cap(observations_test_cap, observations_test_caps, compute_logscore_cap, ultimate_t_cap, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving predicted sequence on test\n",
    "myFile = hdf5.open('../submission/v_seq_test_mem_cap', 'w')\n",
    "myFile:write('v_seq_test', v_seq_test_cap)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viterbi(observations:narrow(1,1,5), compute_logscore, ultimate_t, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 8\n",
       " 1\n",
       " 1\n",
       " 4\n",
       " 1\n",
       "[torch.DoubleTensor of size 5]\n",
       "\n"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_classes:narrow(1,1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('toplot_2', 'w')\n",
    "myFile:write('loss1', loss_1)\n",
    "myFile:write('loss2', loss_2)\n",
    "myFile:write('loss3', loss_cap)\n",
    "myFile:write('loss4', loss_cap_3)\n",
    "myFile:write('loss5', loss_cap_4)\n",
    "myFile:write('loss6', loss_cap_5)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## POS + CAPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data_pos.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train_pos = data['input_matrix_train_pos']\n",
    "input_matrix_dev_pos = data['input_matrix_dev_pos']\n",
    "input_matrix_test_pos = data['input_matrix_test_pos']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 55961\n",
       "    59\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix_train_pos:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwords = train_output:size(1)\n",
    "train_input_pos = torch.Tensor(nwords-1,1+9+5+43)\n",
    "train_input_pos:narrow(2,1,1):copy(input_matrix_train_pos:narrow(2,1,1):narrow(1,2,nwords-1))\n",
    "train_input_pos:narrow(2,2,9):copy(input_matrix_train_pos:narrow(2,2,9):narrow(1,1,nwords-1))\n",
    "train_input_pos:narrow(2,11,5):copy(input_matrix_train_pos:narrow(2,11,5):narrow(1,1,nwords-1))\n",
    "train_input_pos:narrow(2,16,43):copy(input_matrix_train_pos:narrow(2,16,43):narrow(1,1,nwords-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ultimate_t_pos = nn.Sequential()\n",
    "t1_pos = nn.ParallelTable()\n",
    "\n",
    "t1_pos_1 = nn.Sequential()\n",
    "t1_pos_1:add(LT)\n",
    "t1_pos_1:add(nn.View(-1,50))\n",
    "\n",
    "t1_pos_2 = nn.Identity()\n",
    "\n",
    "t1_pos:add(t1_pos_1)\n",
    "t1_pos:add(t1_pos_2)\n",
    "\n",
    "ultimate_t_pos:add(t1_pos)\n",
    "ultimate_t_pos:add(nn.JoinTable(2))\n",
    "\n",
    "ultimate_t_pos:add(nn.Linear(50 + 9 + 5 + 43,9))\n",
    "ultimate_t_pos:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model_cap(train_input, train_output, model, criterion, din, nclass, eta, nEpochs, batchSize)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    loss = torch.Tensor(nEpochs)\n",
    "\n",
    "    -- To store the loss\n",
    "    av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(batchSize, din)\n",
    "    targets_batch = torch.DoubleTensor(batchSize)\n",
    "    outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "--             print('here1')\n",
    "\n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "--             print('here2')\n",
    "            \n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(model:forward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1),\n",
    "                                                                        inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,din-1)}))\n",
    "--             print('here4')\n",
    "            -- Average loss computation\n",
    "            f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            \n",
    "--             print('here5')\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "--             print('here6')\n",
    "            model:backward({inputs_batch:narrow(1,1,current_batch_size):narrow(2,1,1), inputs_batch:narrow(1,1,current_batch_size):narrow(2,2,din-1)}, \n",
    "                            df_do:narrow(1,1,current_batch_size))\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        loss[i] = av_L/math.floor(train_input:size(1)/batchSize)\n",
    "        print('Average Loss: '.. loss[i])\n",
    "       \n",
    "    end\n",
    "    \n",
    "    return loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 74.638386964798\t\n",
       "Average Loss: 0.24734362920411\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 74.167896986008\t\n",
       "Average Loss: 0.16656999558134\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pos_1 = train_model_cap(train_input_pos, train_output, ultimate_t_pos, criterion, 1 + 9 + 5 + 43, 9, 0.1, 2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 80.290169000626\t\n",
       "Average Loss: 0.14793340624815\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 81.143066883087\t\n",
       "Average Loss: 0.13746301808013\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 79.309170007706\t\n",
       "Average Loss: 0.13045959960806\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 80.2799949646\t\n",
       "Average Loss: 0.12526806192372\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 78.669210910797\t\n",
       "Average Loss: 0.12114269568512\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 81.519361019135\t\n",
       "Average Loss: 0.11771335740399\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 79.529055118561\t\n",
       "Average Loss: 0.11477946593546\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 81.843497037888\t\n",
       "Average Loss: 0.11222294004583\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 80.04273891449\t\n",
       "Average Loss: 0.10996897750338\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 82.426858901978\t\n",
       "Average Loss: 0.10796582877536\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pos_2 = train_model_cap(train_input_pos, train_output, ultimate_t_pos, criterion, 1 + 9 + 5 + 43, 9, 0.1, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 73.655549049377\t\n",
       "Average Loss: 0.10617477344597\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 73.671877145767\t\n",
       "Average Loss: 0.10456507407248\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 73.590552806854\t\n",
       "Average Loss: 0.1031113155337\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 73.629473924637\t\n",
       "Average Loss: 0.10179201741353\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 73.549799919128\t\n",
       "Average Loss: 0.10058889747994\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 73.436652898788\t\n",
       "Average Loss: 0.09948634260706\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 73.613955020905\t\n",
       "Average Loss: 0.098470927755774\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 73.383464813232\t\n",
       "Average Loss: 0.097531541395249\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 72.976552009583\t\n",
       "Average Loss: 0.096658699466685\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 73.339462995529\t\n",
       "Average Loss: 0.095844338653943\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pos_3 = train_model_cap(train_input_pos, train_output, ultimate_t_pos, criterion, 1 + 9 + 5 + 43, 9, 0.1, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_logscore_extrafeat(observations, feat, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C+feat:size(2))\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        hot_1:narrow(1,10,feat:size(2)):copy(feat:narrow(1,i,1))\n",
    "        y:narrow(1,j,1):copy(model:forward({observations[i]:view(1,1),hot_1:view(1,C+feat:size(2))}))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function viterbi_extrafeat(observations, feat, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{8,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + compute_logscore_extrafeat(observations, feat, 1, model, C)[8]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore_extrafeat(observations, feat, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end\n",
    "\n",
    "function compute_score(predicted_classes, true_classes)\n",
    "    local n = predicted_classes:size(1)\n",
    "    local right_pred = 0\n",
    "    local positive_true = 0\n",
    "    local positive_pred = 0\n",
    "    for i=1,n do\n",
    "        if predicted_classes[i] > 1 then\n",
    "            positive_pred = positive_pred + 1\n",
    "        end\n",
    "        if true_classes[i] > 1 then\n",
    "            positive_true = positive_true + 1\n",
    "        end\n",
    "        if (true_classes[i] == predicted_classes[i]) and true_classes[i] > 1 then\n",
    "            right_pred = right_pred + 1\n",
    "        end\n",
    "    end\n",
    "    local precision = right_pred/positive_pred\n",
    "    local recall = right_pred/positive_true\n",
    "    return precision, recall\n",
    "end\n",
    "        \n",
    "function f_score(predicted_classes, true_classes)\n",
    "    local p,r = compute_score(predicted_classes, true_classes)\n",
    "    print('Precision: '..p)\n",
    "    print ('Recall: '..r)\n",
    "    print ('f-score: '..2*p*r/(p+r))\n",
    "    return 2*p*r/(p+r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations_dev = input_matrix_dev_pos:narrow(2,1,1):clone()\n",
    "dev_feat = input_matrix_dev_pos:narrow(2,11, 5 + 43)\n",
    "dev_true_classes = input_matrix_dev_pos:narrow(2, 59,1):squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision: 0.85229988052569\t\n",
       "Recall: 0.81342645381984\t\n",
       "f-score: 0.83240956826138\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_pos = viterbi_extrafeat(observations_dev, dev_feat, compute_logscore_extrafeat, ultimate_t_pos, 9)\n",
    "f = f_score(cl_pos, dev_true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations_test_pos = input_matrix_test_pos:narrow(2,1,1)\n",
    "observations_test_feat = input_matrix_test_pos:narrow(2,2,5+43)\n",
    "v_seq_test_pos = viterbi_extrafeat(observations_test_pos, observations_test_feat, compute_logscore_extrafeat, ultimate_t_pos, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving predicted sequence on test\n",
    "myFile = hdf5.open('../submission/v_seq_test_mem_pos', 'w')\n",
    "myFile:write('v_seq_test', v_seq_test_pos)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('toplot_3', 'w')\n",
    "myFile:write('losspos1', loss_pos_1)\n",
    "myFile:write('losspos2', loss_pos_2)\n",
    "myFile:write('losspos3', loss_pos_3)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 8\n",
       " 3\n",
       " 3\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 9\n",
       "[torch.DoubleTensor of size 37]\n",
       "\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_pos:narrow(1,18,37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 8\n",
       " 3\n",
       " 3\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 9\n",
       "[torch.DoubleTensor of size 37]\n",
       "\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_extrafeat(observations_dev:narrow(1,18,37), dev_feat:narrow(1,18,37), compute_logscore_extrafeat, ultimate_t_pos, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
