{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/MM_data_cap.hdf5','r')\n",
    "data = myFile:all()\n",
    "input_matrix_train_cap = data['input_matrix_train_cap']\n",
    "input_matrix_dev_cap = data['input_matrix_dev_cap']\n",
    "input_matrix_test_cap = data['input_matrix_test_cap']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Loading data\n",
    "myFile = hdf5.open('../data/sent_start.hdf5','r')\n",
    "data = myFile:all()\n",
    "sent = data['sent_start']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwords = input_matrix_train_cap:size(1)\n",
    "train_input = torch.Tensor(nwords-1,10)\n",
    "train_input:narrow(2,1,1):copy(input_matrix_train_cap:narrow(2,1,1):narrow(1,2,nwords-1))\n",
    "train_input:narrow(2,2,9):copy(input_matrix_train_cap:narrow(2,2,9):narrow(1,1,nwords-1))\n",
    "train_output = input_matrix_train_cap:narrow(2,16,1):narrow(1,2,nwords-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data/embeddings.hdf5','r')\n",
    "data2 = myFile:all()\n",
    "embeddings = data2['embeddings']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_logscore(observations, i, model, C)\n",
    "    local y = torch.zeros(C,C)\n",
    "    local hot_1 = torch.zeros(C)\n",
    "    for j = 1, C do\n",
    "        hot_1:zero()\n",
    "        hot_1[j] = 1\n",
    "        y:narrow(1,j,1):copy(model:forward({observations[i]:view(1,1),hot_1:view(1,9)}))\n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "function viterbi(observations, compute_logscore, model, C)\n",
    "    \n",
    "    local y = torch.zeros(C,C)\n",
    "    -- Formating tensors\n",
    "    local initial = torch.zeros(C, 1)\n",
    "    -- initial started with a start of sentence: <t>\n",
    "\n",
    "    initial[{8,1}] = 1\n",
    "    initial:log()\n",
    "\n",
    "    -- number of classes\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + compute_logscore(observations, 1, model, C)[8]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "       \n",
    "        y:copy(compute_logscore(observations, i, model, C))\n",
    "        scores = y:transpose(1,2) + maxes:view(1, C):expand(C, C)\n",
    "\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "\n",
    "    return classes\n",
    "end\n",
    "\n",
    "function train_model(train_input, sent, train_output, model, din, nclass, eta, nEpochs)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(100, din)\n",
    "    gold_sequence = torch.DoubleTensor(100)\n",
    "    high_score_seq = torch.DoubleTensor(100)\n",
    "    grad_pos = torch.zeros(9)\n",
    "    grad_neg = torch.zeros(9)\n",
    "    pr1 = torch.zeros(1,9)\n",
    "    pr2 = torch.zeros(1,9)\n",
    "    \n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 2, sent:size(1)-1 do\n",
    "            -- Mini batch data\n",
    "            sent_size = sent[{t,2}]\n",
    "--             print('here1')\n",
    "            \n",
    "            inputs_batch:narrow(1,1,sent_size+1):copy(train_input:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here2')\n",
    "            \n",
    "            gold_sequence:narrow(1,1,sent_size+1):copy(train_output:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass on a batch subsequence:\n",
    "            high_score_seq:narrow(1,1,sent_size+1):copy(viterbi(inputs_batch:narrow(1,1,sent_size+1):narrow(2,1,1), \n",
    "                                                                compute_logscore, model, nclass))\n",
    "--             print('here4')\n",
    "            \n",
    "            \n",
    "            for ii = 1, sent_size+1 do\n",
    "                grad_neg:zero()\n",
    "                grad_pos:zero()\n",
    "                if high_score_seq[ii] ~= gold_sequence[ii] then\n",
    "                    -- WARNING: Need to call backward right after the forward with the same input to compute correct gradients\n",
    "                    \n",
    "                    -- Use of a single gradient (grad_pos) with a penalization on the wrong class predicted (1)\n",
    "                    -- and a valorisation (-1) on the correct class to predict\n",
    "                    \n",
    "                    model:forward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)})\n",
    "                    grad_pos[gold_sequence[ii]] = -1\n",
    "                    grad_pos[high_score_seq[ii]] = 1\n",
    "                    model:backward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)}, grad_pos:view(1,9))\n",
    "                end\n",
    "            end\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "       \n",
    "    end\n",
    "end\n",
    "\n",
    "function train_model2(train_input, sent, train_output, model, din, nclass, eta, nEpochs, obs_val, true_val, f_score)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    \n",
    "    val_res = torch.zeros(nEpochs,3)\n",
    "    -- Memory allocation\n",
    "    inputs_batch = torch.DoubleTensor(100, din)\n",
    "    gold_sequence = torch.DoubleTensor(100)\n",
    "    high_score_seq = torch.DoubleTensor(100)\n",
    "    grad_pos = torch.zeros(9)\n",
    "    grad_neg = torch.zeros(9)\n",
    "    one_hot_true = torch.zeros(1,9)\n",
    "    one_hot_false = torch.zeros(1,9)\n",
    "    \n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 2, sent:size(1)-1 do\n",
    "            -- Mini batch data\n",
    "            sent_size = sent[{t,2}]\n",
    "--             print('here1')\n",
    "            \n",
    "            inputs_batch:narrow(1,1,sent_size+1):copy(train_input:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here2')\n",
    "            \n",
    "            gold_sequence:narrow(1,1,sent_size+1):copy(train_output:narrow(1,sent[{t,1}]-1,sent_size+1))\n",
    "--             print('here3')\n",
    "            \n",
    "            -- reset gradients\n",
    "            model:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass on a batch subsequence:\n",
    "            high_score_seq:narrow(1,1,sent_size+1):copy(viterbi(inputs_batch:narrow(1,1,sent_size+1):narrow(2,1,1), \n",
    "                                                                compute_logscore, model, nclass))\n",
    "--             print('here4')\n",
    "            \n",
    "            previous_error = false\n",
    "\n",
    "            for ii = 1, sent_size+1 do\n",
    "                \n",
    "                grad_neg:zero()\n",
    "                grad_pos:zero()\n",
    "                \n",
    "                if high_score_seq[ii] ~= gold_sequence[ii] and not previous_error then\n",
    "                    -- WARNING: Need to call backward right after the forward with the same input to compute correct gradients\n",
    "                    \n",
    "                    -- Use of a single gradient (grad_pos) with a penalization on the wrong class predicted (1)\n",
    "                    -- and a valorisation (-1) on the correct class to predict\n",
    "                    \n",
    "                    model:forward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)})\n",
    "                    grad_pos[gold_sequence[ii]] = -1\n",
    "                    grad_pos[high_score_seq[ii]] = 1\n",
    "                    model:backward({inputs_batch:narrow(1,ii,1):narrow(2,1,1),inputs_batch:narrow(1,ii,1):narrow(2,2,9)}, grad_pos:view(1,9))\n",
    "                    \n",
    "                    grad_neg:zero()\n",
    "                    grad_pos:zero()\n",
    "                    if ii ~= (sent_size + 1) then\n",
    "                        one_hot_true:zero()\n",
    "                        one_hot_true[1][gold_sequence[ii]] = 1\n",
    "                        model:forward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_true})\n",
    "                        grad_neg[gold_sequence[ii+1]] = -1\n",
    "                        model:backward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_true}, grad_neg:view(1,9) )\n",
    "                        \n",
    "                        one_hot_false:zero()\n",
    "                        one_hot_false[1][high_score_seq[ii]] = 1\n",
    "                        model:forward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_false})\n",
    "                        grad_pos[gold_sequence[ii+1]] = 1\n",
    "                        model:backward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_false}, grad_pos:view(1,9) )\n",
    "                    end\n",
    "                    \n",
    "                    previous_error = true\n",
    "                    \n",
    "                elseif high_score_seq[ii] ~= gold_sequence[ii] and previous_error then\n",
    "                    \n",
    "                    if ii ~= sent_size + 1 then\n",
    "                        one_hot_true:zero()\n",
    "                        one_hot_true[1][gold_sequence[ii]] = 1\n",
    "                        model:forward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_true})\n",
    "                        grad_neg[gold_sequence[ii+1]] = -1\n",
    "                        model:backward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_true}, grad_neg:view(1,9) )\n",
    "                        \n",
    "                        one_hot_false:zero()\n",
    "                        one_hot_false[1][high_score_seq[ii]] = 1\n",
    "                        model:forward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_false})\n",
    "                        grad_pos[gold_sequence[ii+1]] = 1\n",
    "                        model:backward({inputs_batch:narrow(1,ii+1,1):narrow(2,1,1),one_hot_false}, grad_pos:view(1,9) )\n",
    "                    end\n",
    "                    \n",
    "                    previous_error = true\n",
    "                    \n",
    "                else\n",
    "                    previous_error = false\n",
    "                end\n",
    "            end\n",
    "--             print('here7')\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        cl = viterbi(obs_val, compute_logscore, model, 9)\n",
    "        val_res[i][1], val_res[i][2], val_res[i][3]  = f_score(cl, true_val)\n",
    "        print('f-score: '.. val_res[i][1])\n",
    "        \n",
    "    end\n",
    "    return val_res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function compute_score(predicted_classes, true_classes)\n",
    "    local n = predicted_classes:size(1)\n",
    "    local right_pred = 0\n",
    "    local positive_true = 0\n",
    "    local positive_pred = 0\n",
    "    for i=1,n do\n",
    "        if predicted_classes[i] > 1 then\n",
    "            positive_pred = positive_pred + 1\n",
    "        end\n",
    "        if true_classes[i] > 1 then\n",
    "            positive_true = positive_true + 1\n",
    "        end\n",
    "        if (true_classes[i] == predicted_classes[i]) and true_classes[i] > 1 then\n",
    "            right_pred = right_pred + 1\n",
    "        end\n",
    "    end\n",
    "    local precision = right_pred/positive_pred\n",
    "    local recall = right_pred/positive_true\n",
    "    return precision, recall\n",
    "end\n",
    "        \n",
    "function f_score(predicted_classes, true_classes)\n",
    "    local p,r = compute_score(predicted_classes, true_classes)\n",
    "    return 2*p*r/(p+r), p, r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LT = nn.LookupTable(400002,50)\n",
    "LT.weight:narrow(1, 1, 400000):copy(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "t1 = nn.ParallelTable()\n",
    "\n",
    "t1_1 = nn.Sequential()\n",
    "t1_1:add(LT)\n",
    "t1_1:add(nn.View(-1,50))\n",
    "\n",
    "t1_2 = nn.Identity()\n",
    "\n",
    "t1:add(t1_1)\n",
    "t1:add(t1_2)\n",
    "\n",
    "model:add(t1)\n",
    "model:add(nn.JoinTable(2))\n",
    "\n",
    "lin = nn.Linear(59,9)\n",
    "model:add(lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin.weight:zero();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations = input_matrix_dev_cap:narrow(2,1,1):clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_classes = input_matrix_dev_cap:narrow(2,16,1):squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 256.44453811646\t\n"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.63478260869565\t\n"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res = train_model2(train_input, sent, train_output, model, 10, 9, 0.0001, 1, observations, true_classes, f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 253.30662202835\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.56481481481481\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 246.12050509453\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.46610169491525\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 257.61001491547\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.46153846153846\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 249.08931493759\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.47577092511013\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 247.63232302666\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.4688995215311\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 247.5095949173\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.49090909090909\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 247.81283092499\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.53\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 248.55041408539\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.54639175257732\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 248.59220290184\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.52884615384615\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 249.00901293755\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.54455445544554\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 248.41658306122\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.51231527093596\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 247.52356481552\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.50485436893204\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 247.83906602859\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.51485148514851\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 247.31948900223\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.5049504950495\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 247.84553194046\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.52307692307692\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 247.52341294289\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.48756218905473\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 247.16925907135\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.47474747474747\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 247.20517706871\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.48275862068966\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 247.14581179619\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "f-score: 0.47236180904523\t\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res2 = train_model2(train_input, sent, train_output, model, 10, 9, 0.0001, 19, observations, true_classes, f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 8\n",
       " 1\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 9\n",
       "[torch.LongTensor of size 13]\n",
       "\n"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_classes:narrow(1,1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 8\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 5\n",
       "[torch.DoubleTensor of size 13]\n",
       "\n"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi(observations:narrow(1,1,13), compute_logscore, model, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = viterbi(observations, compute_logscore, model, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53327021909656\t0.50733401955739\t0.56200114025086\t\n"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (f_score(cl, true_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108\t\n",
       "123\t\n",
       "73\t\n",
       "0.63203463203463\t\n"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- 0.001 LR\n",
    "print (f_score(cl, true_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108\t\n",
       "100\t\n",
       "58\t\n",
       "0.55769230769231\t\n"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- 0.01 LR\n",
    "print (f_score(cl, true_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
