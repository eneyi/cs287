{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_valid = data['input_data_valid']\n",
    "output_matrix_train = data['output_matrix_train']\n",
    "input_matrix_train = data['input_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "input_data_test = data['input_data_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 599903\n",
       "      1\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 599903\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       " 599905\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_matrix_train:size())\n",
    "print(output_matrix_train:size())\n",
    "print(input_data_train:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Formating the input\n",
    "-- input is a 1d tensor\n",
    "function get_train_input(input, len, batch_size)\n",
    "    -- Building output (we put predict a padding at the end)\n",
    "    local n = input:size(1)\n",
    "    \n",
    "    -- Get the closer multiple of batch_size*len below n\n",
    "    local factor = -math.floor(-n/(len*batch_size))\n",
    "    local n_new = factor*len*batch_size\n",
    "    local input_new = torch.DoubleTensor(n_new)\n",
    "    local t_input, t_output\n",
    "    input_new:narrow(1,1,n):copy(input)\n",
    "    input_new:narrow(1,n,n_new-n+1):fill(2) -- Filling with padding\n",
    "    \n",
    "    -- Building output\n",
    "    local output = torch.DoubleTensor(n_new)\n",
    "    for i=2, n_new do\n",
    "        if input_new[i] ~= 1 then\n",
    "            output[i-1] = 2\n",
    "        else\n",
    "            output[i-1] = input_new[i]\n",
    "        end\n",
    "    end\n",
    "    output[n_new] = 2\n",
    "\n",
    "    -- Issue with last sequence if batch_size does not divide n\n",
    "    t_input = torch.split(input_new:view(batch_size,n_new/batch_size),len, 2)\n",
    "    t_output = torch.split(output:view(batch_size,n_new/batch_size),len, 2)\n",
    "    return t_input, t_output\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_RNN(embed_dim, rho)\n",
    "    return nn.Recurrent(embed_dim, nn.Linear(embed_dim, embed_dim),nn.Linear(embed_dim, embed_dim), nn.Tanh(), rho)\n",
    "end\n",
    "\n",
    "function build_LSTM(embed_dim, rho)\n",
    "    return nn.FastLSTM(embed_dim, embed_dim, rho)\n",
    "end\n",
    "\n",
    "function build_GRU(embed_dim, rho, dropout_p)\n",
    "    return nn.GRU(embed_dim, embed_dim, rho,dropout_p)\n",
    "end\n",
    "\n",
    "function build_rnn(embed_dim, vocab_size, batch_size, recurrent_model, len)\n",
    "    local batchRNN\n",
    "    local params\n",
    "    local grad_params\n",
    "    -- generic RNN transduced\n",
    "    batchRNN = nn.Sequential()\n",
    "        :add(nn.LookupTable(vocab_size, embed_dim))\n",
    "        :add(nn.SplitTable(1, batch_size))\n",
    "    local rec = nn.Sequencer(recurrent_model)\n",
    "    rec:remember('both')\n",
    "    \n",
    "    batchRNN:add(rec)\n",
    "    \n",
    "    -- Output\n",
    "    batchRNN:add(nn.Sequencer(nn.Linear(embed_dim, 2)))\n",
    "    batchRNN:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "    -- Retrieve parameters (To do only once!!!)\n",
    "    params, grad_params = batchRNN:getParameters()\n",
    "    -- Initializing all the parameters between -0.05 and 0.05\n",
    "    for k=1,params:size(1) do\n",
    "        params[k] = torch.uniform(-0.05,0.05)\n",
    "    end\n",
    "    \n",
    "    return batchRNN, params, grad_params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Building output valid matrix\n",
    "output_valid = torch.DoubleTensor(input_data_valid:size(1))\n",
    "for i=2, input_data_valid:size(1) do\n",
    "    if input_data_valid[i] ~= 1 then\n",
    "        output_valid[i-1] = 2\n",
    "    else\n",
    "        output_valid[i-1] = input_data_valid[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train_model(t_input, t_output, model, params, grad_params,\n",
    "                     criterion, eta, nEpochs, batch_size, len, n)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    local timer\n",
    "    local pred\n",
    "    local loss\n",
    "    local dLdPred\n",
    "    local t_inputT = torch.DoubleTensor(len,batch_size)\n",
    "    local t_output_table\n",
    "    local delta = 0.2\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        old_L = av_L\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for k = 1, n/(batch_size * len) do\n",
    "            -- Mini batch data\n",
    "                \n",
    "            t_inputT:copy(t_input[k]:t())\n",
    "            t_output_table = torch.split(t_output[k],1,2)\n",
    "            --format the output\n",
    "            for j=1,len do\n",
    "                t_output_table[j] = t_output_table[j]:squeeze()\n",
    "            end \n",
    "            \n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            \n",
    "            -- Forward loop\n",
    "            pred = model:forward(t_inputT)\n",
    "            loss = criterion:forward(pred, t_output_table)\n",
    "            av_L = av_L + loss\n",
    "\n",
    "            -- Backward loop\n",
    "            dLdPred = criterion:backward(pred, t_output_table)\n",
    "            model:backward(t_inputT, dLdPred)\n",
    "            \n",
    "            -- gradient normalization with max norm 5 (l2 norm)\n",
    "            grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(n/batch_size))\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if (old_L - av_L) < delta then\n",
    "        eta = eta/2\n",
    "        delta = delta/2\n",
    "    end\n",
    "    \n",
    "    if (eta < 0.001) then eta = 0.1 end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model_with_perp(t_input, t_output, model, model_flattened, params_flattened,\n",
    "        params, grad_params, criterion, eta, nEpochs, batch_size, len, n, input_valid, output_valid, step)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    local timer\n",
    "    local pred\n",
    "    local loss\n",
    "    local dLdPred\n",
    "    local t_inputT = torch.DoubleTensor(len,batch_size)\n",
    "    local t_output_table\n",
    "    local size\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "    local perp = 0\n",
    "    local old_perp = 0\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        old_L = av_L\n",
    "        old_perp = perp\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for k = 1, n/(batch_size * len) do\n",
    "            -- Mini batch data\n",
    "                \n",
    "            t_inputT:copy(t_input[k]:t())\n",
    "            t_output_table = torch.split(t_output[k],1,2)\n",
    "            --format the output\n",
    "            for j=1,len do\n",
    "                t_output_table[j] = t_output_table[j]:squeeze()\n",
    "            end \n",
    "            \n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            \n",
    "            -- Forward loop\n",
    "            pred = model:forward(t_inputT)\n",
    "            loss = criterion:forward(pred, t_output_table)\n",
    "            av_L = av_L + loss\n",
    "\n",
    "            -- Backward loop\n",
    "            dLdPred = criterion:backward(pred, t_output_table)\n",
    "            model:backward(t_inputT, dLdPred)\n",
    "            \n",
    "            -- gradient normalization with max norm 5 (l2 norm)\n",
    "            grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(n/batch_size))\n",
    "        -- Print perplexity validity every step of iteration\n",
    "        if (i%step == 0) then\n",
    "            size = input_valid:size(1) - 1\n",
    "            params_flattened:copy(params)\n",
    "            perp = compute_perplexity(input_valid:narrow(1,1,size):view(size,1), output_valid, model_flattened)\n",
    "            print('Valid perplexity: '..perp)\n",
    "            \n",
    "            if old_perp - perp < 0 then\n",
    "                eta = eta/2\n",
    "            end\n",
    "\n",
    "            if (eta < 0.0001) then eta = 0.1 end\n",
    "\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, len)\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1, len)\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.8074369430542\t\n",
       "Average Loss: 0.31228050204274\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.7043259143829\t\n",
       "Average Loss: 0.26151257461365\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.2467911243439\t\n",
       "Average Loss: 0.23146731025455\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 3\n",
    "train_model(t_input, t_output, batchRNN, params, grad_params,\n",
    "                     crit, eta, nEpochs, batch_size, len, n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.0373430252075\t\n",
       "Average Loss: 0.31127603024063\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.3167066034457\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.0228929519653\t\n",
       "Average Loss: 0.2595806616951\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.272589419065\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.0724031925201\t\n",
       "Average Loss: 0.23316074090171\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2505899734403\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.7879350185394\t\n",
       "Average Loss: 0.21455134532284\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2305572804994\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.1380410194397\t\n",
       "Average Loss: 0.20159015092112\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2191191235031\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.0522859096527\t\n",
       "Average Loss: 0.19299361409045\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2106942406731\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.0655410289764\t\n",
       "Average Loss: 0.18630843005958\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2040019027776\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.0618779659271\t\n",
       "Average Loss: 0.18083623497307\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1988415676649\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.0254361629486\t\n",
       "Average Loss: 0.17666558202226\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1948545425466\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.0559229850769\t\n",
       "Average Loss: 0.17341161985071\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.191752075552\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.1608598232269\t\n",
       "Average Loss: 0.17066010915357\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1893514698956\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.0460610389709\t\n",
       "Average Loss: 0.16842283821082\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1876828130608\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.1154489517212\t\n",
       "Average Loss: 0.16659270468897\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1864067460075\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.0670311450958\t\n",
       "Average Loss: 0.16518998250815\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1853287486702\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.1075801849365\t\n",
       "Average Loss: 0.16408510411659\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1845620295284\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.3404068946838\t\n",
       "Average Loss: 0.16316840120459\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1840970283144\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.0670158863068\t\n",
       "Average Loss: 0.16239600637254\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1837860540369\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.0414438247681\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss: 0.16169741966653\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1833747002796\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.0382349491119\t\n",
       "Average Loss: 0.16102260010531\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1828553687182\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.026673078537\t\n",
       "Average Loss: 0.16036868317739\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1826217175028\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.1355979442596\t\n",
       "Average Loss: 0.15972079728122\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1824428813963\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.4839720726013\t\n",
       "Average Loss: 0.15909980418245\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.182109999531\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.2839608192444\t\n",
       "Average Loss: 0.15852116560753\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.181668471896\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.2338001728058\t\n",
       "Average Loss: 0.15796460040097\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1811241082699\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.8121101856232\t\n",
       "Average Loss: 0.15744148391804\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1806673353204\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.2398941516876\t\n",
       "Average Loss: 0.15692715807122\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1801969411692\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.1931447982788\t\n",
       "Average Loss: 0.15642420072222\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1797258097392\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.2221410274506\t\n",
       "Average Loss: 0.15592075426583\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1796751236756\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.2164981365204\t\n",
       "Average Loss: 0.15546064818585\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.179654980452\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.8618688583374\t\n",
       "Average Loss: 0.15505075502542\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1795317990726\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600000\t\n"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = 50\n",
    "batch_size = 4\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600000\t\n"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, batch_size, build_RNN(embed_dim, len), len)\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1,build_RNN(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 25.876962900162\t\n",
       "Average Loss: 0.26690913494538\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 25.171590089798\t\n",
       "Average Loss: 0.20740503567645\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 24.630791187286\t\n",
       "Average Loss: 0.18643517302651\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 25.385226964951\t\n",
       "Average Loss: 0.17807200826734\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 26.317702054977\t\n",
       "Average Loss: 0.17290693506462\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1970421011916\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 24.52170085907\t\n",
       "Average Loss: 0.1673060464136\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 24.278975009918\t\n",
       "Average Loss: 0.16566674484942\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 28.287208080292\t\n",
       "Average Loss: 0.16435510963808\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 32.050582170486\t\n",
       "Average Loss: 0.16316460718602\t"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 25.480005025864\t\n",
       "Average Loss: 0.16213567361777\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1868415078835\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 24.611994981766\t\n",
       "Average Loss: 0.16118626629998\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 26.228096961975\t\n",
       "Average Loss: 0.16037952564425\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 31.00887298584\t\n",
       "Average Loss: 0.1597093858762\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 25.062748908997\t\n",
       "Average Loss: 0.15915718304179\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 25.973461866379\t\n",
       "Average Loss: 0.15864680840978\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1839163119006\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 26.059950113297\t\n",
       "Average Loss: 0.15818557140883\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 25.154232025146\t\n",
       "Average Loss: 0.15776211477455\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 25.887181043625\t\n",
       "Average Loss: 0.15734244795882\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 27.179241895676\t\n",
       "Average Loss: 0.15696521569348\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 27.432199001312\t\n",
       "Average Loss: 0.15663540902626\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1824420394642\t\n"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 20\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 27.619936943054\t\n",
       "Average Loss: 0.15974601422568\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1855367178374\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 24.746417045593\t\n",
       "Average Loss: 0.15638448991217\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1824438751704\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 25.023906946182\t\n",
       "Average Loss: 0.15573398220736\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1819785736185\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 25.480671167374\t\n",
       "Average Loss: 0.15540230367625\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1813094890523\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 24.604247093201\t\n",
       "Average Loss: 0.15510953272084\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1811523704405\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 24.404500007629\t\n",
       "Average Loss: 0.15480920641107\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.180707110681\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 25.181984901428\t\n",
       "Average Loss: 0.15454848056418\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1808885187157\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 26.033724784851\t\n",
       "Average Loss: 0.15324498182009\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1788202946797\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 24.985551118851\t\n",
       "Average Loss: 0.15289153281754\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1785937593155\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 26.281076908112\t\n",
       "Average Loss: 0.15275839278728\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1785445168725\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 25.253405094147\t\n",
       "Average Loss: 0.15771314623241\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1839716613607\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 23.995304822922\t\n",
       "Average Loss: 0.15447399569549\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1807325957025\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 23.647886991501\t\n",
       "Average Loss: 0.15392232752519\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1804579521235\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 24.548258066177\t\n",
       "Average Loss: 0.15368239953165\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1801014532801\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 23.791232824326\t\n",
       "Average Loss: 0.15351510321408\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1804442996589\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 23.86344408989\t\n",
       "Average Loss: 0.15224096155613\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1786706140464\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 24.195983171463\t\n",
       "Average Loss: 0.15184575294419\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1785939836208\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 23.519762992859\t\n",
       "Average Loss: 0.15167006138082\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1785269433268\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 23.866048812866\t\n",
       "Average Loss: 0.15154694132977\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1784334320309\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 26.384864091873\t\n",
       "Average Loss: 0.15144445357836\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1783925081262\t\n"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600000\t\n"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = 30\n",
    "batch_size = 16\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)\n",
    "\n",
    "-- Building model\n",
    "batchGRU, params_gru, grad_params_gru = build_rnn(embed_dim, vocab_size, batch_size, build_GRU(embed_dim, len), len)\n",
    "batchGRU_valid, params_valid_gru, grad_params_valid_gru = build_rnn(embed_dim, vocab_size, 1,build_GRU(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 21.985914945602\t\n",
       "Average Loss: 0.34754894743853\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.822425127029\t\n",
       "Average Loss: 0.24662751444763\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.380235910416\t\n",
       "Average Loss: 0.22644992760149\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 20.386257171631\t\n",
       "Average Loss: 0.21586756464063\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 20.260949134827\t\n",
       "Average Loss: 0.20588786611453\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2267422844996\t\n"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning (remember changed position)\n",
    "nEpochs = 5\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchGRU, batchGRU_valid, params_valid_gru,\n",
    "        params_gru, grad_params_gru, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.033187150955\t\n",
       "Average Loss: 0.19548649256202\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.111010074615\t\n",
       "Average Loss: 0.18753432665153\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2088579236428\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.048751831055\t\n",
       "Average Loss: 0.18135815098318\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 19.980526924133\t\n",
       "Average Loss: 0.17843319981618\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2006284614829\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 22.001543998718\t\n",
       "Average Loss: 0.17582000858789\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 21.397794961929\t\n",
       "Average Loss: 0.17342742262632\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1953346338126\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 20.03279709816\t\n",
       "Average Loss: 0.17120608813403\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 21.058824062347\t\n",
       "Average Loss: 0.16911203085189\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1908863198291\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 19.768749952316\t\n",
       "Average Loss: 0.1671295096868\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 20.265580892563\t\n",
       "Average Loss: 0.16527202300677\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1871044336422\t\n"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning (remember changed position)\n",
    "nEpochs = 10\n",
    "step = 2\n",
    "train_model_with_perp(t_input_new, t_output_new, batchGRU, batchGRU_valid, params_valid_gru,\n",
    "        params_gru, grad_params_gru, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.54555106163\t\n",
       "Average Loss: 0.1644748422442\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.115912914276\t\n",
       "Average Loss: 0.1616761848937\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1840898392083\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 19.895653963089\t\n",
       "Average Loss: 0.15819938054031\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 21.474240064621\t\n",
       "Average Loss: 0.15682596094484\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1792869281535\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 20.169448137283\t\n",
       "Average Loss: 0.15560150461672\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 20.641898155212\t\n",
       "Average Loss: 0.15444937533606\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.177232832283\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 19.355062961578\t\n",
       "Average Loss: 0.1533688281671\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 20.005716085434\t\n",
       "Average Loss: 0.1523599688517\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1754881318031\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 20.25895690918\t\n",
       "Average Loss: 0.15141961276476\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 20.001791000366\t\n",
       "Average Loss: 0.15054239950379\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1739414781614\t\n"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning (remember changed position)\n",
    "nEpochs = 10\n",
    "step = 2\n",
    "train_model_with_perp(t_input_new, t_output_new, batchGRU, batchGRU_valid, params_valid_gru,\n",
    "        params_gru, grad_params_gru, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 21.13591504097\t\n",
       "Average Loss: 0.15102133170376\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.824810028076\t\n",
       "Average Loss: 0.14967832680039\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.17339501455\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.168252944946\t\n",
       "Average Loss: 0.14712340869834\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 19.862685918808\t\n",
       "Average Loss: 0.14634317440166\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1697229317069\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 20.198061943054\t\n",
       "Average Loss: 0.14568765712831\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 21.455843925476\t\n",
       "Average Loss: 0.14506850216721\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1684899324422\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 20.93475985527\t\n",
       "Average Loss: 0.14447676786644\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 23.790939092636\t\n",
       "Average Loss: 0.14390880808384\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1673607266979\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 20.453790903091\t\n",
       "Average Loss: 0.14336208173163\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 20.399837970734\t\n",
       "Average Loss: 0.14283445960168\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1663204973306\t\n"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning (remember changed position)\n",
    "nEpochs = 10\n",
    "step = 2\n",
    "train_model_with_perp(t_input_new, t_output_new, batchGRU, batchGRU_valid, params_valid_gru,\n",
    "        params_gru, grad_params_gru, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 22.13996386528\t\n",
       "Average Loss: 0.14379205863432\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.517323970795\t\n",
       "Average Loss: 0.14294781335128\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1665943843895\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.261568069458\t\n",
       "Average Loss: 0.14069050180087\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 20.730599880219\t\n",
       "Average Loss: 0.14011809222691\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1634903073514\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 21.100613117218\t\n",
       "Average Loss: 0.13965992055933\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 21.459497928619\t\n",
       "Average Loss: 0.13922807224974\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.162639710037\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 22.623461008072\t\n",
       "Average Loss: 0.13881433381805\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 19.699815988541\t\n",
       "Average Loss: 0.13841564025072\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1618228377842\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 19.508886098862\t\n",
       "Average Loss: 0.13803027044745\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 21.358961105347\t\n",
       "Average Loss: 0.13765702408165\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1610467126026\t\n"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning (remember changed position)\n",
    "nEpochs = 10\n",
    "step = 2\n",
    "train_model_with_perp(t_input_new, t_output_new, batchGRU, batchGRU_valid, params_valid_gru,\n",
    "        params_gru, grad_params_gru, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600000\t\n"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = 50\n",
    "batch_size = 16\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)\n",
    "\n",
    "-- Building model\n",
    "batchLTM, params_lstm, grad_params_lstm = build_rnn(embed_dim, vocab_size, batch_size, build_LSTM(embed_dim, len), len)\n",
    "batchLTM_valid, params_valid_lstm, grad_params_valid_lstm = build_rnn(embed_dim, vocab_size, 1,build_LSTM(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.500305175781\t\n",
       "Average Loss: 0.42686851261555\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 22.319206953049\t\n",
       "Average Loss: 0.26914507490737\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.252361059189\t\n",
       "Average Loss: 0.23543355068168\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 22.399124145508\t\n",
       "Average Loss: 0.22355271454239\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 22.436785936356\t\n",
       "Average Loss: 0.21356005534607\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2353700014788\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 5\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchLTM, batchLTM_valid, params_valid_lstm,\n",
    "        params_lstm, grad_params_lstm, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600320\t\n"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = 40\n",
    "batch_size = 16\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)\n",
    "\n",
    "-- Building model\n",
    "batchLTM, params_lstm, grad_params_lstm = build_rnn(embed_dim, vocab_size, batch_size, build_LSTM(embed_dim, len), len)\n",
    "batchLTM_valid, params_valid_lstm, grad_params_valid_lstm = build_rnn(embed_dim, vocab_size, 1,build_LSTM(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 21.371793031693\t\n",
       "Average Loss: 0.40999359046677\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.550037145615\t\n",
       "Average Loss: 0.26525554284651\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.77099609375\t\n",
       "Average Loss: 0.22752339722576\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 20.083611965179\t\n",
       "Average Loss: 0.21233982497507\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 20.474061965942\t\n",
       "Average Loss: 0.20172383091247\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2214339281157\t\n"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchLTM, batchLTM_valid, params_valid_lstm,\n",
    "        params_lstm, grad_params_lstm, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 22.699866771698\t\n",
       "Average Loss: 0.19419458614932\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.968109130859\t\n",
       "Average Loss: 0.18793614822398\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2091848838919\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.89581489563\t\n",
       "Average Loss: 0.18274775433131\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 20.497636079788\t\n",
       "Average Loss: 0.18005071151586\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2022368029729\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 21.626466989517\t\n",
       "Average Loss: 0.17758307255514\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 22.789066076279\t\n",
       "Average Loss: 0.17534566218807\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1973702355909\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 19.516790866852\t\n",
       "Average Loss: 0.17335061858939\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 18.870615959167\t\n",
       "Average Loss: 0.17155007475586\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1933553148268\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 19.937397003174\t\n",
       "Average Loss: 0.16989552580692\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 20.051936149597\t\n",
       "Average Loss: 0.16835741463583\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1898619072821\t\n"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchLTM, batchLTM_valid, params_valid_lstm,\n",
    "        params_lstm, grad_params_lstm, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.126780033112\t\n",
       "Average Loss: 0.16735650833021\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 19.257142066956\t\n",
       "Average Loss: 0.16495719005838\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1863063299435\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 19.587309122086\t\n",
       "Average Loss: 0.16227134233296\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 19.77908205986\t\n",
       "Average Loss: 0.16107603165942\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1820073811279\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 19.054136037827\t\n",
       "Average Loss: 0.16002025257414\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 19.094585895538\t\n",
       "Average Loss: 0.15902858172604\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1799882336849\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 20.017446994781\t\n",
       "Average Loss: 0.15808955162245\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 19.609482049942\t\n",
       "Average Loss: 0.15719549394668\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1782467302895\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 19.873846054077\t\n",
       "Average Loss: 0.15633938148774\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 19.472234964371\t\n",
       "Average Loss: 0.15551462341618\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1766833547014\t\n"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchLTM, batchLTM_valid, params_valid_lstm,\n",
    "        params_lstm, grad_params_lstm, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_probability_model(model, input)\n",
    "    return model:forward(input:view(input:size(1), 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Method to compute manually the perplexity\n",
    "function compute_perplexity(input, output, model)\n",
    "    -- Last Position filled in predictions\n",
    "    -- Position to predict in input\n",
    "    local position_input = 1\n",
    "    local probability = torch.DoubleTensor(2)\n",
    "    local probability_table\n",
    "    local perp = 0\n",
    "\n",
    "    -- Build mapping\n",
    "    for i = 1,input:size(1) do\n",
    "        -- Line where the model appears\n",
    "        -- The model remember the states before, just need to feed into it a character\n",
    "        probability_table = compute_probability_model(model, input:narrow(1,i,1))\n",
    "        probability:copy(probability_table[1])\n",
    "        perp = perp + probability[output[i]]\n",
    "    end\n",
    "    -- Cutting the output\n",
    "    return math.exp(-perp/input:size(1))\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 0.17292881011963\t\n",
       "1.2779225376256\t\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Computing perplexity\n",
    "timer = torch.Timer()\n",
    "size = input_data_train:size(1)\n",
    "perp = compute_perplexity(input_data_train:narrow(1,1,size):view(size,1), output_matrix_train:narrow(1,1,size), batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 2.5755980014801\t\n",
       "2.0049887210591\t\n"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Computing perplexity on valid\n",
    "timer = torch.Timer()\n",
    "--size = input_data_valid:size(1)\n",
    "size = 10000\n",
    "perp = compute_perplexity(input_data_valid:narrow(1,1,size):view(size,1), output_valid:narrow(1,1,size), batchLTM_valid)\n",
    "print('Time elasped : '..timer:time().real)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Prediction on test\n",
    "function predict_rnn_greedy(input, len, model)\n",
    "    -- Last Position filled in predictions\n",
    "    local position_prediction = 1\n",
    "    -- Position to predict in input\n",
    "    local position_input = 1\n",
    "    -- We allocate the maximum of memory that could be needed\n",
    "    -- Default value is -1 (to know where predictions end afterwards)\n",
    "    local predictions = torch.ones(2*input:size(1)):mul(-1)\n",
    "    -- Copy the first entry\n",
    "    predictions[position_prediction] = input[position_input]\n",
    "    local probability = torch.zeros(2)\n",
    "    local probability_table\n",
    "\n",
    "    -- Build mapping\n",
    "    while position_input < input:size(1) do\n",
    "        -- Line where the model appears\n",
    "        -- The model remember the states before, just need to feed into it a character\n",
    "        probability_table = compute_probability_model(model, predictions:narrow(1,position_prediction, 1))\n",
    "        probability:copy(probability_table[1])\n",
    "\n",
    "        m,a = probability:max(1)\n",
    "\n",
    "        -- Case space predicted\n",
    "        position_prediction = position_prediction +1\n",
    "        if (a[1] == 1) then\n",
    "            predictions[position_prediction] = 1\n",
    "        else\n",
    "            -- Copying next character\n",
    "            position_input = position_input + 1\n",
    "            predictions[position_prediction] = input[position_input] \n",
    "        end\n",
    "    end\n",
    "    -- Cutting the output\n",
    "    return predictions:narrow(1,1,position_prediction)\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_kaggle_format(predictions_test, N)\n",
    "    -- Counting sentences\n",
    "    local num_sentence = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_sentence = num_sentence + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    -- Counting space per sentence\n",
    "    local num_spaces = torch.DoubleTensor(num_sentence,2)\n",
    "    local row = 1\n",
    "    local count_space = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_spaces[{row, 1}] = row\n",
    "            num_spaces[{row, 2}] = count_space\n",
    "            count_space = 0\n",
    "            row = row + 1\n",
    "        elseif predictions_test[i] == 1 then\n",
    "            count_space = count_space + 1\n",
    "        end\n",
    "    end\n",
    "    return num_spaces\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_rmse(true_kaggle, pred_kaggle)\n",
    "    local rmse = 0\n",
    "    for i=1,true_kaggle:size(1) do\n",
    "        rmse = rmse + math.pow(true_kaggle[{i,2}] - pred_kaggle[{i,2}], 2)\n",
    "    end\n",
    "    return(math.sqrt(rmse/ true_kaggle:size(1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_true_valid = get_kaggle_format(input_data_valid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 24.515151023865\t\n"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = input_data_valid_nospace:size(1)\n",
    "pred_valid_lstm = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchLTM_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE LSTM after 25 epochs\t\n"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.4900644363655\t\n"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_lstm_valid = get_kaggle_format(pred_valid_lstm,2)\n",
    "print('RMSE LSTM after 25 epochs')\n",
    "rsme_lstm = compute_rmse(kaggle_true_valid, kaggle_lstm_valid)\n",
    "print(rsme_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 14.468178033829\t\n"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = input_data_valid_nospace:size(1)\n",
    "pred_valid_rnn = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE RNN\t\n"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.0739178179273\t\n"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_rnn_valid = get_kaggle_format(pred_valid_rnn,2)\n",
    "print('RMSE RNN')\n",
    "rsme_rnn = compute_rmse(kaggle_true_valid, kaggle_rnn_valid)\n",
    "print(rsme_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 31.173984050751\t\n"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = input_data_valid_nospace:size(1)\n",
    "pred_valid_gru = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchGRU_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE GRU\t\n"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.5130211165419\t\n"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_gru_valid = get_kaggle_format(pred_valid_gru,2)\n",
    "print('RMSE GRU')\n",
    "rsme_gru = compute_rmse(kaggle_true_valid, kaggle_gru_valid)\n",
    "print(rsme_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE ENSEMBLE\t\n"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.511174064807\t\n"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Ensemble combinations\n",
    "wgru = 26\n",
    "wrnn = 2\n",
    "wlstm = 0\n",
    "total = wgru + wrnn + wlstm\n",
    "kaggle_ensemble = (torch.mul(kaggle_gru_valid, wgru) + torch.mul(kaggle_rnn_valid, wrnn) + torch.mul(kaggle_lstm_valid, wlstm)):div(total)\n",
    "-- converting to int\n",
    "kaggle_ensemble:add(0.5):floor()\n",
    "print('RMSE ENSEMBLE')\n",
    "rsme_ensemble = compute_rmse(kaggle_true_valid, kaggle_ensemble)\n",
    "print(rsme_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sequences prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 92.837053060532\t\n"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Pred on test\n",
    "timer = torch.Timer()\n",
    "size = input_data_test:size(1)\n",
    "pred_test_gru = predict_rnn_greedy(input_data_test:narrow(1,1,size), len, batchGRU_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saaving test prediction\n",
    "kaggle_test = get_kaggle_format(pred_test_gru,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving the Kaggle format output\n",
    "myFile = hdf5.open('../submission/pred_gru_l30_b16_e45', 'w')\n",
    "myFile:write('num_spaces', kaggle_test)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
