{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_valid = data['input_data_valid']\n",
    "output_matrix_train = data['output_matrix_train']\n",
    "input_matrix_train = data['input_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "input_data_test = data['input_data_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 599903\n",
       "      1\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 599903\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       " 599905\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_matrix_train:size())\n",
    "print(output_matrix_train:size())\n",
    "print(input_data_train:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Formating the input\n",
    "-- input is a 1d tensor\n",
    "function get_train_input(input, len, batch_size)\n",
    "    -- Building output (we put predict a padding at the end)\n",
    "    local n = input:size(1)\n",
    "    \n",
    "    -- Get the closer multiple of batch_size*len below n\n",
    "    local factor = -math.floor(-n/(len*batch_size))\n",
    "    local n_new = factor*len*batch_size\n",
    "    local input_new = torch.DoubleTensor(n_new)\n",
    "    local t_input, t_output\n",
    "    input_new:narrow(1,1,n):copy(input)\n",
    "    input_new:narrow(1,n,n_new-n+1):fill(2) -- Filling with padding\n",
    "    \n",
    "    -- Building output\n",
    "    local output = torch.DoubleTensor(n_new)\n",
    "    for i=2, n_new do\n",
    "        if input_new[i] ~= 1 then\n",
    "            output[i-1] = 2\n",
    "        else\n",
    "            output[i-1] = input_new[i]\n",
    "        end\n",
    "    end\n",
    "    output[n_new] = 2\n",
    "\n",
    "    -- Issue with last sequence if batch_size does not divide n\n",
    "    t_input = torch.split(input_new:view(batch_size,n_new/batch_size),len, 2)\n",
    "    t_output = torch.split(output:view(batch_size,n_new/batch_size),len, 2)\n",
    "    return t_input, t_output\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_RNN(embed_dim, rho)\n",
    "    return nn.Recurrent(embed_dim, nn.Linear(embed_dim, embed_dim),nn.Linear(embed_dim, embed_dim), nn.Tanh(), rho)\n",
    "end\n",
    "\n",
    "function build_LSTM(embed_dim, rho)\n",
    "    return nn.FastLSTM(embed_dim, embed_dim, rho)\n",
    "end\n",
    "\n",
    "function build_GRU(embed_dim, rho, dropout_p)\n",
    "    return nn.GRU(embed_dim, embed_dim, rho,dropout_p)\n",
    "end\n",
    "\n",
    "function build_rnn(embed_dim, vocab_size, batch_size, recurrent_model, len)\n",
    "    local batchRNN\n",
    "    local params\n",
    "    local grad_params\n",
    "    -- generic RNN transduced\n",
    "    batchRNN = nn.Sequential()\n",
    "        :add(nn.LookupTable(vocab_size, embed_dim))\n",
    "        :add(nn.SplitTable(1, batch_size))\n",
    "    batchRNN:add(nn.Sequencer(recurrent_model))\n",
    "\n",
    "    -- Output\n",
    "    batchRNN:add(nn.Sequencer(nn.Linear(embed_dim, 2)))\n",
    "    batchRNN:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "    batchRNN:remember('both')\n",
    "\n",
    "    -- Retrieve parameters (To do only once!!!)\n",
    "    params, grad_params = batchRNN:getParameters()\n",
    "    -- Initializing all the parameters between -0.05 and 0.05\n",
    "    for k=1,params:size(1) do\n",
    "        params[k] = torch.uniform(-0.05,0.05)\n",
    "    end\n",
    "    \n",
    "    return batchRNN, params, grad_params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Building output valid matrix\n",
    "output_valid = torch.DoubleTensor(input_data_valid:size(1))\n",
    "for i=2, input_data_valid:size(1) do\n",
    "    if input_data_valid[i] ~= 1 then\n",
    "        output_valid[i-1] = 2\n",
    "    else\n",
    "        output_valid[i-1] = input_data_valid[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_lstm(embed_dim, vocab_size, batch_size)\n",
    "    local batchRNN\n",
    "    local params\n",
    "    local grad_params\n",
    "    -- Fast LSTM\n",
    "    batchRNN = nn.Sequential()\n",
    "        :add(nn.LookupTable(vocab_size, embed_dim))\n",
    "        :add(nn.SplitTable(1, batch_size))\n",
    "    batchRNN:add(nn.Sequencer((nn.FastLSTM(embed_dim, embed_dim))))\n",
    "    -- Output\n",
    "    batchRNN:add(nn.Sequencer(nn.Linear(embed_dim, 2)))\n",
    "    batchRNN:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "    batchRNN:remember('both')\n",
    "    \n",
    "    return batchRNN\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train_model(t_input, t_output, model, params, grad_params,\n",
    "                     criterion, eta, nEpochs, batch_size, len, n)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    local timer\n",
    "    local pred\n",
    "    local loss\n",
    "    local dLdPred\n",
    "    local t_inputT = torch.DoubleTensor(len,batch_size)\n",
    "    local t_output_table\n",
    "    local delta = 0.2\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        old_L = av_L\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for k = 1, n/(batch_size * len) do\n",
    "            -- Mini batch data\n",
    "                \n",
    "            t_inputT:copy(t_input[k]:t())\n",
    "            t_output_table = torch.split(t_output[k],1,2)\n",
    "            --format the output\n",
    "            for j=1,len do\n",
    "                t_output_table[j] = t_output_table[j]:squeeze()\n",
    "            end \n",
    "            \n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            \n",
    "            -- Forward loop\n",
    "            pred = model:forward(t_inputT)\n",
    "            loss = criterion:forward(pred, t_output_table)\n",
    "            av_L = av_L + loss\n",
    "\n",
    "            -- Backward loop\n",
    "            dLdPred = criterion:backward(pred, t_output_table)\n",
    "            model:backward(t_inputT, dLdPred)\n",
    "            \n",
    "            -- gradient normalization with max norm 5 (l2 norm)\n",
    "            grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(n/batch_size))\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if (old_L - av_L) < delta then\n",
    "        eta = eta/2\n",
    "        delta = delta/2\n",
    "    end\n",
    "    \n",
    "    if (eta < 0.001) then eta = 0.1 end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train_model_with_perp(t_input, t_output, model, model_flattened, params_flattened,\n",
    "        params, grad_params, criterion, eta, nEpochs, batch_size, len, n, input_valid, output_valid, step)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    local timer\n",
    "    local pred\n",
    "    local loss\n",
    "    local dLdPred\n",
    "    local t_inputT = torch.DoubleTensor(len,batch_size)\n",
    "    local t_output_table\n",
    "    local delta = 0.2\n",
    "    local size\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "    local perp = 0\n",
    "    local old_perp = 0\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        old_L = av_L\n",
    "        old_perp = perp\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for k = 1, n/(batch_size * len) do\n",
    "            -- Mini batch data\n",
    "                \n",
    "            t_inputT:copy(t_input[k]:t())\n",
    "            t_output_table = torch.split(t_output[k],1,2)\n",
    "            --format the output\n",
    "            for j=1,len do\n",
    "                t_output_table[j] = t_output_table[j]:squeeze()\n",
    "            end \n",
    "            \n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            \n",
    "            -- Forward loop\n",
    "            pred = model:forward(t_inputT)\n",
    "            loss = criterion:forward(pred, t_output_table)\n",
    "            av_L = av_L + loss\n",
    "\n",
    "            -- Backward loop\n",
    "            dLdPred = criterion:backward(pred, t_output_table)\n",
    "            model:backward(t_inputT, dLdPred)\n",
    "            \n",
    "            -- gradient normalization with max norm 5 (l2 norm)\n",
    "            grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(n/batch_size))\n",
    "        -- Print perplexity validity every step of iteration\n",
    "        if (i%step == 0) then\n",
    "            size = input_valid:size(1) - 1\n",
    "            params_flattened:copy(params)\n",
    "            perp = compute_perplexity(input_valid:narrow(1,1,size):view(size,1), output_valid, model_flattened)\n",
    "            print('Valid perplexity: '..perp)\n",
    "            \n",
    "            if math.abs(old_perp - perp) < delta then\n",
    "                eta = eta/2\n",
    "                delta = delta/2\n",
    "            end\n",
    "\n",
    "            if (eta < 0.0001) then eta = 0.1 end\n",
    "\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, len)\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1, len)\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.8074369430542\t\n",
       "Average Loss: 0.31228050204274\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.7043259143829\t\n",
       "Average Loss: 0.26151257461365\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.2467911243439\t\n",
       "Average Loss: 0.23146731025455\t\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 3\n",
    "train_model(t_input, t_output, batchRNN, params, grad_params,\n",
    "                     crit, eta, nEpochs, batch_size, len, n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.0373430252075\t\n",
       "Average Loss: 0.31127603024063\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.3167066034457\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.0228929519653\t\n",
       "Average Loss: 0.2595806616951\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.272589419065\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.0724031925201\t\n",
       "Average Loss: 0.23316074090171\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2505899734403\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.7879350185394\t\n",
       "Average Loss: 0.21455134532284\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2305572804994\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.1380410194397\t\n",
       "Average Loss: 0.20159015092112\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2191191235031\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.0522859096527\t\n",
       "Average Loss: 0.19299361409045\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2106942406731\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.0655410289764\t\n",
       "Average Loss: 0.18630843005958\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.2040019027776\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.0618779659271\t\n",
       "Average Loss: 0.18083623497307\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1988415676649\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.0254361629486\t\n",
       "Average Loss: 0.17666558202226\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1948545425466\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.0559229850769\t\n",
       "Average Loss: 0.17341161985071\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.191752075552\t\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.1608598232269\t\n",
       "Average Loss: 0.17066010915357\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1893514698956\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.0460610389709\t\n",
       "Average Loss: 0.16842283821082\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1876828130608\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.1154489517212\t\n",
       "Average Loss: 0.16659270468897\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1864067460075\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.0670311450958\t\n",
       "Average Loss: 0.16518998250815\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1853287486702\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.1075801849365\t\n",
       "Average Loss: 0.16408510411659\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1845620295284\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.3404068946838\t\n",
       "Average Loss: 0.16316840120459\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1840970283144\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.0670158863068\t\n",
       "Average Loss: 0.16239600637254\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1837860540369\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.0414438247681\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss: 0.16169741966653\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1833747002796\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.0382349491119\t\n",
       "Average Loss: 0.16102260010531\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1828553687182\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.026673078537\t\n",
       "Average Loss: 0.16036868317739\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1826217175028\t\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 6.1355979442596\t\n",
       "Average Loss: 0.15972079728122\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1824428813963\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.4839720726013\t\n",
       "Average Loss: 0.15909980418245\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.182109999531\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.2839608192444\t\n",
       "Average Loss: 0.15852116560753\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.181668471896\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.2338001728058\t\n",
       "Average Loss: 0.15796460040097\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1811241082699\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.8121101856232\t\n",
       "Average Loss: 0.15744148391804\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1806673353204\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.2398941516876\t\n",
       "Average Loss: 0.15692715807122\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1801969411692\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.1931447982788\t\n",
       "Average Loss: 0.15642420072222\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1797258097392\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.2221410274506\t\n",
       "Average Loss: 0.15592075426583\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1796751236756\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.2164981365204\t\n",
       "Average Loss: 0.15546064818585\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.179654980452\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.8618688583374\t\n",
       "Average Loss: 0.15505075502542\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Valid perplexity: 1.1795317990726\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nEpochs = 10\n",
    "train_model_with_perp(t_input, t_output, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n, input_data_valid, output_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input size is 600320\t\n"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len = 40\n",
    "batch_size = 16\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)\n",
    "\n",
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, batch_size, build_RNN(embed_dim, len), len)\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1,build_RNN(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 7.482204914093\t\n",
       "Average Loss: 0.29908019873378\t\n"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Adaptive learning rate\n",
    "nEpochs = 10\n",
    "step = 1\n",
    "train_model_with_perp(t_input_new, t_output_new, batchRNN, batchRNN_valid, params_valid,\n",
    "        params, grad_params, crit, eta, nEpochs, batch_size, len, n_new, input_data_valid, output_valid, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len = 60\n",
    "batch_size = 16\n",
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 40\n",
    "\n",
    "t_input_new, t_output_new = get_train_input(input_data_train, len, batch_size)\n",
    "n_new = len * batch_size *(#t_input_new)\n",
    "print('Input size is '..n_new)\n",
    "\n",
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, batch_size, build_GRU(embed_dim, len), len)\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1,build_GRU(embed_dim))\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_probability_model(model, input)\n",
    "    return model:forward(input:view(input:size(1), 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Method to compute manually the perplexity\n",
    "function compute_perplexity(input, output, model)\n",
    "    -- Last Position filled in predictions\n",
    "    -- Position to predict in input\n",
    "    local position_input = 1\n",
    "    local probability = torch.DoubleTensor(2)\n",
    "    local probability_table\n",
    "    local perp = 0\n",
    "\n",
    "    -- Build mapping\n",
    "    for i = 1,input:size(1) do\n",
    "        -- Line where the model appears\n",
    "        -- The model remember the states before, just need to feed into it a character\n",
    "        probability_table = compute_probability_model(model, input:narrow(1,i,1))\n",
    "        probability:copy(probability_table[1])\n",
    "        perp = perp + probability[output[i]]\n",
    "    end\n",
    "    -- Cutting the output\n",
    "    return math.exp(-perp/input:size(1))\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 0.17292881011963\t\n",
       "1.2779225376256\t\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Computing perplexity\n",
    "timer = torch.Timer()\n",
    "size = input_data_train:size(1)\n",
    "perp = compute_perplexity(input_data_train:narrow(1,1,size):view(size,1), output_matrix_train:narrow(1,1,size), batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 0.15830206871033\t\n",
       "1.2654810365825\t\n"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Computing perplexity on valid\n",
    "timer = torch.Timer()\n",
    "--size = input_data_valid:size(1)\n",
    "size = 1000\n",
    "perp = compute_perplexity(input_data_valid:narrow(1,1,size):view(size,1), output_valid:narrow(1,1,size), batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Prediction on test\n",
    "function predict_rnn_greedy(input, len, model)\n",
    "    -- Last Position filled in predictions\n",
    "    local position_prediction = 1\n",
    "    -- Position to predict in input\n",
    "    local position_input = 1\n",
    "    -- We allocate the maximum of memory that could be needed\n",
    "    -- Default value is -1 (to know where predictions end afterwards)\n",
    "    local predictions = torch.ones(2*input:size(1)):mul(-1)\n",
    "    -- Copy the first entry\n",
    "    predictions[position_prediction] = input[position_input]\n",
    "    local probability = torch.zeros(2)\n",
    "    local probability_table\n",
    "\n",
    "    -- Build mapping\n",
    "    while position_input < input:size(1) do\n",
    "        -- Line where the model appears\n",
    "        -- The model remember the states before, just need to feed into it a character\n",
    "        probability_table = compute_probability_model(model, predictions:narrow(1,position_prediction, 1))\n",
    "        probability:copy(probability_table[1])\n",
    "\n",
    "        m,a = probability:max(1)\n",
    "\n",
    "        -- Case space predicted\n",
    "        position_prediction = position_prediction +1\n",
    "        if (a[1] == 1) then\n",
    "            predictions[position_prediction] = 1\n",
    "        else\n",
    "            -- Copying next character\n",
    "            position_input = position_input + 1\n",
    "            predictions[position_prediction] = input[position_input] \n",
    "        end\n",
    "    end\n",
    "    -- Cutting the output\n",
    "    return predictions:narrow(1,1,position_prediction)\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 13.989942073822\t\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = input_data_valid_nospace:size(1)\n",
    "pred_valid = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 56.393217802048\t\n"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Pred on test\n",
    "timer = torch.Timer()\n",
    "size = input_data_test:size(1)\n",
    "pred_test = predict_rnn_greedy(input_data_test:narrow(1,1,size), len, batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 38.907659053802\t\n"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = input_data_valid_nospace:size(1)\n",
    "pred_valid_lstm = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batch_lsm)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_kaggle_format(predictions_test, N)\n",
    "    -- Counting sentences\n",
    "    local num_sentence = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_sentence = num_sentence + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    -- Counting space per sentence\n",
    "    local num_spaces = torch.DoubleTensor(num_sentence,2)\n",
    "    local row = 1\n",
    "    local count_space = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_spaces[{row, 1}] = row\n",
    "            num_spaces[{row, 2}] = count_space\n",
    "            count_space = 0\n",
    "            row = row + 1\n",
    "        elseif predictions_test[i] == 1 then\n",
    "            count_space = count_space + 1\n",
    "        end\n",
    "    end\n",
    "    return num_spaces\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_rmse(true_kaggle, pred_kaggle)\n",
    "    local rmse = 0\n",
    "    for i=1,true_kaggle:size(1) do\n",
    "        rmse = rmse + math.pow(true_kaggle[{i,2}] - pred_kaggle[{i,2}], 2)\n",
    "    end\n",
    "    return(math.sqrt(rmse/ true_kaggle:size(1)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_true_valid = get_kaggle_format(input_data_valid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE RNN\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4.2979129688982\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_rnn_valid = get_kaggle_format(pred_valid,2)\n",
    "print('RMSE RNN')\n",
    "rsme_rnn = compute_rmse(kaggle_true_valid, kaggle_rnn_valid)\n",
    "print(rsme_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE LSTM\t\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.3705971151496\t\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_lstm_valid = get_kaggle_format(pred_valid_lstm,2)\n",
    "print('RMSE LSTM')\n",
    "rsme_rnn = compute_rmse(kaggle_true_valid, kaggle_lstm_valid)\n",
    "print(rsme_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saaving test prediction\n",
    "kaggle_test = get_kaggle_format(pred_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving the Kaggle format output\n",
    "myFile = hdf5.open('../submission/pred_rnn_50_16', 'w')\n",
    "myFile:write('num_spaces', kaggle_test)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
