{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  H5Z_FILTER_CONFIG_ENCODE_ENABLED : 1\n",
       "  H5F_ACC_RDWR : 1\n",
       "  _getTorchType : function: 0x0e27b0c0\n",
       "  H5F_OBJ_FILE : 1\n",
       "  H5S_ALL : 0\n",
       "  H5F_OBJ_GROUP : 4\n",
       "  C : userdata: 0x0e660ee0\n",
       "  H5P_DEFAULT : 0\n",
       "  _describeObject : function: 0x0e65fc48\n",
       "  H5Z_FILTER_NBIT : 5\n",
       "  _debugMode : false\n",
       "  _getObjectType : function: 0x0e6604b0\n",
       "  H5F_OBJ_ALL : 31\n",
       "  _getObjectName : function: 0x0e305480\n",
       "  version : \n",
       "    {\n",
       "      1 : 1\n",
       "  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "    2 : 8\n",
       "      3 : 15\n",
       "    }\n",
       "  H5Z_FILTER_SHUFFLE : 2\n",
       "  HDF5Group : table: 0x0e288838\n",
       "  open : function: 0x0e2e2738\n",
       "  H5Z_FILTER_SZIP : 4\n",
       "  H5F_OBJ_ATTR : 16\n",
       "  H5Z_FILTER_FLETCHER32 : 3\n",
       "  H5F_OBJ_DATATYPE : 8\n",
       "  debugMode : function: 0x0e2f8610\n",
       "  H5F_ACC_EXCL : 4\n",
       "  H5Z_FILTER_NONE : 0\n",
       "  _testUtils : \n",
       "    {\n",
       "      deepAlmostEq : function: 0x0e2f85d0\n",
       "      withTmpDir : function: 0x0e2f8530\n",
       "    }\n",
       "  _nativeTypeForTensorType : function: 0x0e25b320\n",
       "  H5F_ACC_TRUNC : 2\n",
       "  _config : \n",
       "    {\n",
       "      HDF5_INCLUDE_PATH : /Users/nicolasdrizard/anaconda/include\n",
       "      HDF5_LIBRARIES : /Users/nicolasdrizard/anaconda/lib/libhdf5.dylib;/Users/nicolasdrizard/anaconda/lib/libhdf5_hl.dylib;/Users/nicolasdrizard/anaconda/lib/libhdf5.dylib;/Users/nicolasdrizard/anaconda/lib/libz.dylib;/usr/lib/libdl.dylib;/usr/lib/libm.dylib\n",
       "    }\n",
       "  _loadObject : function: 0x0e2e2718\n",
       "  DataSetOptions : table: 0x0e2b5940\n",
       "  HDF5DataSet : table: 0x0e293cf0\n",
       "  H5Z_FILTER_RESERVED : 256\n",
       "  _logger : \n",
       "    {\n",
       "      error : function: 0x0e2ffcf8\n",
       "      warn : function: 0x0e2ffcf8\n",
       "      debug : function: 0x0e2ffd40\n",
       "    }\n",
       "  H5F_ACC_RDONLY : 0\n",
       "  _fletcher32Available : function: 0x0e65c038\n",
       "  H5Z_FILTER_CONFIG_DECODE_ENABLED : 2\n",
       "  ffi : \n",
       "    {\n",
       "      abi : function: builtin#202\n",
       "      copy : function: builtin#200\n",
       "      errno : function: builtin#198\n",
       "      typeinfo : function: builtin#193\n",
       "      alignof : function: builtin#196\n",
       "      cdef : function: builtin#189\n",
       "      C : userdata: 0x0de7fb38\n",
       "      cast : function: builtin#191\n",
       "      load : function: builtin#205\n",
       "      offsetof : function: builtin#197\n",
       "      sizeof : function: builtin#195\n",
       "      string : function: builtin#199\n",
       "      metatype : function: builtin#203\n",
       "      new : function: builtin#190\n",
       "      arch : x64\n",
       "      os : OSX\n",
       "      gc : function: builtin#204\n",
       "      fill : function: builtin#201\n",
       "      istype : function: builtin#194\n",
       "      typeof : function: builtin#192\n",
       "    }\n",
       "  H5Z_FILTER_ERROR : -1\n",
       "  _outputTypeForTensorType : function: 0x0e25b2d8\n",
       "  H5Z_FILTER_MAX : 65535\n",
       "  h5t : \n",
       "    {\n",
       "      STD_B32LE : 50331728\n",
       "      IEEE_F32BE : 50331703\n",
       "      NATIVE_B16 : 50331694\n",
       "      NATIVE_HSIZE : 50331698\n",
       "      NO_CLASS : -1\n",
       "      NATIVE_UINT_FAST32 : 50331681\n",
       "      STD_B8LE : 50331724\n",
       "      STD_I64BE : 50331715\n",
       "      NATIVE_LONG : 50331662\n",
       "      NATIVE_DOUBLE : 50331691\n",
       "      TIME : 2\n",
       "      NATIVE_INT16 : 50331670\n",
       "      NATIVE_LLONG : 50331688\n",
       "      STD_I8BE : 50331709\n",
       "      STD_B64LE : 50331730\n",
       "      NATIVE_HSSIZE : 50331699\n",
       "      STD_B32BE : 50331729\n",
       "      INTEGER : 0\n",
       "      NATIVE_INT64 : 50331682\n",
       "      STD_I8LE : 50331708\n",
       "      STD_I32LE : 50331712\n",
       "      NATIVE_SCHAR : 50331656\n",
       "      NATIVE_INT_FAST16 : 50331674\n",
       "      NATIVE_INT : 50331660\n",
       "      BITFIELD : 4\n",
       "      NATIVE_UINT_LEAST16 : 50331673\n",
       "      NATIVE_INT_LEAST16 : 50331672\n",
       "      IEEE_F64LE : 50331704\n",
       "    "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  NATIVE_INT_FAST64 : 50331686\n",
       "      NATIVE_UINT_FAST64 : 50331687\n",
       "      NATIVE_UINT_LEAST64 : 50331685\n",
       "      NATIVE_INT_LEAST64 : 50331684\n",
       "      ENUM : 8\n",
       "      NATIVE_UINT64 : 50331683\n",
       "      NATIVE_HBOOL : 50331701\n",
       "      NATIVE_ULONG : 50331663\n",
       "      NATIVE_INT_FAST32 : 50331680\n",
       "      NATIVE_HADDR : 50331697\n",
       "      NATIVE_UINT : 50331661\n",
       "      NCLASSES : 11\n",
       "      NATIVE_UINT_LEAST32 : 50331679\n",
       "      NATIVE_INT_LEAST32 : 50331678\n",
       "      STD_U64LE : 50331722\n",
       "      NATIVE_UINT32 : 50331677\n",
       "      NATIVE_SHORT : 50331658\n",
       "      NATIVE_INT32 : 50331676\n",
       "      VLEN : 9\n",
       "      ARRAY : 10\n",
       "      STD_U16LE : 50331718\n",
       "      STD_B16LE : 50331726\n",
       "      STD_I64LE : 50331714\n",
       "      NATIVE_UINT16 : 50331671\n",
       "      NATIVE_UINT_FAST8 : 50331669\n",
       "      STD_B16BE : 50331727\n",
       "      NATIVE_INT_FAST8 : 50331668\n",
       "      FLOAT : 1\n",
       "      REFERENCE : 7\n",
       "      STD_U32LE : 50331720\n",
       "      NATIVE_USHORT : 50331659\n",
       "      NATIVE_ULLONG : 50331689\n",
       "      NATIVE_INT8 : 50331664\n",
       "      IEEE_F32LE : 50331702\n",
       "      STD_U8BE : 50331717\n",
       "      NATIVE_INT_LEAST8 : 50331666\n",
       "      NATIVE_UINT8 : 50331665\n",
       "      NATIVE_B32 : 50331695\n",
       "      NATIVE_HERR : 50331700\n",
       "      NATIVE_OPAQUE : 50331736\n",
       "      NATIVE_LDOUBLE : 50331692\n",
       "      NATIVE_UINT_LEAST8 : 50331667\n",
       "      COMPOUND : 6\n",
       "      STD_REF_OBJ : 50331739\n",
       "      NATIVE_UINT_FAST16 : 50331675\n",
       "      NATIVE_B64 : 50331696\n",
       "      STD_U16BE : 50331719\n",
       "      STD_REF_DSETREG : 50331740\n",
       "      NATIVE_B8 : 50331693\n",
       "      STD_I32BE : 50331713\n",
       "      IEEE_F64BE : 50331705\n",
       "      NATIVE_FLOAT : 50331690\n",
       "      NATIVE_UCHAR : 50331657\n",
       "      STD_U32BE : 50331721\n",
       "      OPAQUE : 5\n",
       "  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "    STD_B64BE : 50331731\n",
       "      STD_U8LE : 50331716\n",
       "      STD_I16BE : 50331711\n",
       "      STD_B8BE : 50331725\n",
       "      STRING : 3\n",
       "      STD_I16LE : 50331710\n",
       "      STD_U64BE : 50331723\n",
       "    }\n",
       "  HDF5File : table: 0x0e2cfbc0\n",
       "  H5Z_FILTER_SCALEOFFSET : 6\n",
       "  H5Z_FILTER_DEFLATE : 1\n",
       "  H5F_ACC_CREAT : 16\n",
       "  H5F_UNLIMITED : 18446744073709551615ULL\n",
       "  _deflateAvailable : function: 0x0e2c6ff8\n",
       "  _inDebugMode : function: 0x0e2f8650\n",
       "  H5F_OBJ_LOCAL : 32\n",
       "  H5S_SELECT_SET : 0\n",
       "  _datatypeName : function: 0x0e2c70d0\n",
       "  H5F_ACC_DEBUG : 8\n",
       "  H5F_OBJ_DATASET : 2\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Probability Computation with Greedy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_F_count(F, N)\n",
    "    -- Build the mapping from (N-1)gram to row index\n",
    "    -- and the count matrix F_count: (num_context, 2)\n",
    "    local ngram_to_ind = {}\n",
    "    local key\n",
    "    for i=1,F:size(1) do\n",
    "        key = tostring(F[{i,1}])\n",
    "        -- Building key\n",
    "        for k = 2,N-1 do\n",
    "            key = key .. '-' .. tostring(F[{i,k}])\n",
    "        end\n",
    "        ngram_to_ind[key] = i\n",
    "    end\n",
    "    return F:narrow(2,N,2), ngram_to_ind\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_perplexity(gram_input, F_count, ngram_to_ind, N)\n",
    "    -- Compute perplexity on entry with space\n",
    "    local perp = 0\n",
    "    local context = torch.zeros(N-1)\n",
    "    local probability = torch.zeros(2)\n",
    "    -- Do not predict for the last char\n",
    "    --for i=1,gram_input:size(1)-N do\n",
    "    local size=gram_input:size(1) - (N-1)\n",
    "    for i=1,size do\n",
    "        context:copy(gram_input:narrow(1,i,N-1))\n",
    "        -- Line where the model appears\n",
    "        probability:copy(compute_count_based_probability(context, F_count, ngram_to_ind, 1))\n",
    "        if gram_input[i+(N-1)] == 1 then\n",
    "            right_proba = probability[1]\n",
    "            --print('space')\n",
    "            --print(right_proba)\n",
    "        else\n",
    "            right_proba = probability[2]\n",
    "        end\n",
    "        perp = perp + math.log(right_proba)\n",
    "    end\n",
    "    perp = math.exp(-perp/size)\n",
    "    --perp = math.exp(-perp/(gram_input:size(1)-N))\n",
    "    return perp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train\t\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.3967959853446\t\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train')\n",
    "print(compute_perplexity(input_data_train, F_count, ngram_to_ind, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Compute proba distribution over (space, char) for the context\n",
    "-- F is here the count matrix (num_context, 2)\n",
    "function compute_count_based_probability(context, F_count, ngram_to_ind, alpha)\n",
    "    local probability = torch.zeros(2)\n",
    "    -- Building key, ie (N-1)gram (from i to i+(N-2))\n",
    "    local key = tostring(context[1])\n",
    "    for k = 2,context:size(1) do\n",
    "        key = key .. '-' .. tostring(context[k])\n",
    "    end\n",
    "    -- If (N-1)gram never seen, prior distribution\n",
    "    if (ngram_to_ind[key] ~= nil) then\n",
    "        -- index of the current (n-1)gram in the F matrix\n",
    "        local index = ngram_to_ind[key]\n",
    "        probability:copy(F_count:narrow(1,index,1))\n",
    "        -- Adding smoothing\n",
    "        probability:add(alpha)\n",
    "    -- Case unseen context\n",
    "    else\n",
    "        -- Prior\n",
    "        probability:copy(torch.DoubleTensor({F_count:narrow(2,1,1):sum(), F_count:narrow(2,2,1):sum()}))\n",
    "    end\n",
    "    return probability:div(probability:sum())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict_count_based_greedy(gram_input, F_count, ngram_to_ind, N)\n",
    "    -- Next Position to fill in predictions\n",
    "    local position = N\n",
    "    -- We allocate the maximum of memory that could be needed\n",
    "    -- Default value is -1 (to know where predictions end afterwards)\n",
    "    local predictions = torch.ones(2*(gram_input:size(1) - N)):mul(-1)\n",
    "    -- Copy the first (N-1) gram\n",
    "    predictions:narrow(1,1,N-1):copy(gram_input:narrow(1,1,N-1))\n",
    "    local probability = torch.zeros(2)\n",
    "    local context = torch.zeros(N-1)\n",
    "\n",
    "    -- Build mapping\n",
    "    for i=1,gram_input:size(1)-N do\n",
    "        -- Compute proba for next char\n",
    "        context:copy(predictions:narrow(1,position-(N-1),N-1))\n",
    "        -- Line where the model appears\n",
    "        probability:copy(compute_count_based_probability(context, F_count, ngram_to_ind, 1))\n",
    "        m,a = probability:max(1)\n",
    "\n",
    "        -- Case space predicted\n",
    "        if (a[1] == 1) then\n",
    "            predictions[position] = 1\n",
    "            position = position +1\n",
    "        end\n",
    "\n",
    "        -- Copying next character\n",
    "        predictions[position] = gram_input[i+N-1]\n",
    "        position = position +1\n",
    "    end\n",
    "    -- Adding last character (</s>)\n",
    "    predictions[position] = gram_input[gram_input:size(1)]\n",
    "    -- Cutting the output\n",
    "    return predictions:narrow(1,1,position)\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/5-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_valid = data['input_data_valid']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "input_data_test = data['input_data_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_count, ngram_to_ind = get_F_count(F_train, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100961\t\n",
       "498942\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(F_count:narrow(2,1,1):sum())\n",
    "print(F_count:narrow(2,2,1):sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "gram_input_no_space = input_data_valid_nospace\n",
    "predictions_new = predict_count_based_greedy(gram_input_no_space, F_count, ngram_to_ind, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\t\n",
       "Train\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.3967959853446\t\n",
       "Valid\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4000666169436\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3\t\n",
       "Train\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.2680508928739\t\n",
       "Valid\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.2728844305488\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4\t\n",
       "Train\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1791804874081\t\n",
       "Valid\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1872601167372\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5\t\n",
       "Train\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1467907206376\t\n",
       "Valid\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1643258177066\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6\t\n",
       "Train\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1618916590178\t\n",
       "Valid\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.1911975320322\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for N=2,6 do\n",
    "    myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "    data = myFile:all()\n",
    "    F_train = data['F_train']\n",
    "    input_data_valid = data['input_data_valid']\n",
    "    input_data_train = data['input_data_train']\n",
    "    input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "    myFile:close()\n",
    "\n",
    "    F_count, ngram_to_ind = get_F_count(F_train, N)\n",
    "    print(N)\n",
    "    print('Train')\n",
    "    print(compute_perplexity(input_data_train, F_count, ngram_to_ind, N))\n",
    "    print('Valid')\n",
    "    print(compute_perplexity(input_data_valid, F_count, ngram_to_ind, N))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Kaggle Prediction\n",
    "N = 5\n",
    "\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_test = data['input_data_test']\n",
    "input_data_valid = data['input_data_valid']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "myFile:close()\n",
    "\n",
    "F_count, ngram_to_ind = get_F_count(F_train, N)\n",
    "predictions_test = predict_count_based_greedy(input_data_test, F_count, ngram_to_ind, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2\n",
       "[torch.LongTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_test:narrow(1,input_data_test:size(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_kaggle_format(predictions_test, N)\n",
    "    -- Counting sentences\n",
    "    local num_sentence = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_sentence = num_sentence + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    -- Counting space per sentence\n",
    "    local num_spaces = torch.DoubleTensor(num_sentence,2)\n",
    "    local row = 1\n",
    "    local count_space = 0\n",
    "    for i=N-1,predictions_test:size(1) do\n",
    "        if predictions_test[i] == 2 then\n",
    "            num_spaces[{row, 1}] = row\n",
    "            num_spaces[{row, 2}] = count_space\n",
    "            count_space = 0\n",
    "            row = row + 1\n",
    "        elseif predictions_test[i] == 1 then\n",
    "            count_space = count_space + 1\n",
    "        end\n",
    "    end\n",
    "    return num_spaces\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_spaces = get_kaggle_format(predictions_test, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Saving the Kaggle format output\n",
    "myFile = hdf5.open('../submission/pred_test_greedi_count_5', 'w')\n",
    "myFile:write('num_spaces', num_spaces)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Viterbi coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- In pi matrix col1: space; col2: char\n",
    "\n",
    "function predict_count_based_viterbi(gram_input, F_count, ngram_to_ind, N)\n",
    "    -- Backpointer\n",
    "    local score\n",
    "    local bp = torch.zeros(gram_input:size(1) + 1, 2)\n",
    "    local context = torch.DoubleTensor(1)\n",
    "    local y_hat = torch.DoubleTensor(2)\n",
    "    local pi = torch.ones(gram_input:size(1) + 1, 2):mul(-9999)\n",
    "    -- Initialization\n",
    "    pi[{1,1}] = 0\n",
    "    -- i is shifted\n",
    "    for i=2,gram_input:size(1)+1 do\n",
    "        for c_prev =1,2 do\n",
    "            -- Precompute y_hat(c_prev)\n",
    "            if c_prev == 1 then\n",
    "                context[1] = c_prev\n",
    "            else\n",
    "                context[1] = gram_input[i-1]\n",
    "            end\n",
    "            -- Line where the model appears\n",
    "            y_hat:copy(compute_probability(context, F_count, ngram_to_ind, 1))\n",
    "\n",
    "            for c_current =1,2 do\n",
    "                score = pi[{i-1, c_prev}] + math.log(y_hat[c_current])\n",
    "                if score > pi[{i, c_current}] then\n",
    "                    pi[{i, c_current}] = score\n",
    "                    bp[{i, c_current}] = c_prev\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return pi, bp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Building the sequences from the backpointer\n",
    "function build_sequences_from_bp(bp, gram_input)\n",
    "    local predictions = torch.DoubleTensor(2*gram_input:size(1))\n",
    "    -- Next position to fill in predictions (have to do it backward)\n",
    "    local position = 2*gram_input:size(1)\n",
    "    local col = 2\n",
    "    -- Loop until the 3rd position (because 2nd is the first one, could be set by hand)\n",
    "    for i=bp:size(1),3,-1 do\n",
    "        -- coming from a space\n",
    "        if bp[i][col] == 1 then\n",
    "            predictions[position] = 1\n",
    "            position = position - 1\n",
    "            col = 1\n",
    "        else\n",
    "            col = 2\n",
    "        end\n",
    "        -- index i is shifted of 1 wrt local index in gram_input\n",
    "        predictions[position] = gram_input[i-1]\n",
    "        position = position - 1\n",
    "    end\n",
    "    -- Beginnning of gram_input set\n",
    "    predictions[position] = gram_input[1]\n",
    "    position = position - 1\n",
    "\n",
    "    return predictions:narrow(1,position+1,predictions:size(1)-position)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_test = data['input_data_test']\n",
    "input_data_valid = data['input_data_valid']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "myFile:close()\n",
    "\n",
    "-- Dynamic Programming version for bigram\n",
    "F_count, ngram_to_ind = get_F_count(F_train, N)\n",
    "gram_input = input_data_test\n",
    "\n",
    "pi, bp = predict_count_based_viterbi(gram_input, F_count, ngram_to_ind, N)\n",
    "pred = build_sequences_from_bp(bp, gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_spaces_viterbi = get_kaggle_format(pred, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of spaces with Viterbi in test\t\n",
       "3218\t\n",
       "Number of spaces with Greedy in test\t\n",
       "64456\t\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of spaces with Viterbi in test')\n",
    "print(num_spaces_viterbi:narrow(2,2,1):sum())\n",
    "print('Number of spaces with Greedy in test')\n",
    "print(num_spaces:narrow(2,2,1):sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Viterbi on 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- In pi matrix col1: space; col2: char\n",
    "\n",
    "function predict_count_based_viterbi_trigram(gram_input, F_count, ngram_to_ind, N)\n",
    "    -- Backpointer\n",
    "    local score\n",
    "    local bp = torch.zeros(gram_input:size(1) + 1, 3)\n",
    "    local context = torch.DoubleTensor(2)\n",
    "    local y_hat = torch.DoubleTensor(2)\n",
    "    -- pi is built as ('char-space', 'char-char', 'space-char')\n",
    "    -- corresponding index in the context\n",
    "    local pi = torch.ones(gram_input:size(1) + 1, 3):mul(-999999999)\n",
    "    -- Initialization\n",
    "    pi[{2,1}] = 0\n",
    "    --pi[{2,2}] = 0\n",
    "    --pi[{2,3}] = 0\n",
    "    -- We need to start at the first trigram\n",
    "    for i=3,gram_input:size(1)+1 do\n",
    "        for c_prev =1,3 do\n",
    "            -- Precompute y_hat(c_prev)\n",
    "            if c_prev == 1 then\n",
    "                context[1] = gram_input[i-2]\n",
    "                context[2] = 1\n",
    "            elseif c_prev == 2 then\n",
    "                context[1] = gram_input[i-2]\n",
    "                context[2] = gram_input[i-1]\n",
    "            else\n",
    "                context[1] = 1\n",
    "                context[2] = gram_input[i-1]\n",
    "            end\n",
    "            -- Line where the model appears\n",
    "            y_hat:copy(compute_probability(context, F_count, ngram_to_ind, 1))\n",
    "\n",
    "            -- cannot have 2 spaces in a row: from 1 goes to 3 necessarily\n",
    "            if c_prev == 1 then\n",
    "                pi[{i, 3}] = pi[{i-1, c_prev}] + math.log(y_hat[2])\n",
    "                bp[{i, 3}] = c_prev\n",
    "            else\n",
    "                -- last char is necessarily 'char' so\n",
    "                -- 1: space predicted (ie 'char-space')\n",
    "                -- 2: char predicted (ie 'char-char')\n",
    "                for c_current =1,2 do\n",
    "                    score = pi[{i-1, c_prev}] + math.log(y_hat[c_current])\n",
    "                    if score > pi[{i, c_current}] then\n",
    "                        pi[{i, c_current}] = score\n",
    "                        bp[{i, c_current}] = c_prev\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return pi, bp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Building the sequences from the backpointer\n",
    "-- We start the sequence by the ('char'-'char') configuration\n",
    "-- as we know it's the only one possible\n",
    "function build_sequences_from_bp_trigram(bp, gram_input)\n",
    "    local predictions = torch.DoubleTensor(2*gram_input:size(1))\n",
    "    -- Next position to fill in predictions (have to do it backward)\n",
    "    local position = 2*gram_input:size(1)\n",
    "    local col = 2\n",
    "    -- Loop until the 4th position \n",
    "    for i=bp:size(1),4,-1 do\n",
    "        -- coming from a space\n",
    "        if bp[i][col] == 1 then\n",
    "            predictions[position] = 1\n",
    "            position = position - 1\n",
    "        end\n",
    "        col = bp[i][col]\n",
    "        -- index i is shifted of 1 wrt local index in gram_input\n",
    "        predictions[position] = gram_input[i-1]\n",
    "        position = position - 1\n",
    "    end\n",
    "    -- Beginnning of gram_input set\n",
    "    predictions[position] = gram_input[2]\n",
    "    position = position - 1\n",
    "    predictions[position] = gram_input[1]\n",
    "    position = position - 1\n",
    "\n",
    "    return predictions:narrow(1,position+1,predictions:size(1)-position)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_test = data['input_data_test']\n",
    "input_data_valid = data['input_data_valid']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "myFile:close()\n",
    "\n",
    "-- Dynamic Programming version for bigram\n",
    "F_count, ngram_to_ind = get_F_count(F_train, N)\n",
    "gram_input = input_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pi_tri, bp_tri = predict_count_based_viterbi_trigram(gram_input, F_count, ngram_to_ind, N)\n",
    "---pred = build_sequences_from_bp(bp, gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_tri = build_sequences_from_bp_trigram(bp_tri, gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of spaces with Viterbi trigram in test\t\n",
       "51832\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_spaces_tri = get_kaggle_format(seq_tri, N)\n",
    "print('Number of spaces with Viterbi trigram in test')\n",
    "print(num_spaces_tri:narrow(2,2,1):sum())\n",
    "-- The number is closer to the Greedy case!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving the Kaggle format output\n",
    "myFile = hdf5.open('../submission/pred_test_viterbi_trigram', 'w')\n",
    "myFile:write('num_spaces', num_spaces_tri)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
