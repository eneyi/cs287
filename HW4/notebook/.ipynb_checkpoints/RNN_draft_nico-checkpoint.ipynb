{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_valid = data['input_data_valid']\n",
    "output_matrix_train = data['output_matrix_train']\n",
    "input_matrix_train = data['input_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "input_data_test = data['input_data_test']\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 599903\n",
       "      1\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 599903\n",
       "[torch.LongStorage of size 1]\n",
       "\n",
       " 599905\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_matrix_train:size())\n",
    "print(output_matrix_train:size())\n",
    "print(input_data_train:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599200\t\n",
       "749\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Formating the input\n",
    "-- Currently using a hack to have nive divisions\n",
    "n = input_data_train:size(1)\n",
    "n_new = n - 705\n",
    "len = 50\n",
    "batch_size = 16\n",
    "print(n_new)\n",
    "print(n_new/(batch_size*len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Issue with last sequence if batch_size does not divide n\n",
    "t_input = torch.split(input_data_train:narrow(1,1,n_new):view(batch_size,n_new/batch_size),len, 2)\n",
    "t_output = torch.split(output_matrix_train:narrow(1,1,n_new):view(batch_size,n_new/batch_size),len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_rnn(embed_dim, vocab_size, batch_size, len)\n",
    "    local batchRNN\n",
    "    local params\n",
    "    local grad_params\n",
    "    -- generic RNN transduced\n",
    "    batchRNN = nn.Sequential()\n",
    "        :add(nn.LookupTable(vocab_size, embed_dim))\n",
    "        :add(nn.SplitTable(1, batch_size))\n",
    "    \n",
    "    batchRNN:add(nn.Sequencer(nn.Recurrent(\n",
    "       embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "       nn.Linear(embed_dim, embed_dim), nn.Tanh(), len)))\n",
    "    -- Output\n",
    "    batchRNN:add(nn.Sequencer(nn.Linear(embed_dim, 2)))\n",
    "    batchRNN:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "    batchRNN:remember('both')\n",
    "\n",
    "    -- Retrieve parameters (To do only once!!!)\n",
    "    params, grad_params = batchRNN:getParameters()\n",
    "    \n",
    "    return batchRNN, params, grad_params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_lstm(embed_dim, vocab_size, batch_size)\n",
    "    local batchRNN\n",
    "    local params\n",
    "    local grad_params\n",
    "    -- Fast LSTM\n",
    "    batchRNN = nn.Sequential()\n",
    "        :add(nn.LookupTable(vocab_size, embed_dim))\n",
    "        :add(nn.SplitTable(1, batch_size))\n",
    "    batchRNN:add(nn.Sequencer((nn.FastLSTM(embed_dim, embed_dim))))\n",
    "    -- Output\n",
    "    batchRNN:add(nn.Sequencer(nn.Linear(embed_dim, 2)))\n",
    "    batchRNN:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "    batchRNN:remember('both')\n",
    "\n",
    "    -- Retrieve parameters (To do only once!!!)\n",
    "    params, grad_params = batchRNN:getParameters()\n",
    "    \n",
    "    return batchRNN, params, grad_params\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train_model(t_input, t_output, model, params, grad_params,\n",
    "                     criterion, eta, nEpochs, batch_size, len, n)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "    local timer\n",
    "    local pred\n",
    "    local loss\n",
    "    local dLdPred\n",
    "    local t_inputT = torch.DoubleTensor(len,batch_size)\n",
    "    local t_output_table\n",
    "    local delta = 0.2\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "    \n",
    "    -- Initializing all the parameters between -0.05 and 0.05\n",
    "    for k=1,params:size(1) do\n",
    "        params[k] = torch.uniform(-0.05,0.05)\n",
    "    end\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        timer = torch.Timer()\n",
    "        old_L = av_L\n",
    "        av_L = 0\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for k = 1, n/(batch_size * len) do\n",
    "            -- Mini batch data\n",
    "                \n",
    "            t_inputT:copy(t_input[k]:t())\n",
    "            t_output_table = torch.split(t_output[k],1,2)\n",
    "            --format the output\n",
    "            for j=1,len do\n",
    "                t_output_table[j] = t_output_table[j]:squeeze()\n",
    "            end \n",
    "            \n",
    "            -- reset gradients\n",
    "            grad_params:zero()\n",
    "            \n",
    "            -- Forward loop\n",
    "            pred = model:forward(t_inputT)\n",
    "            loss = criterion:forward(pred, t_output_table)\n",
    "            av_L = av_L + loss\n",
    "\n",
    "            -- Backward loop\n",
    "            dLdPred = criterion:backward(pred, t_output_table)\n",
    "            model:backward(t_inputT, dLdPred)\n",
    "            \n",
    "            -- gradient normalization with max norm 5 (l2 norm)\n",
    "            grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "            model:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(n/batch_size))\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if (old_L - av_L) < delta then\n",
    "        eta = eta/2\n",
    "        delta = delta/2\n",
    "    end\n",
    "    \n",
    "    if (eta < 0.001) then eta = 0.1 end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 7.422128200531\t\n",
       "Average Loss: 0.30979213901479\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 6.4211950302124\t\n",
       "Average Loss: 0.25576773451975\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 6.3254590034485\t\n",
       "Average Loss: 0.22644764109874\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 6.4085111618042\t\n",
       "Average Loss: 0.20789739247033\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 6.3699600696564\t\n",
       "Average Loss: 0.19375478694154\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 6.381441116333\t\n",
       "Average Loss: 0.18503419077917\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 6.9063639640808\t\n",
       "Average Loss: 0.1792965625867\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 6.5559759140015\t\n",
       "Average Loss: 0.17522007718129\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 6.9096751213074\t\n",
       "Average Loss: 0.17217148793924\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 6.5440270900726\t\n",
       "Average Loss: 0.16966121016686\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 10\n",
    "\n",
    "-- Building model\n",
    "batchRNN, params, grad_params = build_rnn(embed_dim, vocab_size, len)\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "train_model(t_input, t_output, batchRNN, params, grad_params,\n",
    "                     crit, eta, nEpochs, batch_size, len, n_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 49\n",
    "embed_dim = 20\n",
    "eta = 0.5\n",
    "nEpochs = 10\n",
    "\n",
    "-- Building model\n",
    "batchLSTM, params_lstm, grad_params_lstm = build_lstm(embed_dim, vocab_size)\n",
    "crit2 = nn.SequencerCriterion(nn.ClassNLLCriterion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 36.954732894897\t\n",
       "Average Loss: 0.43456628210534\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 36.342836141586\t\n",
       "Average Loss: 0.27944201210318\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 39.1511490345\t\n",
       "Average Loss: 0.24199334790094\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 34.9020819664\t\n",
       "Average Loss: 0.22528050802921\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 34.562178134918\t\n",
       "Average Loss: 0.2153748178659\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 35.032074928284\t\n",
       "Average Loss: 0.20743909895576\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 32.87624502182\t\n",
       "Average Loss: 0.20070673120846\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 32.899857997894\t\n",
       "Average Loss: 0.19397212705706\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 35.779467105865\t\n",
       "Average Loss: 0.1880882761721\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 34.576239109039\t\n",
       "Average Loss: 0.18328521033972\t\n",
       "\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(t_input, t_output, batchLSTM, params_lstm, grad_params_lstm,\n",
    "                     crit2, eta, nEpochs, batch_size, len, n_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Copying model into one with batch_size = 1\n",
    "batchRNN_valid, params_valid, grad_params_valid = build_rnn(embed_dim, vocab_size, 1, len)\n",
    "params_valid:copy(params)\n",
    "\n",
    "-- Compute perplexity on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_lsm, params_valid_lsm, grad_params_valid_lsm = build_lstm(embed_dim, vocab_size, 1)\n",
    "params_valid_lsm:copy(params_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 11.978783130646\t\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "size = 10000\n",
    "pred_train = batchRNN_valid:forward(input_data_train:narrow(1,1,size):view(size,1))\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timer = torch.Timer()\n",
    "size = 10000\n",
    "pred_train_short = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Compute perplexity on train\n",
    "pred_train = batchRNN_valid:forward(input_data_train:view(input_data_train:size(1),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_output_table_train = {}\n",
    "--format the output\n",
    "for j=1, do\n",
    "    t_output_table[j] = output_matrix_train:narrodata,i,1)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_valid = input_data_valid:view(input_data_valid:size(1), 1)\n",
    "pred_valid = batchRNN_valid:forward(input_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_valid_output_table = {}\n",
    "--format the output\n",
    "for j=1,input_valid:size(1) do\n",
    "    if input_valid[j] == 1 then\n",
    "        t_valid_output_table[j] = torch.DoubleTensor({1})\n",
    "    else\n",
    "        t_valid_output_table[j] = torch.DoubleTensor({2})\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_valid = crit:forward(pred_valid, t_valid_output_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = batchRNN_valid:get(1)['weight']\n",
    "w_original = batchRNN:get(1)['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38958298749322\t\n",
       "1.4763650028245\t\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Compute perplexity\n",
    "loss_valid_avg = loss_valid/input_valid:size(1)\n",
    "perp_valid = math.exp(loss_valid_avg)\n",
    "print(loss_valid_avg)\n",
    "print(perp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_probability_model(model, input)\n",
    "    return model:forward(input:view(input:size(1), 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Prediction on test\n",
    "function predict_rnn_greedy(input, len, model)\n",
    "    -- Last Position filled in predictions\n",
    "    local position_prediction = 1\n",
    "    -- Position to predict in input\n",
    "    local position_input = 1\n",
    "    -- We allocate the maximum of memory that could be needed\n",
    "    -- Default value is -1 (to know where predictions end afterwards)\n",
    "    local predictions = torch.ones(2*input:size(1)):mul(-1)\n",
    "    -- Copy the first entry\n",
    "    predictions[position_prediction] = input[position_input]\n",
    "    local probability = torch.zeros(2)\n",
    "    local probability_table\n",
    "\n",
    "    -- Build mapping\n",
    "    while position_input < input:size(1) do\n",
    "        -- Line where the model appears\n",
    "        -- The model remember the states before, just need to feed into it a character\n",
    "        probability_table = compute_probability_model(model, predictions:narrow(1,position_prediction, 1))\n",
    "        probability:copy(probability_table[1])\n",
    "\n",
    "        m,a = probability:max(1)\n",
    "\n",
    "        -- Case space predicted\n",
    "        position_prediction = position_prediction +1\n",
    "        if (a[1] == 1) then\n",
    "            predictions[position_prediction] = 1\n",
    "        else\n",
    "            -- Copying next character\n",
    "            position_input = position_input + 1\n",
    "            predictions[position_prediction] = input[position_input] \n",
    "        end\n",
    "    end\n",
    "    -- Cutting the output\n",
    "    return predictions:narrow(1,1,position_prediction)\n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_valid_short = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,20), len, batchRNN_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 14\n",
       "  9\n",
       "  7\n",
       "  1\n",
       " 18\n",
       " 17\n",
       " 20\n",
       "  4\n",
       "  5\n",
       " 18\n",
       "  1\n",
       " 20\n",
       "  3\n",
       " 16\n",
       " 15\n",
       "  3\n",
       "  7\n",
       " 10\n",
       " 10\n",
       "  9\n",
       " 20\n",
       "  9\n",
       "[torch.DoubleTensor of size 22]\n",
       "\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- LSM\n",
    "pred_valid_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 14\n",
       "  9\n",
       "  7\n",
       " 18\n",
       "  1\n",
       " 17\n",
       " 20\n",
       "  4\n",
       "  5\n",
       " 18\n",
       "  1\n",
       " 20\n",
       "  3\n",
       " 16\n",
       "  1\n",
       " 15\n",
       "  3\n",
       "  7\n",
       " 10\n",
       " 10\n",
       "  9\n",
       " 20\n",
       "  1\n",
       "  9\n",
       "[torch.DoubleTensor of size 24]\n",
       "\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- RNN\n",
    "pred_valid_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elasped : 1.6905431747437\t\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "timer = torch.Timer()\n",
    "size = 10000\n",
    "pred_valid_short = predict_rnn_greedy(input_data_valid_nospace:narrow(1,1,size), len, batchRNN_valid)\n",
    "print('Time elasped : '..timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 367515\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_test:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
