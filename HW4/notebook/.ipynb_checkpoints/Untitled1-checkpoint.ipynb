{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5';\n",
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_model(dwin, nchar, nclass, hid1, hid2)\n",
    "    -- Model with skip layer from Bengio, standards parameters\n",
    "    -- should be:\n",
    "    -- dwin = 5\n",
    "    -- hid1 = 30\n",
    "    -- hid2 = 100\n",
    "\n",
    "    -- To store the whole model\n",
    "    local dnnlm = nn.Sequential()\n",
    "\n",
    "    -- Layer to embedd (and put the words along the window into one vector)\n",
    "    local LT = nn.Sequential()\n",
    "    local LT_ = nn.LookupTable(nchar,hid1)\n",
    "    LT:add(LT_)\n",
    "    LT:add(nn.View(-1, hid1*dwin))\n",
    "\n",
    "    dnnlm:add(LT)\n",
    "\n",
    "    local concat = nn.ConcatTable()\n",
    "\n",
    "    local lin_tanh = nn.Sequential()\n",
    "    lin_tanh:add(nn.Linear(hid1*dwin,hid2))\n",
    "    lin_tanh:add(nn.Tanh())\n",
    "\n",
    "    local id = nn.Identity()\n",
    "\n",
    "    concat:add(lin_tanh)\n",
    "    concat:add(id)\n",
    "\n",
    "    dnnlm:add(concat)\n",
    "    dnnlm:add(nn.JoinTable(2))\n",
    "    dnnlm:add(nn.Linear(hid1*dwin + hid2, nclass))\n",
    "    dnnlm:add(nn.LogSoftMax())\n",
    "\n",
    "    -- Loss\n",
    "    local criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "    return dnnlm, criterion\n",
    "end\n",
    "\n",
    "function compute_perplexity(gram_input, nnlm, N)\n",
    "    local perp = 0\n",
    "    local context = torch.zeros(N-1)\n",
    "    local probability = torch.zeros(2)\n",
    "    -- Do not predict for the last char\n",
    "    --for i=1,gram_input:size(1)-N do\n",
    "    local size=gram_input:size(1) - (N-1)\n",
    "    for i=1,size do\n",
    "        context:copy(gram_input:narrow(1,i,N-1))\n",
    "        -- Line where the model appears\n",
    "        probability:copy(nnlm:forward(context))\n",
    "        if gram_input[i+(N-1)] == 1 then\n",
    "            right_proba = probability[1]\n",
    "        else\n",
    "            right_proba = probability[2]\n",
    "        end\n",
    "        perp = perp + right_proba\n",
    "    end\n",
    "    perp = math.exp(-perp/size)\n",
    "    return perp\n",
    "end\n",
    "\n",
    "function train_model(train_input, train_output, dnnlm, criterion, dwin, nclass, eta, nEpochs, batchSize, valid, N)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    local inputs_batch = torch.DoubleTensor(batchSize,dwin)\n",
    "    local targets_batch = torch.DoubleTensor(batchSize)\n",
    "    local outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    local df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "    \n",
    "    local train_perplexity = torch.DoubleTensor(nEpochs)\n",
    "    local valid_perplexity = torch.DoubleTensor(nEpochs)\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        local timer = torch.Timer()\n",
    "\n",
    "        av_L = 0\n",
    "        \n",
    "        -- max renorm of the lookup table\n",
    "        dnnlm:get(1):get(1).weight:renorm(2,1,1)\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            local current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "            \n",
    "            -- reset gradients\n",
    "            dnnlm:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(dnnlm:forward(inputs_batch:narrow(1,1,current_batch_size)))\n",
    "\n",
    "            -- Average loss computation\n",
    "            local f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "            dnnlm:backward(inputs_batch:narrow(1,1,current_batch_size), df_do:narrow(1,1,current_batch_size))\n",
    "            dnnlm:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(train_input:size(1)/batchSize))\n",
    "        \n",
    "        train_perplexity[i] = math.exp(av_L/math.floor(train_input:size(1)/batchSize))\n",
    "        valid_perplexity[i] = compute_perplexity(valid, dnnlm, N)\n",
    "    end\n",
    "\n",
    "    return train_perplexity, valid_perplexity\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/4-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "N = 4\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "\n",
    "input_data_valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "input_data_test = data['input_data_test']:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.040657043457\t\n",
       "Average Loss: 0.2999279016966\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "[string \"function build_model(dwin, nchar, nclass, hid...\"]:119: attempt to index global 'valid_perplexity' (a nil value)\nstack traceback:\n\t[string \"function build_model(dwin, nchar, nclass, hid...\"]:119: in function 'train_model'\n\t[string \"perp_train_3, perp_valid_3 = train_model(trai...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010289eb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"function build_model(dwin, nchar, nclass, hid...\"]:119: attempt to index global 'valid_perplexity' (a nil value)\nstack traceback:\n\t[string \"function build_model(dwin, nchar, nclass, hid...\"]:119: in function 'train_model'\n\t[string \"perp_train_3, perp_valid_3 = train_model(trai...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010289eb50"
     ]
    }
   ],
   "source": [
    "torch.manualSeed(1)\n",
    "nnlm1, crit = build_model(N-1, 49, 2, 16, 80)\n",
    "perp_train_3, perp_valid_3 = train_model(train_input, train_output, nnlm1, crit, N-1, 2, 0.01, 15, 20, input_data_valid, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/4-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "N = 4\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "\n",
    "input_data_valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "input_data_test = data['input_data_test']:clone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
