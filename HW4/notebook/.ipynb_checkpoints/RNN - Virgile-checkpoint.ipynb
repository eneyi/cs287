{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5';\n",
    "require 'rnn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599905\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data_train']:size(1)-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data['input_data_train']:narrow(1,5,data['input_data_train']:size(1)-1509)\n",
    "out = data['output_matrix_train']:narrow(1,1,data['input_data_train']:size(1)-1509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 50\n",
    "b = 32\n",
    "n = train:size(1)\n",
    "train_matrix = train:view(b,n/b):type('torch.DoubleTensor')\n",
    "out_matrix = out:view(b,n/b):type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nchar = 49\n",
    "embed_dim = 20\n",
    "LT = nn.LookupTable(nchar, embed_dim)\n",
    "\n",
    "r = nn.Recurrent(\n",
    "   embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "   nn.Linear(embed_dim, embed_dim), nn.Tanh(),l\n",
    ")\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(LT) \n",
    "   :add(nn.SplitTable(1,10))\n",
    "   :add(nn.Sequencer(r))\n",
    "   :add(nn.Sequencer(nn.Linear(embed_dim,2)))\n",
    "   :add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "rnn:remember('both')\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "params, grad_params = rnn:getParameters()\n",
    "\n",
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1, params:size(1) do\n",
    "    params[i] = torch.uniform(-0.05,0.05)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 8.064178943634\t\n",
       "Average Loss: 0.3866133138793\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 7.9011170864105\t\n",
       "Average Loss: 0.31600915759062\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 7.3565239906311\t\n",
       "Average Loss: 0.30965662668445\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 7.4580230712891\t\n",
       "Average Loss: 0.30202855209428\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 7.3622870445251\t\n",
       "Average Loss: 0.29651457980714\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 7.1814610958099\t\n",
       "Average Loss: 0.2942087753093\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 7.3360669612885\t\n",
       "Average Loss: 0.29330337152334\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 7.5940849781036\t\n",
       "Average Loss: 0.29291146771129\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 7.2559850215912\t\n",
       "Average Loss: 0.29273152420827\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 7.2782471179962\t\n",
       "Average Loss: 0.29264715973915\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 7.528126001358\t\n",
       "Average Loss: 0.2926051183024\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 7.2583739757538\t\n",
       "Average Loss: 0.29258355378164\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 7.455992937088\t\n",
       "Average Loss: 0.29257268246563\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 7.1697318553925\t\n",
       "Average Loss: 0.29256723411433\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 7.1605479717255\t\n",
       "Average Loss: 0.29256450777645\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 7.236114025116\t\n",
       "Average Loss: 0.2925631441753\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 7.142914056778\t\n",
       "Average Loss: 0.29256246227982\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 7.6399219036102\t\n",
       "Average Loss: 0.29256212130989\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 7.3285710811615\t\n",
       "Average Loss: 0.29256195081957\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 7.1288621425629\t\n",
       "Average Loss: 0.2925618655731\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- To store the loss\n",
    "av_L = 0\n",
    "old_L = 0\n",
    "new_L = 0\n",
    "c = 0.1\n",
    "for i = 1, 20 do\n",
    "    -- timing the epoch\n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    old_L = new_L\n",
    "    \n",
    "    av_L = 0\n",
    "\n",
    "    -- mini batch loop\n",
    "    for t = 1, n/(b*l) do\n",
    "        -- Mini batch data\n",
    "        inputs_batch = train_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        targets_batch = out_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        \n",
    "        tab = torch.split(targets_batch,1,2)\n",
    "        target_table = {}\n",
    "        for k, v in pairs(tab) do\n",
    "          target_table[k] = v:squeeze()\n",
    "        end \n",
    "        \n",
    "        -- reset gradients\n",
    "        grad_params:zero()\n",
    "\n",
    "        -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "        outputs = rnn:forward(inputs_batch:t()) \n",
    "\n",
    "        -- Average loss computation\n",
    "        f = crit:forward(outputs, target_table)\n",
    "        av_L = av_L +f\n",
    "\n",
    "        -- Backward pass\n",
    "        df_do = crit:backward(outputs,target_table)\n",
    "        rnn:backward(inputs_batch, df_do)\n",
    "        \n",
    "        grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "        \n",
    "        rnn:updateParameters(lr)\n",
    "\n",
    "    end\n",
    "    \n",
    "    new_L = av_L/math.floor(train:size(1)/b)\n",
    "    \n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..new_L)\n",
    "    \n",
    "    if (new_L-old_L)< c then \n",
    "        lr = lr/2 \n",
    "        c = c/2\n",
    "    end\n",
    "    \n",
    "    if c < 0.001 then c = 0.1 end\n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
