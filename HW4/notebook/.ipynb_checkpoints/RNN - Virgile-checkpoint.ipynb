{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'rnn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599905\t\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data_train']:size(1)-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data['input_data_train']:narrow(1,5,data['input_data_train']:size(1)-909)\n",
    "out = data['output_matrix_train']:narrow(1,1,data['input_data_train']:size(1)-909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 50\n",
    "b = 10\n",
    "n = train:size(1)\n",
    "train_matrix = train:view(b,n/b)\n",
    "out_matrix = out:view(b,n/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nchar = 49\n",
    "embed_dim = 16\n",
    "LT = nn.LookupTable(nchar, embed_dim)\n",
    "\n",
    "r = nn.Recurrent(\n",
    "   embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "   nn.Linear(embed_dim, embed_dim), nn.Tanh(),l\n",
    ")\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(LT) \n",
    "   :add(nn.SplitTable(1,10))\n",
    "   :add(nn.Sequencer(r))\n",
    "   :add(nn.Sequencer(nn.Linear(embed_dim,2)))\n",
    "   :add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "rnn:remember('both')\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "params, grad_params = rnn:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = torch.split(ex_out:type('torch.DoubleTensor'),1,2)\n",
    "tp = {}\n",
    "for k, v in pairs (t) do\n",
    "  tp[k] = v:squeeze()\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "bad argument #1 to '?' (expecting number or torch.DoubleTensor or torch.DoubleStorage at /Users/virgileaudi/torch/pkg/torch/generic/Tensor.c:1123)\nstack traceback:\n\t[C]: at 0x0301b2d0\n\t[C]: in function 'DoubleTensor'\n\t[string \"-- To store the loss...\"]:6: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0102caeb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #1 to '?' (expecting number or torch.DoubleTensor or torch.DoubleStorage at /Users/virgileaudi/torch/pkg/torch/generic/Tensor.c:1123)\nstack traceback:\n\t[C]: at 0x0301b2d0\n\t[C]: in function 'DoubleTensor'\n\t[string \"-- To store the loss...\"]:6: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0102caeb50"
     ]
    }
   ],
   "source": [
    "-- To store the loss\n",
    "local av_L = 0\n",
    "\n",
    "-- Memory allocation\n",
    "inputs_batch = torch.DoubleTensor(b,l)\n",
    "targets_batch = torch.DoubleTensor(batchSize)\n",
    "df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "\n",
    "for i = 1, 1 do\n",
    "    -- timing the epoch\n",
    "    local timer = torch.Timer()\n",
    "\n",
    "    av_L = 0\n",
    "\n",
    "    -- mini batch loop\n",
    "    for t = 1, (n/(b*l)) do\n",
    "        -- Mini batch data\n",
    "        inputs_batch = train_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        targets_batch = out_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        \n",
    "        table = torch.split(targets_batch:type('torch.DoubleTensor'),1,2)\n",
    "        target_table = {}\n",
    "        for k, v in pairs (t) do\n",
    "          target_table[k] = v:squeeze()\n",
    "        end \n",
    "        \n",
    "        -- reset gradients\n",
    "        grad_params:zero()\n",
    "\n",
    "        -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "        outputs = rrn:forward(inputs_batch:t()) \n",
    "\n",
    "        -- Average loss computation\n",
    "        f = crit:forward(outputs, target_table)\n",
    "        av_L = av_L +f\n",
    "\n",
    "        -- Backward pass\n",
    "        df_do = crit:backward(outputs,target_table)\n",
    "        rnn:backward(inputs_batch, df_do)\n",
    "        \n",
    "        grad_params:view(4,1):renorm(1,2,5)\n",
    "        \n",
    "        rnn:updateParameters(eta)\n",
    "\n",
    "    end\n",
    "\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..av_L/math.floor(train_input:size(1)/batchSize))\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
