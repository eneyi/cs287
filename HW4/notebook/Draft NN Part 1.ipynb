{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'hdf5';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_model(dwin, nchar, nclass, hid1, hid2)\n",
    "    -- Model with skip layer from Bengio, standards parameters\n",
    "    -- should be:\n",
    "    -- dwin = 5\n",
    "    -- hid1 = 30\n",
    "    -- hid2 = 100\n",
    "\n",
    "    -- To store the whole model\n",
    "    local dnnlm = nn.Sequential()\n",
    "\n",
    "    -- Layer to embedd (and put the words along the window into one vector)\n",
    "    local LT = nn.Sequential()\n",
    "    local LT_ = nn.LookupTable(nchar,hid1)\n",
    "    LT:add(LT_)\n",
    "    LT:add(nn.View(-1, hid1*dwin))\n",
    "\n",
    "    dnnlm:add(LT)\n",
    "\n",
    "    local concat = nn.ConcatTable()\n",
    "\n",
    "    local lin_tanh = nn.Sequential()\n",
    "    lin_tanh:add(nn.Linear(hid1*dwin,hid2))\n",
    "    lin_tanh:add(nn.Tanh())\n",
    "\n",
    "    local id = nn.Identity()\n",
    "\n",
    "    concat:add(lin_tanh)\n",
    "    concat:add(id)\n",
    "\n",
    "    dnnlm:add(concat)\n",
    "    dnnlm:add(nn.JoinTable(2))\n",
    "    dnnlm:add(nn.Linear(hid1*dwin + hid2, nclass))\n",
    "    dnnlm:add(nn.LogSoftMax())\n",
    "\n",
    "    -- Loss\n",
    "    local criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "    return dnnlm, criterion\n",
    "end\n",
    "\n",
    "\n",
    "function train_model(train_input, train_output, dnnlm, criterion, dwin, nclass, eta, nEpochs, batchSize)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    local inputs_batch = torch.DoubleTensor(batchSize,dwin)\n",
    "    local targets_batch = torch.DoubleTensor(batchSize)\n",
    "    local outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    local df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "\n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        local timer = torch.Timer()\n",
    "\n",
    "        av_L = 0\n",
    "        \n",
    "        -- max renorm of the lookup table\n",
    "        dnnlm:get(1):get(1).weight:renorm(2,1,1)\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            local current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "            \n",
    "            -- reset gradients\n",
    "            dnnlm:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(dnnlm:forward(inputs_batch:narrow(1,1,current_batch_size)))\n",
    "\n",
    "            -- Average loss computation\n",
    "            local f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "            dnnlm:backward(inputs_batch:narrow(1,1,current_batch_size), df_do:narrow(1,1,current_batch_size))\n",
    "            dnnlm:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(train_input:size(1)/batchSize))\n",
    "       \n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input_data_test : LongTensor - size: 367519\n",
       "  input_data_valid : LongTensor - size: 115720\n",
       "  F_train : DoubleTensor - size: 65033x7\n",
       "  input_data_train : LongTensor - size: 599909\n",
       "  input_matrix_train : DoubleTensor - size: 599903x5\n",
       "  input_data_valid_nospace : LongTensor - size: 95827\n",
       "  output_matrix_train : DoubleTensor - size: 599903\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nwin = 5\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "\n",
    "valid_space = data['input_data_valid_nospace']\n",
    "valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "test = data['input_data_test']:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 30.32079577446\t\n",
       "Average Loss: 0.28291292916549\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 30.03511595726\t\n",
       "Average Loss: 0.22909422380413\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 28.832560062408\t\n",
       "Average Loss: 0.20544086393986\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 28.815920829773\t\n",
       "Average Loss: 0.19439121899764\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 30.704405069351\t\n",
       "Average Loss: 0.18717225893088\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 30.742899179459\t\n",
       "Average Loss: 0.18127659217664\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 31.944208860397\t\n",
       "Average Loss: 0.1765919324312\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 34.879153966904\t\n",
       "Average Loss: 0.17284293586983\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 32.785515069962\t\n",
       "Average Loss: 0.16978364828228\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 32.413477182388\t\n",
       "Average Loss: 0.16708374429545\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 28.789509057999\t\n",
       "Average Loss: 0.16467734778624\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 29.227755069733\t\n",
       "Average Loss: 0.16264201066196\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 32.339390993118\t\n",
       "Average Loss: 0.16092642410432\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 35.106617927551\t\n",
       "Average Loss: 0.15947024681839\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 33.359790086746\t\n",
       "Average Loss: 0.15822392705003\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 35.18958902359\t\n",
       "Average Loss: 0.15711771041754\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 30.188794851303\t\n",
       "Average Loss: 0.15611926878796\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 29.59033203125\t\n",
       "Average Loss: 0.15523507092617\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 36.355064153671\t\n",
       "Average Loss: 0.15446284926575\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 30.361381053925\t\n",
       "Average Loss: 0.15377656872611\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manualSeed(1)\n",
    "\n",
    "nnlm1, crit = build_model(Nwin, 49, 2, 20, 16)\n",
    "\n",
    "train_model(train_input, train_output, nnlm1, crit, Nwin, 2, 0.01, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "here\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = 1\n",
    "i = 1\n",
    "nextpred = torch.Tensor(2)\n",
    "\n",
    "print('here')\n",
    "while it<data['input_data_valid_nospace']:size(1)-(Nwin-1) do\n",
    "    it = it + 1\n",
    "    nextpred:copy(nnlm1:forward(valid:narrow(1,i,Nwin)));\n",
    "    m, argm = nextpred:max(1)\n",
    "\n",
    "    if argm[1] == 2 then\n",
    "        i = i + 1\n",
    "    elseif argm[1] == 1 then \n",
    "        valid_ = torch.LongTensor(valid:size(1)+1)\n",
    "        valid_:narrow(1,1,i+(Nwin-1)):copy(valid:narrow(1,1,i+(Nwin-1)))\n",
    "        valid_[i+Nwin] = 1\n",
    "        valid_:narrow(1,i+(Nwin-1)+2,valid:size(1)-i-(Nwin-1)):copy(valid:narrow(1,i+(Nwin-1)+1,valid:size(1)-i-(Nwin-1)))\n",
    "        valid = valid_\n",
    "        i = i + 2\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sent = 0\n",
    "for i = 5,valid_space:size(1) do\n",
    "    if valid_space[i] == 2 then\n",
    "        num_sent = num_sent + 1\n",
    "    end\n",
    "end\n",
    "print(num_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_spaces = torch.DoubleTensor(num_sent,2)\n",
    "row = 1\n",
    "count_space = 0\n",
    "for i=5,valid:size(1) do\n",
    "    if valid[i] == 2 then\n",
    "        num_spaces[{row, 1}] = row\n",
    "        num_spaces[{row, 2}] = count_space\n",
    "        count_space = 0\n",
    "        row = row + 1\n",
    "    elseif valid[i] == 1 then\n",
    "        count_space = count_space + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 7\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_spaces[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "here\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = 1\n",
    "i = 1\n",
    "nextpred = torch.Tensor(2)\n",
    "\n",
    "print('here')\n",
    "while it<data['input_data_test']:size(1)-(Nwin-1) do\n",
    "    it = it + 1\n",
    "    nextpred:copy(nnlm1:forward(test:narrow(1,i,Nwin)));\n",
    "    m, argm = nextpred:max(1)\n",
    "\n",
    "    if argm[1] == 2 then\n",
    "        i = i + 1\n",
    "    elseif argm[1] == 1 then \n",
    "        test_ = torch.LongTensor(test:size(1)+1)\n",
    "        test_:narrow(1,1,i+(Nwin-1)):copy(test:narrow(1,1,i+(Nwin-1)))\n",
    "        test_[i+Nwin] = 1\n",
    "        test_:narrow(1,i+(Nwin-1)+2,test:size(1)-i-(Nwin-1)):copy(test:narrow(1,i+(Nwin-1)+1,test:size(1)-i-(Nwin-1)))\n",
    "        test = test_\n",
    "        i = i + 2\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3761\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sent = 0\n",
    "for i = 5,test:size(1) do\n",
    "    if test[i] == 2 then\n",
    "        num_sent = num_sent + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "print(num_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_spaces_test = torch.DoubleTensor(num_sent,2)\n",
    "row = 1\n",
    "count_space = 0\n",
    "for i=5,test:size(1) do\n",
    "    if test[i] == 2 then\n",
    "        num_spaces_test[{row, 1}] = row\n",
    "        num_spaces_test[{row, 2}] = count_space\n",
    "        count_space = 0\n",
    "        row = row + 1\n",
    "    elseif test[i] == 1 then\n",
    "        count_space = count_space + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"local f = function() return count_space:sum(1...\"]:1: attempt to index global 'count_space' (a number value)\nstack traceback:\n\t[string \"local f = function() return count_space:sum(1...\"]:1: in function 'f'\n\t[string \"local f = function() return count_space:sum(1...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010977cb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"local f = function() return count_space:sum(1...\"]:1: attempt to index global 'count_space' (a number value)\nstack traceback:\n\t[string \"local f = function() return count_space:sum(1...\"]:1: in function 'f'\n\t[string \"local f = function() return count_space:sum(1...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010977cb50"
     ]
    }
   ],
   "source": [
    "count_space:sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../submission/pred_test_greedy_nn_5', 'w')\n",
    "myFile:write('num_spaces', num_spaces_test)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viturby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict_viterbi(nnlm, gram_input)\n",
    "    -- Backpointer\n",
    "    local score\n",
    "    local bp = torch.zeros(gram_input:size(1) + 1, 2)\n",
    "    local context = torch.DoubleTensor(1)\n",
    "    local y_hat = torch.DoubleTensor(2)\n",
    "    local pi = torch.ones(gram_input:size(1) + 1, 2):mul(-9999)\n",
    "    -- Initialization\n",
    "    pi[{1,1}] = 0\n",
    "    -- i is shifted\n",
    "    for i=2,gram_input:size(1)+1 do\n",
    "        for c_prev =1,2 do\n",
    "            -- Precompute y_hat(c_prev)\n",
    "            if c_prev == 1 then\n",
    "                context[1] = c_prev\n",
    "            else\n",
    "                context[1] = gram_input[i-1]\n",
    "            end\n",
    "            -- Line where the model appears\n",
    "            y_hat:copy(nnlm:forward(context))\n",
    "\n",
    "            for c_current =1,2 do\n",
    "                score = pi[{i-1, c_prev}] + math.log(y_hat[c_current])\n",
    "                if score > pi[{i, c_current}] then\n",
    "                    pi[{i, c_current}] = score\n",
    "                    bp[{i, c_current}] = c_prev\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return pi, bp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Building the sequences from the backpointer\n",
    "function build_sequences_from_bp(bp, gram_input)\n",
    "    local predictions = torch.DoubleTensor(2*gram_input:size(1))\n",
    "    -- Next position to fill in predictions (have to do it backward)\n",
    "    local position = 2*gram_input:size(1)\n",
    "    local col = 2\n",
    "    -- Loop until the 3rd position (because 2nd is the first one, could be set by hand)\n",
    "    for i=bp:size(1),3,-1 do\n",
    "        -- coming from a space\n",
    "        if bp[i][col] == 1 then\n",
    "            predictions[position] = 1\n",
    "            position = position - 1\n",
    "            col = 1\n",
    "        else\n",
    "            col = 2\n",
    "        end\n",
    "        -- index i is shifted of 1 wrt local index in gram_input\n",
    "        predictions[position] = gram_input[i-1]\n",
    "        position = position - 1\n",
    "    end\n",
    "    -- Beginnning of gram_input set\n",
    "    predictions[position] = gram_input[1]\n",
    "    position = position - 1\n",
    "\n",
    "    return predictions:narrow(1,position+1,predictions:size(1)-position)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:49: input view (1x20) and desired view (-1x100) do not match\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:49: in function 'batchsize'\n\t/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:80: in function 'updateOutput'\n\t...irgileaudi/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'updateOutput'\n\t...irgileaudi/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"function predict_viterbi(nnlm, gram_input)...\"]:20: in function 'predict_viterbi'\n\t[string \"N = 2...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01029c3b50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:49: input view (1x20) and desired view (-1x100) do not match\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:49: in function 'batchsize'\n\t/Users/virgileaudi/torch/install/share/lua/5.1/nn/View.lua:80: in function 'updateOutput'\n\t...irgileaudi/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'updateOutput'\n\t...irgileaudi/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"function predict_viterbi(nnlm, gram_input)...\"]:20: in function 'predict_viterbi'\n\t[string \"N = 2...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01029c3b50"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "\n",
    "myFile = hdf5.open('../data_preprocessed/'..tostring(N)..'-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "F_train = data['F_train']\n",
    "input_data_test = data['input_data_test']\n",
    "input_data_valid = data['input_data_valid']\n",
    "input_data_train = data['input_data_train']\n",
    "input_data_valid_nospace = data['input_data_valid_nospace']\n",
    "myFile:close()\n",
    "\n",
    "-- Dynamic Programming version for bigram\n",
    "gram_input = input_data_test\n",
    "\n",
    "pi, bp = predict_viterbi(nnlm1, gram_input)\n",
    "pred = build_sequences_from_bp(bp, gram_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
