{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5';\n",
    "require 'rnn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599905\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data_train']:size(1)-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data['input_data_train']:narrow(1,5,data['input_data_train']:size(1)-1509)\n",
    "out = data['output_matrix_train']:narrow(1,1,data['input_data_train']:size(1)-1509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nchar = 49\n",
    "l = 50\n",
    "b = 16\n",
    "n = train:size(1)\n",
    "train_matrix = train:view(b,n/b):type('torch.DoubleTensor')\n",
    "out_matrix = out:view(b,n/b):type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_dim = 20\n",
    "LT = nn.LookupTable(nchar, embed_dim)\n",
    "\n",
    "r = nn.Recurrent(\n",
    "   embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "   nn.Linear(embed_dim, embed_dim), nn.Tanh(),l\n",
    ")\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(LT) \n",
    "   :add(nn.SplitTable(1,10))\n",
    "   :add(nn.Sequencer(r))\n",
    "   :add(nn.Sequencer(nn.Linear(embed_dim,2)))\n",
    "   :add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "rnn:remember('both')\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "params, grad_params = rnn:getParameters()\n",
    "\n",
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1, params:size(1) do\n",
    "    params[i] = torch.uniform(-0.05,0.05)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 16.774312973022\t\n",
       "Average Loss: 0.31411771687415\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 16.888953208923\t\n",
       "Average Loss: 0.25923890417995\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 13.90478515625\t\n",
       "Average Loss: 0.23034241823792\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 14.78458404541\t\n",
       "Average Loss: 0.21935126587833\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 15.43119096756\t\n",
       "Average Loss: 0.21465063898723\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 14.959115028381\t\n",
       "Average Loss: 0.2124872896255\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 14.845481872559\t\n",
       "Average Loss: 0.21147041162226\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 16.291630983353\t\n",
       "Average Loss: 0.21098668229729\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 14.565922021866\t\n",
       "Average Loss: 0.21074714345045\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 16.529317140579\t\n",
       "Average Loss: 0.21062054130321\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 15.261260032654\t\n",
       "Average Loss: 0.21055235924861\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 15.272789955139\t\n",
       "Average Loss: 0.2105165998709\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 14.611160993576\t\n",
       "Average Loss: 0.21049852508072\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 14.525181055069\t\n",
       "Average Loss: 0.21048946780999\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 16.240922927856\t\n",
       "Average Loss: 0.2104849302507\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 15.005460977554\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss: 0.21048265858625\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 15.517771959305\t\n",
       "Average Loss: 0.21048152195259\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 16.392879009247\t\n",
       "Average Loss: 0.21048095342564\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 14.436084985733\t\n",
       "Average Loss: 0.21048066910843\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 14.600162982941\t\n",
       "Average Loss: 0.21048052693625\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- To store the loss\n",
    "av_L = 0\n",
    "old_L = 0\n",
    "new_L = 0\n",
    "c = 0.1\n",
    "for i = 1, 20 do\n",
    "    -- timing the epoch\n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    old_L = new_L\n",
    "    \n",
    "    av_L = 0\n",
    "\n",
    "    -- mini batch loop\n",
    "    for t = 1, n/(b*l) do\n",
    "        -- Mini batch data\n",
    "        inputs_batch = train_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        targets_batch = out_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        \n",
    "        tab = torch.split(targets_batch,1,2)\n",
    "        target_table = {}\n",
    "        for k, v in pairs(tab) do\n",
    "          target_table[k] = v:squeeze()\n",
    "        end \n",
    "        \n",
    "        -- reset gradients\n",
    "        grad_params:zero()\n",
    "\n",
    "        -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "        outputs = rnn:forward(inputs_batch:t()) \n",
    "\n",
    "        -- Average loss computation\n",
    "        f = crit:forward(outputs, target_table)\n",
    "        av_L = av_L +f\n",
    "\n",
    "        -- Backward pass\n",
    "        df_do = crit:backward(outputs,target_table)\n",
    "        rnn:backward(inputs_batch, df_do)\n",
    "        \n",
    "        grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "        \n",
    "        rnn:updateParameters(lr)\n",
    "\n",
    "    end\n",
    "    \n",
    "    new_L = av_L/math.floor(train:size(1)/b)\n",
    "    \n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..new_L)\n",
    "    \n",
    "    if (new_L-old_L)< c then \n",
    "        lr = lr/2 \n",
    "        c = c/2\n",
    "    end\n",
    "    \n",
    "    if c < 0.001 then c = 0.1 end\n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_dim = 20\n",
    "LT_lstm = nn.LookupTable(nchar, embed_dim)\n",
    "\n",
    "r = nn.Recurrent(\n",
    "   embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "   nn.Linear(embed_dim, embed_dim), nn.Tanh(),l\n",
    ")\n",
    "\n",
    "rnn_lstm = nn.Sequential()\n",
    "   :add(LT) \n",
    "   :add(nn.SplitTable(1,10))\n",
    "   :add(nn.Sequencer(nn.LSTM(embed_dim,embed_embed_dim)))\n",
    "   :add(nn.Sequencer(nn.Linear(embed_dim,2)))\n",
    "   :add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "rnn_lstm:remember('both')\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "params, grad_params = rnn_lstm:getParameters()\n",
    "\n",
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1, params:size(1) do\n",
    "    params[i] = torch.uniform(-0.05,0.05)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 75.165275812149\t\n",
       "Average Loss: 0.41858265751432\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 73.915522098541\t\n",
       "Average Loss: 0.27539834276709\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 73.694918870926\t\n",
       "Average Loss: 0.24231290195373\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 73.67759180069\t\n",
       "Average Loss: 0.23135388427404\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 73.235505819321\t\n",
       "Average Loss: 0.22704875186764\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 73.321480989456\t\n",
       "Average Loss: 0.22514831060971\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 73.24760890007\t\n",
       "Average Loss: 0.22426745733644\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 73.180319070816\t\n",
       "Average Loss: 0.22384502857628\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 73.288930177689\t\n",
       "Average Loss: 0.22363730901724\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 73.066717147827\t\n",
       "Average Loss: 0.22352996149639\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 73.37776684761\t\n",
       "Average Loss: 0.22347259253221\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 73.271715164185\t\n",
       "Average Loss: 0.22344267248635\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 73.286930084229\t\n",
       "Average Loss: 0.22342752280938\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 73.258930921555\t\n",
       "Average Loss: 0.22341992594497\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 73.240504980087\t\n",
       "Average Loss: 0.22341612400718\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16: 73.073932170868\t\n",
       "Average Loss: 0.22341422233888\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17: 72.55375289917\t\n",
       "Average Loss: 0.22341327133655\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18: 76.872616052628\t\n",
       "Average Loss: 0.22341279579756\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19: 73.501359939575\t\n",
       "Average Loss: 0.22341255802113\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20: 73.484076023102\t\n",
       "Average Loss: 0.22341243913064\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- To store the loss\n",
    "av_L = 0\n",
    "old_L = 0\n",
    "new_L = 0\n",
    "c = 0.1\n",
    "for i = 1, 20 do\n",
    "    -- timing the epoch\n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    old_L = new_L\n",
    "    \n",
    "    av_L = 0\n",
    "\n",
    "    -- mini batch loop\n",
    "    for t = 1, n/(b*l) do\n",
    "        -- Mini batch data\n",
    "        inputs_batch = train_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        targets_batch = out_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        \n",
    "        tab = torch.split(targets_batch,1,2)\n",
    "        target_table = {}\n",
    "        for k, v in pairs(tab) do\n",
    "          target_table[k] = v:squeeze()\n",
    "        end \n",
    "        \n",
    "        -- reset gradients\n",
    "        grad_params:zero()\n",
    "\n",
    "        -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "        outputs = rnn_lstm:forward(inputs_batch:t()) \n",
    "\n",
    "        -- Average loss computation\n",
    "        f = crit:forward(outputs, target_table)\n",
    "        av_L = av_L +f\n",
    "\n",
    "        -- Backward pass\n",
    "        df_do = crit:backward(outputs,target_table)\n",
    "        rnn_lstm:backward(inputs_batch, df_do)\n",
    "        \n",
    "        grad_params:view(grad_params:size(1),1):renorm(1,2,5)\n",
    "        \n",
    "        rnn_lstm:updateParameters(lr)\n",
    "\n",
    "    end\n",
    "    \n",
    "    new_L = av_L/math.floor(train:size(1)/b)\n",
    "    \n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..new_L)\n",
    "    \n",
    "    if (new_L-old_L)< c then \n",
    "        lr = lr/2 \n",
    "        c = c/2\n",
    "    end\n",
    "    \n",
    "    if c < 0.001 then c = 0.1 end\n",
    "    \n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
