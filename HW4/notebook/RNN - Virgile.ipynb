{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5';\n",
    "require 'rnn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599905\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_data_train']:size(1)-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = data['input_data_train']:narrow(1,5,data['input_data_train']:size(1)-909)\n",
    "out = data['output_matrix_train']:narrow(1,1,data['input_data_train']:size(1)-909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = 50\n",
    "b = 10\n",
    "n = train:size(1)\n",
    "train_matrix = train:view(b,n/b):type('torch.DoubleTensor')\n",
    "out_matrix = out:view(b,n/b):type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nchar = 49\n",
    "embed_dim = 16\n",
    "LT = nn.LookupTable(nchar, embed_dim)\n",
    "\n",
    "r = nn.Recurrent(\n",
    "   embed_dim, nn.Linear(embed_dim, embed_dim), \n",
    "   nn.Linear(embed_dim, embed_dim), nn.Tanh(),l\n",
    ")\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(LT) \n",
    "   :add(nn.SplitTable(1,10))\n",
    "   :add(nn.Sequencer(r))\n",
    "   :add(nn.Sequencer(nn.Linear(embed_dim,2)))\n",
    "   :add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "rnn:remember('both')\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.ClassNLLCriterion())\n",
    "\n",
    "params, grad_params = rnn:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1, params:size(1) do\n",
    "    params[i] = torch.uniform(-0.05,0.05)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- To store the loss\n",
    "av_L = 0\n",
    "\n",
    "for i = 1, 1 do\n",
    "    -- timing the epoch\n",
    "    timer = torch.Timer()\n",
    "\n",
    "    av_L = 0\n",
    "\n",
    "    -- mini batch loop\n",
    "    for t = 1, 1 do\n",
    "        -- Mini batch data\n",
    "        inputs_batch = train_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        targets_batch = out_matrix:narrow(2,(t-1)*l+1,l)\n",
    "        \n",
    "        table = torch.split(targets_batch,1,2)\n",
    "        target_table = {}\n",
    "        for k, v in pairs (t) do\n",
    "          target_table[k] = v:squeeze()\n",
    "        end \n",
    "        \n",
    "        -- reset gradients\n",
    "        grad_params:zero()\n",
    "\n",
    "        -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "        outputs = rrn:forward(inputs_batch:t()) \n",
    "\n",
    "        -- Average loss computation\n",
    "        f = crit:forward(outputs, target_table)\n",
    "        av_L = av_L +f\n",
    "\n",
    "        -- Backward pass\n",
    "        df_do = crit:backward(outputs,target_table)\n",
    "        rnn:backward(inputs_batch, df_do)\n",
    "        \n",
    "        grad_params:view(4,1):renorm(1,2,5)\n",
    "        \n",
    "        rnn:updateParameters(eta)\n",
    "\n",
    "    end\n",
    "\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..av_L/math.floor(train_input:size(1)/b))\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
