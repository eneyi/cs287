{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5';\n",
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_model(dwin, nchar, nclass, hid1, hid2)\n",
    "    -- Model with skip layer from Bengio, standards parameters\n",
    "    -- should be:\n",
    "    -- dwin = 5\n",
    "    -- hid1 = 30\n",
    "    -- hid2 = 100\n",
    "\n",
    "    -- To store the whole model\n",
    "    local dnnlm = nn.Sequential()\n",
    "\n",
    "    -- Layer to embedd (and put the words along the window into one vector)\n",
    "    local LT = nn.Sequential()\n",
    "    local LT_ = nn.LookupTable(nchar,hid1)\n",
    "    LT:add(LT_)\n",
    "    LT:add(nn.View(-1, hid1*dwin))\n",
    "\n",
    "    dnnlm:add(LT)\n",
    "\n",
    "    local concat = nn.ConcatTable()\n",
    "\n",
    "    local lin_tanh = nn.Sequential()\n",
    "    lin_tanh:add(nn.Linear(hid1*dwin,hid2))\n",
    "    lin_tanh:add(nn.Tanh())\n",
    "\n",
    "    local id = nn.Identity()\n",
    "\n",
    "    concat:add(lin_tanh)\n",
    "    concat:add(id)\n",
    "\n",
    "    dnnlm:add(concat)\n",
    "    dnnlm:add(nn.JoinTable(2))\n",
    "    dnnlm:add(nn.Linear(hid1*dwin + hid2, nclass))\n",
    "    dnnlm:add(nn.LogSoftMax())\n",
    "\n",
    "    -- Loss\n",
    "    local criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "    return dnnlm, criterion\n",
    "end\n",
    "\n",
    "function compute_perplexity(gram_input, nnlm, crit, N)\n",
    "    local perp = 0\n",
    "    local context = torch.zeros(N-1)\n",
    "    local probability = torch.zeros(2)\n",
    "    -- Do not predict for the last char\n",
    "    --for i=1,gram_input:size(1)-N do\n",
    "    local size=gram_input:size(1) - (N-1)\n",
    "    for i=1,size do\n",
    "        context:copy(gram_input:narrow(1,i,N-1))\n",
    "        -- Line where the model appears\n",
    "        probability:copy(nnlm:forward(context))\n",
    "        if gram_input[i+(N-1)] == 1 then\n",
    "            L = crit:forward(probability,1)\n",
    "        else\n",
    "            L = crit:forward(probability,2)\n",
    "        end\n",
    "        perp = perp + L\n",
    "    end\n",
    "    perp = math.exp(perp/size)\n",
    "    return perp\n",
    "end\n",
    "\n",
    "\n",
    "function train_model(train_input, train_output, dnnlm, criterion, dwin, nclass, eta, nEpochs, batchSize)\n",
    "    -- Train the model with a mini batch SGD\n",
    "    -- standard parameters are\n",
    "    -- nEpochs = 1\n",
    "    -- batchSize = 32\n",
    "    -- eta = 0.01\n",
    "\n",
    "    -- To store the loss\n",
    "    local av_L = 0\n",
    "\n",
    "    -- Memory allocation\n",
    "    local inputs_batch = torch.DoubleTensor(batchSize,dwin)\n",
    "    local targets_batch = torch.DoubleTensor(batchSize)\n",
    "    local outputs = torch.DoubleTensor(batchSize, nclass)\n",
    "    local df_do = torch.DoubleTensor(batchSize, nclass)\n",
    "    \n",
    "    local train_perplexity = torch.DoubleTensor(nEpochs)\n",
    "    \n",
    "    for i = 1, nEpochs do\n",
    "        -- timing the epoch\n",
    "        local timer = torch.Timer()\n",
    "\n",
    "        av_L = 0\n",
    "        \n",
    "        -- max renorm of the lookup table\n",
    "        dnnlm:get(1):get(1).weight:renorm(2,1,1)\n",
    "        \n",
    "        -- mini batch loop\n",
    "        for t = 1, train_input:size(1), batchSize do\n",
    "            -- Mini batch data\n",
    "            local current_batch_size = math.min(batchSize,train_input:size(1)-t)\n",
    "            inputs_batch:narrow(1,1,current_batch_size):copy(train_input:narrow(1,t,current_batch_size))\n",
    "            targets_batch:narrow(1,1,current_batch_size):copy(train_output:narrow(1,t,current_batch_size))\n",
    "            \n",
    "            -- reset gradients\n",
    "            dnnlm:zeroGradParameters()\n",
    "            --gradParameters:zero()\n",
    "\n",
    "            -- Forward pass (selection of inputs_batch in case the batch is not full, ie last batch)\n",
    "            outputs:narrow(1,1,current_batch_size):copy(dnnlm:forward(inputs_batch:narrow(1,1,current_batch_size)))\n",
    "\n",
    "            -- Average loss computation\n",
    "            local f = criterion:forward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size))\n",
    "            av_L = av_L +f\n",
    "\n",
    "            -- Backward pass\n",
    "            df_do:narrow(1,1,current_batch_size):copy(criterion:backward(outputs:narrow(1,1,current_batch_size), targets_batch:narrow(1,1,current_batch_size)))\n",
    "            dnnlm:backward(inputs_batch:narrow(1,1,current_batch_size), df_do:narrow(1,1,current_batch_size))\n",
    "            dnnlm:updateParameters(eta)\n",
    "            \n",
    "        end\n",
    "            \n",
    "        print('Epoch '..i..': '..timer:time().real)\n",
    "        print('Average Loss: '..av_L/math.floor(train_input:size(1)/batchSize))\n",
    "        \n",
    "        train_perplexity[i] = math.exp(av_L/math.floor(train_input:size(1)/batchSize))\n",
    "    end\n",
    "\n",
    "    return train_perplexity\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/4-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "N = 4\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "\n",
    "input_data_valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "input_data_test = data['input_data_test']:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 20.381507873535\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss: 0.2999279016966\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 20.16481089592\t\n",
       "Average Loss: 0.26833430403236\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.844784021378\t\n",
       "Average Loss: 0.24193435098863\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 17.762979984283\t\n",
       "Average Loss: 0.22844307013896\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 17.731731176376\t\n",
       "Average Loss: 0.21732259188103\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 17.609931945801\t\n",
       "Average Loss: 0.20984310688726\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 17.612291097641\t\n",
       "Average Loss: 0.20524385023812\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 17.596704959869\t\n",
       "Average Loss: 0.2020497821542\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 17.577955961227\t\n",
       "Average Loss: 0.19964882002223\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 17.762266874313\t\n",
       "Average Loss: 0.19777197601831\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 18.534914970398\t\n",
       "Average Loss: 0.19617452139248\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 18.180015087128\t\n",
       "Average Loss: 0.19464074499331\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 17.259115934372\t\n",
       "Average Loss: 0.19310638144052\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 17.277981996536\t\n",
       "Average Loss: 0.19163403265493\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 17.273786783218\t\n",
       "Average Loss: 0.19025300134216\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manualSeed(1)\n",
    "nnlm1, crit = build_model(N-1, 49, 2, 16, 80)\n",
    "perp_train_3, perp_valid_3 = train_model(train_input, train_output, nnlm1, crit, N-1, 2, 0.01, 15, 20, input_data_valid, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/5-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "N = 5\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "\n",
    "input_data_valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "input_data_test = data['input_data_test']:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 17.849504947662\t\n",
       "Average Loss: 0.29443654451786\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 17.788382053375\t\n",
       "Average Loss: 0.27378908120055\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 20.099086999893\t\n",
       "Average Loss: 0.24403272683775\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 17.813330888748\t\n",
       "Average Loss: 0.22213200721034\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 18.144514083862\t\n",
       "Average Loss: 0.20911243675907\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 17.942358016968\t\n",
       "Average Loss: 0.19831868559116\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 17.967022895813\t\n",
       "Average Loss: 0.18999367837257\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 17.963499069214\t\n",
       "Average Loss: 0.18388471579704\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 19.656719923019\t\n",
       "Average Loss: 0.17968586361457\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 18.448729038239\t\n",
       "Average Loss: 0.17670111663555\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 18.227150917053\t\n",
       "Average Loss: 0.17436727230211\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 17.678957939148\t\n",
       "Average Loss: 0.17243752242786\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 17.738479852676\t\n",
       "Average Loss: 0.17078575326792\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 17.798008918762\t\n",
       "Average Loss: 0.16932815903052\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 21.19105887413\t\n",
       "Average Loss: 0.16800128690437\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manualSeed(1)\n",
    "nnlm2, crit = build_model(N-1, 49, 2, 16, 80)\n",
    "perp_train_4, perp_valid_4 = train_model(train_input, train_output, nnlm2, crit, N-1, 2, 0.01, 15, 20, input_data_valid, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.5521\n",
       " 1.5767\n",
       " 1.6266\n",
       " 1.6342\n",
       " 1.6224\n",
       " 1.6164\n",
       " 1.6104\n",
       " 1.6083\n",
       " 1.6069\n",
       " 1.6068\n",
       " 1.6084\n",
       " 1.6115\n",
       " 1.6155\n",
       " 1.6196\n",
       " 1.6231\n",
       "[torch.DoubleTensor of size 15]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp_valid_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../data_preprocessed/6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "N = 6\n",
    "\n",
    "train_input = data['input_matrix_train']\n",
    "train_output = data['output_matrix_train']\n",
    "input_data_train = data['input_data_train']\n",
    "\n",
    "input_data_valid = data['input_data_valid_nospace']:clone()\n",
    "\n",
    "input_data_test = data['input_data_test']:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 18.536489963531\t\n",
       "Average Loss: 0.295621389953\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 17.972072124481\t\n",
       "Average Loss: 0.27468023492365\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3: 18.546638011932\t\n",
       "Average Loss: 0.25618872109793\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4: 19.354636192322\t\n",
       "Average Loss: 0.22655003590524\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5: 17.919018983841\t\n",
       "Average Loss: 0.20997346406349\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 6: 19.95677280426\t\n",
       "Average Loss: 0.19872725299921\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7: 18.224895000458\t\n",
       "Average Loss: 0.18992938442935\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8: 18.835289955139\t\n",
       "Average Loss: 0.18301274359037\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9: 17.934269189835\t\n",
       "Average Loss: 0.17770018348404\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10: 17.851098060608\t\n",
       "Average Loss: 0.17367809783134\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11: 18.178263187408\t\n",
       "Average Loss: 0.1704792645748\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12: 18.148210048676\t\n",
       "Average Loss: 0.16774662850185\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13: 18.001205205917\t\n",
       "Average Loss: 0.16530856897846\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14: 17.900924921036\t\n",
       "Average Loss: 0.16307442759655\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15: 17.944164037704\t\n",
       "Average Loss: 0.16100459655088\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manualSeed(1)\n",
    "nnlm3, crit = build_model(N-1, 49, 2, 16, 80)\n",
    "perp_train_5 = train_model(train_input, train_output, nnlm3, crit, N-1, 2, 0.01, 15, 20, input_data_valid, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
