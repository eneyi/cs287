{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'\n",
    "\n",
    "local Squeeze, parent = torch.class('nn.Squeeze', 'nn.Module')\n",
    "\n",
    "function Squeeze:updateOutput(input)\n",
    "    self.size = input:size()\n",
    "    self.output = input:squeeze()\n",
    "    return self.output\n",
    "end\n",
    "\n",
    "function Squeeze:updateGradInput(input, gradOutput)\n",
    "  self.gradInput = gradOutput:view(self.size)\n",
    "  return self.gradInput  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('2-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  valid_output : LongTensor - size: 3370x50\n",
       "  train : LongTensor - size: 259471x3\n",
       "  nwords : LongTensor - size: 1\n",
       "  valid : LongTensor - size: 3370x51\n",
       "  test : LongTensor - size: 3761x51\n",
       "}\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data['train']:narrow(2,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   14\n",
       "    5\n",
       " 7475\n",
       "[torch.LongTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = train:narrow(2,1,4)\n",
    "train_output = train:narrow(2,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LT = nn.LookupTable(data['nwords'][1],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       "-0.5626 -0.7167 -0.8011  0.1635  0.4544 -2.0875 -0.4934  0.4453  0.4442 -0.8109\n",
       "-0.5626 -0.7167 -0.8011  0.1635  0.4544 -2.0875 -0.4934  0.4453  0.4442 -0.8109\n",
       "-0.5626 -0.7167 -0.8011  0.1635  0.4544 -2.0875 -0.4934  0.4453  0.4442 -0.8109\n",
       "-0.5626 -0.7167 -0.8011  0.1635  0.4544 -2.0875 -0.4934  0.4453  0.4442 -0.8109\n",
       "\n",
       "Columns 11 to 20\n",
       "-0.5965  0.5523  0.7668 -0.8587 -1.5801 -0.4235 -0.4902 -0.7762 -0.1874  0.0707\n",
       "-0.5965  0.5523  0.7668 -0.8587 -1.5801 -0.4235 -0.4902 -0.7762 -0.1874  0.0707\n",
       "-0.5965  0.5523  0.7668 -0.8587 -1.5801 -0.4235 -0.4902 -0.7762 -0.1874  0.0707\n",
       "-0.5965  0.5523  0.7668 -0.8587 -1.5801 -0.4235 -0.4902 -0.7762 -0.1874  0.0707\n",
       "\n",
       "Columns 21 to 30\n",
       "-0.9597 -0.9056 -1.4552 -0.2263 -0.1127 -0.2337  0.9416  1.6251 -1.7943 -0.8021\n",
       "-0.9597 -0.9056 -1.4552 -0.2263 -0.1127 -0.2337  0.9416  1.6251 -1.7943 -0.8021\n",
       "-0.9597 -0.9056 -1.4552 -0.2263 -0.1127 -0.2337  0.9416  1.6251 -1.7943 -0.8021\n",
       "-0.9597 -0.9056 -1.4552 -0.2263 -0.1127 -0.2337  0.9416  1.6251 -1.7943 -0.8021\n",
       "\n",
       "Columns 31 to 40\n",
       " 0.3752  0.1008  1.4687  2.0639 -1.4469  0.2266 -0.2549  0.9683  1.2138  0.7566\n",
       " 0.3752  0.1008  1.4687  2.0639 -1.4469  0.2266 -0.2549  0.9683  1.2138  0.7566\n",
       " 0.3752  0.1008  1.4687  2.0639 -1.4469  0.2266 -0.2549  0.9683  1.2138  0.7566\n",
       " 0.3752  0.1008  1.4687  2.0639 -1.4469  0.2266 -0.2549  0.9683  1.2138  0.7566\n",
       "\n",
       "Columns 41 to 50\n",
       " 0.1574 -0.2614 -2.5482  1.1901  0.4902  0.8573  1.7495 -0.3192  0.3423  0.9114\n",
       " 0.1574 -0.2614 -2.5482  1.1901  0.4902  0.8573  1.7495 -0.3192  0.3423  0.9114\n",
       " 0.1574 -0.2614 -2.5482  1.1901  0.4902  0.8573  1.7495 -0.3192  0.3423  0.9114\n",
       " 0.1574 -0.2614 -2.5482  1.1901  0.4902  0.8573  1.7495 -0.3192  0.3423  0.9114\n",
       "[torch.DoubleTensor of size 4x50]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LT:forward(train_input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"nnlm = nn.Sequential()...\"]:3: attempt to index global 'neuralnet' (a nil value)\nstack traceback:\n\t[string \"nnlm = nn.Sequential()...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01090fbb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"nnlm = nn.Sequential()...\"]:3: attempt to index global 'neuralnet' (a nil value)\nstack traceback:\n\t[string \"nnlm = nn.Sequential()...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01090fbb50"
     ]
    }
   ],
   "source": [
    "nnlm = nn.Sequential()\n",
    "nnlm:add(nn.LookupTable(data['nwords'][1],50))\n",
    "neuralnet:add(nn.View(1,-1,5*50))\n",
    "neuralnet:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "neuralnet:add(nn.Linear(5*dim_hidden,dim_hidden2))\n",
    "neuralnet:add(nn.HardTanh())\n",
    "neuralnet:add(nn.Linear(dim_hidden2, data['nclasses'][1]))\n",
    "neuralnet:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset[i] = {train[i]:view(1,5), train_output[i]}\n",
    "end\n",
    "function dataset:size() return train:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(neuralnet, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.maxIteration = 10\n",
    "trainer:train(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
