{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words2index = {}\n",
    "with open('data/words.dict') as f:\n",
    "    for line in f:\n",
    "        (val, key, num) = line.split()\n",
    "        words2index[key] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2words = {}\n",
    "with open('data/words.dict') as f:\n",
    "    for line in f:\n",
    "        (val, key, num) = line.split()\n",
    "        index2words[int(val)] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_get_Ngram(filepath,words2index,N):\n",
    "    results = []\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            lsplit = [words2index[x] for x in line.split()]\n",
    "            l = np.append(np.repeat(words2index['<s>'],N-1),lsplit)\n",
    "\n",
    "            for i in range(len(lsplit)):\n",
    "                g = l[i:N-1+i]\n",
    "                v = lsplit[i]\n",
    "                results.append((g,v))\n",
    "            results.append((l[-N+1:],words2index['</s>']))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_test_Ngram(filepath, words2index, N, test = False):\n",
    "    results = []\n",
    "    if test == False:\n",
    "        with open(filepath) as f:\n",
    "            i=1\n",
    "            for line in f:\n",
    "                lsplit = line.split()\n",
    "                if lsplit[0] == 'Q':\n",
    "                    topredict = np.array([words2index[x] for x in lsplit[1:]])\n",
    "                if lsplit[0] == 'C':\n",
    "                    l = np.append(np.repeat(words2index['<s>'], N-1),[words2index[x] for x in lsplit[1:-1]])\n",
    "                    lastNgram =  l[-N+1:] \n",
    "                    results.append((lastNgram, topredict))\n",
    "    else:\n",
    "        with open(filepath) as f:\n",
    "            i=1\n",
    "            for line in f:\n",
    "                lsplit = line.split()\n",
    "                if lsplit[0] == 'Q':\n",
    "                    topredict = np.array([words2index[x] for x in lsplit[1:]])\n",
    "                if lsplit[0] == 'C':\n",
    "                    l = np.append(np.repeat(words2index['<s>'], N-1),[words2index[x] for x in lsplit[1:-1]])\n",
    "                    lastNgram =  l[-N+1:] \n",
    "                    results.append((lastNgram, topredict))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def tomatrix(results,train = True):\n",
    "    N = len(results[0][0])+1\n",
    "    if train:\n",
    "        tuplelist = []\n",
    "        for i in range(len(results)):\n",
    "            tuplelist.append(tuple(list(np.append(results[i][0],results[i][1]))))\n",
    "        Count = Counter(tuplelist).most_common()\n",
    "        tooutput = np.empty((len(Count),N+1))\n",
    "\n",
    "        for i in range(len(Count)):\n",
    "            tooutput[i,:] = np.append(np.array(Count[i][0]),Count[i][1])\n",
    "\n",
    "        return tooutput.astype(int)\n",
    "    \n",
    "    else:\n",
    "        tooutput = np.empty((len(results),50+N-1))\n",
    "        \n",
    "        for i in range(len(results)):\n",
    "            tooutput[i,:] = np.hstack((results[i][1],results[i][0]))\n",
    "        \n",
    "        return tooutput.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams = train_get_Ngram('data/train.txt',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = train_get_Ngram('data/train.txt',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589720, 4)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomatrix(trigrams).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_kaggle(filepath):\n",
    "    it = 0\n",
    "    results = []\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            if it == 0 :\n",
    "                it+=1\n",
    "            else:\n",
    "                lsplit = line.split(',')\n",
    "                l = [int(x.rstrip()) for x in lsplit[1:]]\n",
    "                results.append(l)\n",
    "    return np.array(results)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3370, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_kaggle('data/valid_kaggle.txt').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dealing with 1000 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words2index1000 = {}\n",
    "with open('data/words.1000.dict') as f:\n",
    "    for line in f:\n",
    "        (val, key, num) = line.split()\n",
    "        words2index1000[key] = int(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unk_or_index(word,words2index1000):\n",
    "    if word in words2index1000.keys():\n",
    "        return words2index1000[word]\n",
    "    else:\n",
    "        return words2index1000['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "with open('data/valid.1000.txt') as f:\n",
    "    for line in f:\n",
    "        lsplit = [words2index1000[x] for x in line.split()]\n",
    "        l = np.append(np.repeat(words2index1000['<s>'],N-1),lsplit[:-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,1],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
