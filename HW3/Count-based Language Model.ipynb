{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Train format is (number of Ngrams, Ngram_size + 1) with last\n",
    "-- col the count of the N_gram of the line\n",
    "\n",
    "-- Validation format is (number of words to predict, 50 + Ngrams_size -1)\n",
    "-- where the 50 columns stands for the 50 words possibilities in the prediction,\n",
    "-- the next col stands for the current context (goal is to predict the Nth word)\n",
    "\n",
    "\n",
    "myFile = hdf5.open('2-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "train_2 = data['train']\n",
    "validation_2 = data['valid']\n",
    "validation_output = data['valid_output']\n",
    "myFile:close()\n",
    "\n",
    "myFile = hdf5.open('3-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "train_3 = data['train']\n",
    "validation_3 = data['valid']\n",
    "myFile:close()\n",
    "\n",
    "myFile = hdf5.open('4-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "train_4 = data['train']\n",
    "validation_4 = data['valid']\n",
    "myFile:close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function build_context_count(count_tensor)\n",
    "    -- Ngram count (depend on w and context)\n",
    "    -- {'indexN': {index1-...-indexN-1} : count}\n",
    "    local F_c_w = {}\n",
    "    -- F_c dict (independent of w, only context based)\n",
    "    -- {index1-...-indexN-1 : count all words in c}\n",
    "    local F_c = {}\n",
    "    -- N_c dict (independent of w, only context based)\n",
    "    -- {index1-...-indexN-1 : count unique type of words in c}\n",
    "    local N_c = {}\n",
    "\n",
    "    local N = count_tensor:size(1)\n",
    "    local M = count_tensor:size(2)\n",
    "\n",
    "    for i=1, N do\n",
    "        indexN = count_tensor[{i,M-1}]\n",
    "        \n",
    "        -- build the key index1-...-indexN-1\n",
    "        indexes = tostring(count_tensor[{i,1}])\n",
    "        for j=2, M - 2 do\n",
    "            indexes = indexes .. '-' .. tostring(count_tensor[{i,j}])\n",
    "        end\n",
    "        \n",
    "        -- Filling F_c_w\n",
    "        -- case context never seen before:\n",
    "        -- we look for the reduced context (ie index2-...-indexN-1)\n",
    "        if F_c_w[indexN] == nil then\n",
    "            F_c_w[indexN] = {[indexes] = count_tensor[{i, M}]}\n",
    "        else\n",
    "            if F_c_w[indexN][indexes] == nil then\n",
    "                F_c_w[indexN][indexes] = count_tensor[{i, M}]\n",
    "            else\n",
    "                F_c_w[indexN][indexes] = count_tensor[{i, M}] + F_c_w[indexN][indexes]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        -- Updating F_c and F_c\n",
    "        if F_c[indexes] == nil then\n",
    "            F_c[indexes] = count_tensor[{i, M}]\n",
    "            N_c[indexes] = 1\n",
    "        else\n",
    "            F_c[indexes] = count_tensor[{i, M}] + F_c[indexes]\n",
    "            N_c[indexes] = 1 + N_c[indexes]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return F_c_w, F_c, N_c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Prediction with the MLE (with Laplace smoothing)\n",
    "\n",
    "function mle_proba(data, F_c_w, alpha)\n",
    "    local N = data:size(1)\n",
    "    local M = data:size(2)\n",
    "    -- Output format: distribution predicted for each N word along the\n",
    "    -- 50 possibilities\n",
    "    local distribution = torch.DoubleTensor(N, 50)\n",
    "\n",
    "    for i=1, N do\n",
    "        -- build the key index1-...-indexN-1\n",
    "        indexes = tostring(data[{i,51}])\n",
    "        for j=52, M do\n",
    "            indexes = indexes .. '-' .. tostring(data[{i,j}])\n",
    "        end\n",
    "        \n",
    "        -- Look up in the dictionnary for the 50 possible ngrams asked\n",
    "        for j=1, 50 do\n",
    "            indexN = data[{i,j}]\n",
    "            if F_c_w[indexN] == nil or F_c_w[indexN][indexes] == nil then\n",
    "                distribution[{i,j}] = alpha\n",
    "            else\n",
    "                distribution[{i,j}] = F_c_w[indexN][indexes] + alpha\n",
    "            end\n",
    "        end\n",
    "        -- Debug: case where no n-gram were found (only when alpha=0.)\n",
    "        if distribution:narrow(1,i,1):sum(2)[{1,1}] == 0 then\n",
    "            -- Select the first one (most common)\n",
    "            distribution[{i,1}] = 1\n",
    "        end\n",
    "    end\n",
    "    -- normalization (ie we do the MLE given only the 50 possibilities)\n",
    "    distribution:cdiv(torch.expand(distribution:sum(2), N, 50))\n",
    "    \n",
    "    return distribution\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(distribution, true_words)\n",
    "    -- exp of the average of the cross entropy of the true word for each line\n",
    "    -- true words (N_words to predict, one hot true value among 50)\n",
    "    local perp = 0\n",
    "    local N = true_words:size(1)\n",
    "    for i = 1,N do\n",
    "        mm,aa = true_words[i]:max(1)\n",
    "        perp = perp + math.log(distribution[{i, aa[1]}])\n",
    "    end\n",
    "    perp = math.exp(- perp/N)\n",
    "    return perp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_c_w, F_c, N_c = build_context_count(train_2)\n",
    "distribution_mle_2 = mle_proba(validation_2, F_c_w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_c_w, F_c, N_c = build_context_count(train_3)\n",
    "distribution_mle_3 = mle_proba(validation_3, F_c_w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F_c_w, F_c, N_c = build_context_count(train_4)\n",
    "distribution_mle_4 = mle_proba(validation_4, F_c_w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing 2grams\t8.8680603647573\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing 3grams\t21.513973503713\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing 4grams\t29.942969799245\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Results on the validation set\n",
    "print('Result on alpha smoothing 2grams', perplexity(distribution_mle_2, validation_output))\n",
    "print('Result on alpha smoothing 3grams', perplexity(distribution_mle_3, validation_output))\n",
    "print('Result on alpha smoothing 4grams', perplexity(distribution_mle_4, validation_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Witten Bell Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Witten Bell:\n",
    "--\n",
    "-- p_wb(w|c) = (F_c_w + N_c_. * p_wb(w|c'))/(N_c_. + F_c_.)\n",
    "function distribution_proba_WB(data, alpha)\n",
    "    local N = data:size(1)\n",
    "    local M = data:size(2)\n",
    "    local distribution = torch.DoubleTensor(N, 50)\n",
    "    \n",
    "    -- Loading train of the current gram_size\n",
    "    filename = M - 49 .. '-grams.hdf5'\n",
    "    myFile = hdf5.open(filename,'r')\n",
    "    train = myFile:all()['train']\n",
    "    myFile:close()\n",
    "    print(filename)\n",
    "        \n",
    "    -- Compute the distribution for current gram_size\n",
    "    F_c_w, F_c, N_c = build_context_count(train)\n",
    "\n",
    "    -- Witten Bell lambda computation\n",
    "    local first = torch.zeros(N, 50)\n",
    "    local second = torch.zeros(N, 50)\n",
    "    local denom = torch.zeros(N, 50)\n",
    "    for i=1,N do\n",
    "        -- Context\n",
    "        indexes = tostring(data[{i, 51}])\n",
    "        for j=52, M do\n",
    "            indexes = indexes .. '-' .. tostring(data[{i, j}])\n",
    "        end\n",
    "        for j=1,50 do\n",
    "            indexN = data[{i,j}]\n",
    "            -- case data[{i, j}] = <s>\n",
    "            if F_c_w[indexN] == nil or F_c_w[indexN][indexes] == nil then\n",
    "                first[{i, j}] = alpha\n",
    "            else\n",
    "                first[{i, j}] = F_c_w[indexN][indexes] + alpha\n",
    "            end\n",
    "        end  \n",
    "        -- Debug: case where no n-gram were found\n",
    "        if first:narrow(1,i,1):sum(2)[{1,1}] == 0 then\n",
    "            -- Select the first one (most common)\n",
    "            first[{i,1}] = 1\n",
    "        end\n",
    "        \n",
    "        -- if indexes not in N_c keys, also not in F_c keys\n",
    "        -- TODO: merge N_c and F_c\n",
    "        if N_c[indexes] ~= nil then\n",
    "            second:narrow(1,i,1):add(N_c[indexes])\n",
    "            denom:narrow(1,i,1):add(N_c[indexes] + F_c[indexes])\n",
    "        else\n",
    "            denom:narrow(1,i,1):add(1)\n",
    "        end\n",
    "    end\n",
    "    -- case bigram\n",
    "    if M == 51 then\n",
    "        first:cdiv(torch.expand(first:sum(2), N, 50))\n",
    "        return first\n",
    "    else\n",
    "        local next_context = torch.cat(data:narrow(2,1,50), data:narrow(2,52,M - 51), 2)\n",
    "        local distribution_next_context = distribution_proba_WB(next_context, alpha)\n",
    "        -- Recurrence\n",
    "        return first:add(distribution_next_context:cmul(second)):cdiv(denom)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-grams.hdf5\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3-grams.hdf5\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2-grams.hdf5\t\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wB = distribution_proba_WB(validation_4, 1)\n",
    "print(d_wB:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-grams.hdf5\t\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3-grams.hdf5\t\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2-grams.hdf5\t\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "   50\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wB_no = distribution_proba_WB(validation_4, 0)\n",
    "print(d_wB:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.0837  0.0837  0.0853  0.0847  0.0837  0.0837  0.0838  0.0837  0.0941  0.0837\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0838  0.0837  0.0837  0.0838  0.0837  0.0837  0.0847  0.0845  0.0843  0.0843\n",
       "\n",
       "Columns 21 to 30\n",
       " 0.0837  0.0838  0.0863  0.0840  0.0837  0.0837  0.0837  0.0865  0.0837  0.0848\n",
       "\n",
       "Columns 31 to 40\n",
       " 0.0837  0.0843  0.0837  0.0838  0.0852  0.0837  0.0837  0.0838  0.0842  0.0837\n",
       "\n",
       "Columns 41 to 50\n",
       " 0.1815  0.0837  0.0837  0.0848  0.0840  0.0861  0.0837  0.0853  0.0842  0.0837\n",
       "[torch.DoubleTensor of size 1x50]\n",
       "\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wB:narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.0833  0.0000  0.0017  0.0011  0.0000  0.0000  0.0002  0.0000  0.0111  0.0000\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0002  0.0000  0.0000  0.0002  0.0000  0.0000  0.0011  0.0009  0.0007  0.0007\n",
       "\n",
       "Columns 21 to 30\n",
       " 0.0000  0.0002  0.0028  0.0004  0.0000  0.0000  0.0000  0.0030  0.0000  0.0012\n",
       "\n",
       "Columns 31 to 40\n",
       " 0.0000  0.0007  0.0000  0.0002  0.0016  0.0000  0.0000  0.0002  0.0005  0.0000\n",
       "\n",
       "Columns 41 to 50\n",
       " 0.1041  0.0000  0.0000  0.0012  0.0004  0.0026  0.0000  0.0018  0.0005  0.0000\n",
       "[torch.DoubleTensor of size 1x50]\n",
       "\n"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wB_no:narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.0000  0.0000  0.0500  0.0000  0.0000  0.0000  0.0000  0.0000  0.0500  0.0000\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0500  0.0000\n",
       "\n",
       "Columns 21 to 30\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1000  0.0000  0.0500\n",
       "\n",
       "Columns 31 to 40\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "\n",
       "Columns 41 to 50\n",
       " 0.6500  0.0000  0.0000  0.0000  0.0000  0.0500  0.0000  0.0000  0.0000  0.0000\n",
       "[torch.DoubleTensor of size 1x50]\n",
       "\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_3:narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.0000  0.0000  0.0117  0.0078  0.0000  0.0000  0.0013  0.0000  0.0805  0.0000\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0013  0.0000  0.0000  0.0013  0.0000  0.0000  0.0078  0.0065  0.0039  0.0052\n",
       "\n",
       "Columns 21 to 30\n",
       " 0.0000  0.0013  0.0208  0.0026  0.0000  0.0000  0.0000  0.0195  0.0000  0.0078\n",
       "\n",
       "Columns 31 to 40\n",
       " 0.0000  0.0052  0.0000  0.0013  0.0117  0.0000  0.0000  0.0013  0.0039  0.0000\n",
       "\n",
       "Columns 41 to 50\n",
       " 0.7506  0.0000  0.0000  0.0091  0.0026  0.0182  0.0000  0.0130  0.0039  0.0000\n",
       "[torch.DoubleTensor of size 1x50]\n",
       "\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution:narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, true_output = validation_output:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function compute_accuracy(pred, true_output)\n",
    "    max,argmax = pred:max(2)\n",
    "    acc = 0\n",
    "    for i = 1, true_output:size(1) do\n",
    "        if argmax[i][1] == true_output[i][1] then\n",
    "            acc = acc + 1\n",
    "        end\n",
    "    end\n",
    "    score = acc/true_output:size(1)\n",
    "    \n",
    "    return score\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.59258160237389\t\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t0.37952522255193\t\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t0.23412462908012\t\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on Witten Bell \t0.32640949554896\t\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on Witten Bell \t0.25786350148368\t\n"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result on alpha smoothing ', compute_accuracy(distribution, true_output))\n",
    "print('Result on alpha smoothing ', compute_accuracy(distribution_3, true_output))\n",
    "print('Result on alpha smoothing ', compute_accuracy(distribution_4, true_output))\n",
    "print('Result on Witten Bell ', compute_accuracy(d_wB, true_output))\n",
    "print('Result on Witten Bell ', compute_accuracy(d_wB_no, true_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t110.46837660031\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t64.899935042845\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on alpha smoothing \t59.51012776219\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on Witten Bell \t5.52172116585\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Result on Witten Bell \tinf\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Result on alpha smoothing ', perplexity(distribution))\n",
    "print('Result on alpha smoothing ', perplexity(distribution_3))\n",
    "print('Result on alpha smoothing ', perplexity(distribution_4))\n",
    "print('Result on Witten Bell ', perplexity(d_wB))\n",
    "print('Result on Witten Bell ', perplexity(d_wB_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
