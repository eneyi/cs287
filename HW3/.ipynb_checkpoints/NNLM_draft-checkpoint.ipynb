{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('5-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  valid_output : LongTensor - size: 3370x50\n",
       "  train : LongTensor - size: 754037x6\n",
       "  nwords : LongTensor - size: 1\n",
       "  valid : LongTensor - size: 3370x54\n",
       "  test : LongTensor - size: 3761x54\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the counts (used for the Count based language model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = data['nwords'][1]\n",
    "train = data['train']:narrow(2,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = train:narrow(2,1,4)\n",
    "train_output = train:narrow(2,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 50\n",
    "hid2 = 50\n",
    "nnlm = nn.Sequential()\n",
    "\n",
    "tanh = nn.Sequential()\n",
    "tanh:add(nn.LookupTable(nwords,hid1))\n",
    "tanh:add(nn.View(1,-1,dwin*hid1))\n",
    "tanh:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "tanh:add(nn.Linear(dwin*hid1,hid2))\n",
    "tanh:add(nn.Tanh())\n",
    "\n",
    "nnlm:add(tanh)\n",
    "nnlm:add(nn.Linear(hid2, nwords))\n",
    "nnlm:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10001\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnlm:forward(train_input:narrow(1,1,1)):size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset[i] = {train_input[i]:view(1,4), train_output[i]}\n",
    "end\n",
    "function dataset:size() return train:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timer = torch.Timer()\n",
    "trainer = nn.StochasticGradient(nnlm, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.maxIteration = 1\n",
    "trainer:train(dataset)\n",
    "print(timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 50\n",
    "hid2 = 50\n",
    "nnlm = nn.Sequential()\n",
    "\n",
    "LT = nn.Sequential()\n",
    "LT:add(nn.LookupTable(nwords,hid1))\n",
    "LT:add(nn.View(1,-1,dwin*hid1))\n",
    "LT:add(nn.Squeeze())\n",
    "\n",
    "parall = nn.Parallel(2,1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
