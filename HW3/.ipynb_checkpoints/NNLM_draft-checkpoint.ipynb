{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  valid_output : LongTensor - size: 3370x50\n",
       "  train_1000 : LongTensor - size: 696825x7\n",
       "  test : LongTensor - size: 3761x55\n",
       "  nwords : LongTensor - size: 1\n",
       "  train : LongTensor - size: 772670x7\n",
       "  valid : LongTensor - size: 3370x55\n",
       "}\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the counts (used for the Count based language model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = 10001\n",
    "train = data['train']:narrow(2,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = train:narrow(2,1,5)\n",
    "train_output = train:narrow(2,6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 6\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 100\n",
    "nnlm = nn.Sequential()\n",
    "\n",
    "tanh = nn.Sequential()\n",
    "tanh:add(nn.LookupTable(nwords,hid1/dwin))\n",
    "tanh:add(nn.View(1,-1,hid1))\n",
    "tanh:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "tanh:add(nn.Linear(hid1,hid2))\n",
    "tanh:add(nn.Tanh())\n",
    "\n",
    "nnlm:add(tanh)\n",
    "nnlm:add(nn.Linear(hid2, nwords))\n",
    "nnlm:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10001\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnlm:forward(train_input:narrow(1,1,1)):size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset[i] = {train_input[i]:view(1,5), train_output[i]}\n",
    "end\n",
    "function dataset:size() return train:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 6.4245431634655\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 6.4245431634655\t\n",
       "Epoch 1: 1867.2106969357\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.9158270506484\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.9158270506484\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 1851.8256881237\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.8087271387059\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.8087271387059\t\n",
       "Epoch 3: 2067.7188940048\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.6064206043748\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.6064206043748\t\n",
       "Epoch 4: 1839.1438748837\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.5844903921627\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.5844903921627\t\n",
       "Epoch 5: 1832.6268959045\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4698433440264\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4698433440264\t\n",
       "Epoch 6: 1833.8597950935\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4624980810907\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4624980810907\t\n",
       "Epoch 7: 1834.5379061699\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3855606170359\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3855606170359\t\n",
       "Epoch 8: 1838.4308679104\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3781181681479\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3781181681479\t\n",
       "Epoch 9: 1839.4745910168\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3245020409265\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3245020409265\t\n",
       "Epoch 10: 1820.8121240139\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3180288904676\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3180288904676\t\n",
       "Epoch 11: 1806.8632180691\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.2783573349033\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.2783573349033\t\n",
       "Epoch 12: 1801.1834139824\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.2723746036031\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.2723746036031\t\n",
       "Epoch 13: 1806.0853638649\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.2412188396928\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.2412188396928\t\n",
       "Epoch 14: 1801.4268000126\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.234915767834\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.234915767834\t\n",
       "Epoch 15: 1803.8201138973\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.2105918915854\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.2105918915854\t\n",
       "Epoch 16: 1804.5267899036\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.2061212614106\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.2061212614106\t\n",
       "Epoch 17: 1807.6521818638\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.1854116802198\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.1854116802198\t\n",
       "Epoch 18: 1804.7857210636\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.1802477525104\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.1802477525104\t\n",
       "Epoch 19: 1804.3937339783\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.163963303637\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.163963303637\t\n",
       "Epoch 20: 1804.8741080761\t\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--with regularisation:\n",
    "\n",
    "sq_mat = torch.zeros(10001,6)\n",
    "norm_mat = torch.zeros(10001,6)\n",
    "\n",
    "for i = 1, 20 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    if i ~= 1 then\n",
    "        sq_mat:copy(torch.pow(nnlm:findModules('nn.LookupTable')[1].weight,2))\n",
    "        norm_mat:copy(torch.expandAs(sq_mat:sum(2), sq_mat))\n",
    "        nnlm:findModules('nn.LookupTable')[1].weight:cdiv(norm_mat)\n",
    "    end\n",
    "    \n",
    "    trainer = nn.StochasticGradient(nnlm, criterion)\n",
    "    trainer.learningRate = 0.01\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--save\n",
    "torch.save('nnlm1',nnlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.3886357784844\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.1514940863395\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.0717284582465\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.0314867838883\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.00779912249\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.00779912249\t\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Without regularisation:\n",
    "\n",
    "trainer = nn.StochasticGradient(nnlm, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.maxIteration = 5\n",
    "trainer:train(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative de Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--load:\n",
    "nnlm = torch.load('../../nnlm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag = data['valid_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kag = data['valid_output']\n",
    "valid = data['valid']\n",
    "valid_topredict = valid:narrow(2,1,50)\n",
    "valid_input = valid:narrow(2,51,5)\n",
    "preds_valid = nnlm:forward(valid_input)\n",
    "kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    kag_pred_valid[i]:copy(preds_valid[i]:index(1,valid_topredict[i])):exp()\n",
    "end\n",
    "norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "kag_pred_valid:cdiv(norm_mat_)\n",
    "perp = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    perp = perp + math.log(kag_pred_valid[i][aa[1]])\n",
    "end\n",
    "perp = math.exp(-perp/preds_valid:size(1))\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_valid = nnlm:forward(valid_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    kag_pred_valid[i]:copy(preds_valid[i]:index(1,valid_topredict[i])):exp()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "kag_pred_valid:cdiv(norm_mat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42581602373887\t\n"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    m,a = kag_pred_valid[i]:max(1)\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    if aa[1] == a[1] then\n",
    "        acc = acc + 1\n",
    "    end\n",
    "end\n",
    "print(acc/3370.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(distribution)\n",
    "    local perp = torch.DoubleTensor(distribution:size(1), distribution:size(2))\n",
    "    perp:copy(distribution)\n",
    "    n = distribution:size(1) * distribution:size(2)\n",
    "    return math.exp(-(1/n)* perp:log():sum())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.309662260245\t\n"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    perp = perp + math.log(kag_pred_valid[i][aa[1]])\n",
    "end\n",
    "perp = math.exp(-perp/preds_valid:size(1))\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49076318656613\t\n"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kag_pred_valid[preds_valid:size(1)][aa[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : LongTensor - size: 1x5\n",
       "  2 : LongTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 6\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 100\n",
    "dnnlm = nn.Sequential()\n",
    "\n",
    "LT = nn.Sequential()\n",
    "LT:add(nn.LookupTable(nwords,hid1/dwin))\n",
    "LT:add(nn.View(1,-1,hid1))\n",
    "LT:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm:add(LT)\n",
    "\n",
    "concat = nn.ConcatTable()\n",
    "\n",
    "lin_tanh = nn.Sequential()\n",
    "lin_tanh:add(nn.Linear(hid1,hid2))\n",
    "lin_tanh:add(nn.Tanh())\n",
    "\n",
    "id = nn.Identity()\n",
    "\n",
    "concat:add(lin_tanh)\n",
    "concat:add(id)\n",
    "\n",
    "dnnlm:add(concat)\n",
    "dnnlm:add(nn.JoinTable(1))\n",
    "dnnlm:add(nn.Linear(hid2+hid1, nwords))\n",
    "dnnlm:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = train_input[8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt = dnnlm:forward(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 130\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.JoinTable(1):forward(ttt):size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.705445706632\t\n"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_mat:sum(2):max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 6.0753078968396\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 6.0753078968396\t\n",
       "Epoch 2: 2378.5694739819\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.9075009795102\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.9075009795102\t\n",
       "Epoch 3: 2383.4352579117\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.7951605307499\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.7951605307499\t\n",
       "Epoch 4: 2360.0455019474\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.7137464722437\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.7137464722437\t\n",
       "Epoch 5: 2359.0405631065\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.6505833421658\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.6505833421658\t\n",
       "Epoch 6: 2364.4075038433\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.6016661823111\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.6016661823111\t\n",
       "Epoch 7: 2357.3720500469\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.5607049309392\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.5607049309392\t\n",
       "Epoch 8: 2360.9850211143\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.5264242272571\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.5264242272571\t\n",
       "Epoch 9: 2362.8160278797\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4981025271048\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4981025271048\t\n",
       "Epoch 10: 2359.8637549877\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4717365583531\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4717365583531\t\n",
       "Epoch 11: 2363.4240169525\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4497181814615\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4497181814615\t\n",
       "Epoch 12: 2363.7275400162\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4319642996491\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4319642996491\t\n",
       "Epoch 13: 4948.130671978\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.4142337359248\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.4142337359248\t\n",
       "Epoch 14: 2365.0248579979\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3984644474863\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3984644474863\t\n",
       "Epoch 15: 2369.2235422134\t\n"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--with regularisation:\n",
    "\n",
    "sq_mat = torch.zeros(10001,6)\n",
    "norm_mat = torch.zeros(10001,6)\n",
    "\n",
    "\n",
    "for i = 2, 15 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    if i ~= 1 then\n",
    "        sq_mat:copy(torch.pow(dnnlm:findModules('nn.LookupTable')[1].weight,2))\n",
    "        norm_mat:copy(torch.expandAs(sq_mat:sum(2), sq_mat))\n",
    "        nnlm:findModules('nn.LookupTable')[1].weight:cdiv(norm_mat)\n",
    "    end\n",
    "    \n",
    "    trainer = nn.StochasticGradient(dnnlm, criterion)\n",
    "    trainer.learningRate = 0.01\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    kag_pred_valid[i]:copy(dnnlm:forward(valid_input[i]):index(1,valid_topredict[i])):exp()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "kag_pred_valid:cdiv(norm_mat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57833827893175\t\n"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    m,a = kag_pred_valid[i]:max(1)\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    if aa[1] == a[1] then\n",
    "        acc = acc + 1\n",
    "    end\n",
    "end\n",
    "print(acc/3370.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CE = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    CE = CE + math.log(kag_pred_valid[i][aa[1]])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perplexity is equal to: 7.3734290599113\t\n"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Perplexity is equal to: '.. math.exp(-CE/preds_valid:size(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = data['test']\n",
    "test_topredict = test_data:narrow(2,1,50)\n",
    "test_input = test_data:narrow(2,51,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag_pred_test = torch.Tensor(test_data:size(1),50)\n",
    "for i = 1,test_data:size(1) do\n",
    "    kag_pred_test[i]:copy(dnnlm:forward(test_input[i]):index(1,test_topredict[i])):exp()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_mat_ = torch.zeros(test_data:size(1),50)\n",
    "norm_mat_:copy(torch.expandAs(kag_pred_test:sum(2), kag_pred_test))\n",
    "kag_pred_test:cdiv(norm_mat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'tocsv_1.f5'\n",
    "myFile = hdf5.open(filename, 'w')\n",
    "myFile:write(filename, kag_pred_test)\n",
    "myFile:close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with 4-grams and changing embeddings size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../../5-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train5 = data['train_nocounts']\n",
    "train_input5 = train5:narrow(2,1,4)\n",
    "train_output5 = train5:narrow(2,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset5={};\n",
    "for i=1,train5:size(1) do \n",
    "  dataset5[i] = {train_input5[i]:view(1,4), train_output5[i]}\n",
    "end\n",
    "function dataset5:size() return train5:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kag5 = data['valid_output']\n",
    "valid5 = data['valid']\n",
    "valid_topredict5 = valid5:narrow(2,1,50)\n",
    "valid_input5 = valid5:narrow(2,51,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nwords = 10001\n",
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 80\n",
    "dnnlm2 = nn.Sequential()\n",
    "\n",
    "LT2 = nn.Sequential()\n",
    "LT1 = nn.LookupTable(nwords,hid1)\n",
    "LT2:add(LT1)\n",
    "LT2:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm2:add(LT2)\n",
    "\n",
    "concat2 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2 = nn.Sequential()\n",
    "lin_tanh2:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2:add(nn.Tanh())\n",
    "\n",
    "id2 = nn.Identity()\n",
    "\n",
    "concat2:add(lin_tanh2)\n",
    "concat2:add(id2)\n",
    "\n",
    "dnnlm2:add(concat2)\n",
    "dnnlm2:add(nn.JoinTable(1))\n",
    "dnnlm2:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "dnnlm2:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kag_pred_valid5 = torch.Tensor(valid_input5:size(1),50)\n",
    "norm_mat_5 = torch.zeros(valid_input5:size(1),50)\n",
    "sq_mat = torch.zeros(10001,30)\n",
    "\n",
    "val_res = torch.Tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--with regularisation:\n",
    "\n",
    "for i = 1, 1 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT1.weight:renorm(2,2,1)\n",
    "    \n",
    "    trainer2 = nn.StochasticGradient(dnnlm2, criterion)\n",
    "    trainer2.learningRate = 0.005\n",
    "    trainer2.maxIteration = 1\n",
    "    trainer2:train(dataset5)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "    kag_pred_valid5:zero()\n",
    "\n",
    "    for i = 1,valid5:size(1) do\n",
    "        kag_pred_valid5[i]:copy(dnnlm2:forward(valid_input5[i]):index(1,valid_topredict5[i])):exp()\n",
    "    end\n",
    "    \n",
    "    norm_mat_5:zero()\n",
    "    norm_mat_5:copy(torch.expandAs(kag_pred_valid5:sum(2), kag_pred_valid5))\n",
    "    kag_pred_valid5:cdiv(norm_mat_5)\n",
    "    \n",
    "    CE = 0\n",
    "    for i = 1,kag_pred_valid5:size(1) do\n",
    "        mm,aa = kag5[i]:max(1)\n",
    "        CE = CE + math.log(kag_pred_valid5[i][aa[1]])\n",
    "    end\n",
    "    \n",
    "    val_res[i] = math.exp(-CE/kag_pred_valid5:size(1))\n",
    "    print('Perplexity on valid: '..val_res[i])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7071  0.7071\n",
       " 0.7071  0.7071\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../../5-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  train_nocounts : DoubleTensor - size: 887522x5\n",
       "  train_1000 : DoubleTensor - size: 887522x5\n",
       "  test : LongTensor - size: 3761x54\n",
       "  train : LongTensor - size: 754037x6\n",
       "  nwords : LongTensor - size: 1\n",
       "  valid : LongTensor - size: 3370x54\n",
       "  train_1000_nocounts : LongTensor - size: 620208x6\n",
       "  valid_output : LongTensor - size: 3370x50\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train5 = data['train_nocounts']\n",
    "train_input5 = train5:narrow(2,1,4)\n",
    "train_output5 = train5:narrow(2,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output5:max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = 10001\n",
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 80\n",
    "dnnlm2 = nn.Sequential()\n",
    "\n",
    "LT2 = nn.Sequential()\n",
    "LT1 = nn.LookupTable(nwords,hid1)\n",
    "LT2:add(LT1)\n",
    "LT2:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm2:add(LT2)\n",
    "\n",
    "concat2 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2 = nn.Sequential()\n",
    "lin_tanh2:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2:add(nn.Tanh())\n",
    "\n",
    "id2 = nn.Identity()\n",
    "\n",
    "concat2:add(lin_tanh2)\n",
    "concat2:add(id2)\n",
    "\n",
    "dnnlm2:add(concat2)\n",
    "dnnlm2:add(nn.JoinTable(2))\n",
    "dnnlm2:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "dnnlm2:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = dnnlm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param, gradparam = model:getParameters()\n",
    "batchsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1completed in (sec): 575.05744695663\t\n",
       "Average Loss on train: 7.922858046091\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2completed in (sec): 559.13870000839\t\n",
       "Average Loss on train: 6.9411545443104\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3completed in (sec): 554.5067191124\t\n",
       "Average Loss on train: 6.7439821096093\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4completed in (sec): 549.67982292175\t\n",
       "Average Loss on train: 6.6323669364111\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5completed in (sec): 554.31065011024\t\n",
       "Average Loss on train: 6.5619067452224\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e = 1,5 do\n",
    "    timer = torch.Timer()\n",
    "    avLoss = 0\n",
    "    \n",
    "    LT1.weight:renorm(2,2,1)\n",
    "    \n",
    "    for t = 1,train5:size(1),batchsize do\n",
    "    -- for t = 1,1,1 do\n",
    "        inputs = torch.zeros(math.min(batchsize,train5:size(1)-t+1),dwin)\n",
    "        targets = torch.zeros(math.min(batchsize,train5:size(1)-t+1))\n",
    "        k = 1\n",
    "\n",
    "        for i = t,math.min(t+batchsize-1,train5:size(1)) do\n",
    "            targets[k] = train_output5[i]\n",
    "            inputs[k] = train_input5[i]\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        function feval(x)\n",
    "            collectgarbage()\n",
    "\n",
    "            if x ~= param then\n",
    "                param:copy(x)\n",
    "            end\n",
    "\n",
    "            gradparam:zero()\n",
    "\n",
    "            outputs = model:forward(inputs)\n",
    "            L = criterion:forward(outputs,targets)\n",
    "            dL = criterion:backward(outputs,targets)\n",
    "            model:backward(inputs,dL)\n",
    "\n",
    "            avLoss = avLoss + L\n",
    "\n",
    "            return L,gradparam\n",
    "\n",
    "        end\n",
    "\n",
    "        sgdState = {learningRate = 0.005}\n",
    "\n",
    "        optim.sgd(feval,param,sgdState)\n",
    "\n",
    "    end\n",
    "    print('Epoch '.. e ..'completed in (sec): '..timer:time().real)\n",
    "    print('Average Loss on train: '.. avLoss/math.floor(train5:size(1)/batchsize))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 6completed in (sec): 549.36122202873\t\n",
       "Average Loss on train: 6.5131466153525\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 7completed in (sec): 551.05811500549\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss on train: 6.4747375418067\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 8completed in (sec): 550.92656683922\t\n",
       "Average Loss on train: 6.4417819511198\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 9completed in (sec): 551.57784795761\t\n",
       "Average Loss on train: 6.4115803367962\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10completed in (sec): 554.43027997017\t\n",
       "Average Loss on train: 6.3828083099609\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 11completed in (sec): 626.0440788269\t\n",
       "Average Loss on train: 6.3552663748153\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 12completed in (sec): 553.7746090889\t\n",
       "Average Loss on train: 6.3291940073103\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 13completed in (sec): 574.50339698792\t\n",
       "Average Loss on train: 6.3046952082911\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 14completed in (sec): 549.67145800591\t\n",
       "Average Loss on train: 6.2816738423971\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 15completed in (sec): 552.563601017\t\n",
       "Average Loss on train: 6.259960740982\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 16completed in (sec): 545.59943294525\t\n",
       "Average Loss on train: 6.2394098589757\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 17completed in (sec): 545.86253595352\t\n",
       "Average Loss on train: 6.2199206628517\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 18completed in (sec): 546.13499903679\t\n",
       "Average Loss on train: 6.2014229691107\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 19completed in (sec): 545.99924588203\t\n",
       "Average Loss on train: 6.1838587273178\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20completed in (sec): 545.85558891296\t\n",
       "Average Loss on train: 6.1671739215651\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e = 6,20 do\n",
    "    timer = torch.Timer()\n",
    "    avLoss = 0\n",
    "    \n",
    "    LT1.weight:renorm(2,2,1)\n",
    "    \n",
    "    for t = 1,train5:size(1),batchsize do\n",
    "    -- for t = 1,1,1 do\n",
    "        inputs = torch.zeros(math.min(batchsize,train5:size(1)-t+1),dwin)\n",
    "        targets = torch.zeros(math.min(batchsize,train5:size(1)-t+1))\n",
    "        k = 1\n",
    "\n",
    "        for i = t,math.min(t+batchsize-1,train5:size(1)) do\n",
    "            targets[k] = train_output5[i]\n",
    "            inputs[k] = train_input5[i]\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        function feval(x)\n",
    "            collectgarbage()\n",
    "\n",
    "            if x ~= param then\n",
    "                param:copy(x)\n",
    "            end\n",
    "\n",
    "            gradparam:zero()\n",
    "\n",
    "            outputs = model:forward(inputs)\n",
    "            L = criterion:forward(outputs,targets)\n",
    "            dL = criterion:backward(outputs,targets)\n",
    "            model:backward(inputs,dL)\n",
    "\n",
    "            avLoss = avLoss + L\n",
    "\n",
    "            return L,gradparam\n",
    "\n",
    "        end\n",
    "\n",
    "        sgdState = {learningRate = 0.005}\n",
    "\n",
    "        optim.sgd(feval,param,sgdState)\n",
    "\n",
    "    end\n",
    "    print('Epoch '.. e ..'completed in (sec): '..timer:time().real)\n",
    "    print('Average Loss on train: '.. avLoss/math.floor(train5:size(1)/batchsize))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag = data['valid_output']\n",
    "valid = data['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_topredict = valid:narrow(2,1,50)\n",
    "valid_input = valid:narrow(2,51,4)\n",
    "preds_valid = model:forward(valid_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2295951783231\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_valid = model:forward(valid_input)\n",
    "kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    kag_pred_valid[i]:copy(preds_valid[i]:index(1,valid_topredict[i])):exp()\n",
    "end\n",
    "norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "kag_pred_valid:cdiv(norm_mat_)\n",
    "perp = 0\n",
    "for i = 1,preds_valid:size(1) do\n",
    "    mm,aa = kag[i]:max(1)\n",
    "    perp = perp + math.log(kag_pred_valid[i][aa[1]])\n",
    "end\n",
    "perp = math.exp(-perp/preds_valid:size(1))\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-gram & optim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('../../6-grams.hdf5','r')\n",
    "data6 = myFile:all()\n",
    "myFile:close()\n",
    "\n",
    "train6 = data6['train_nocounts']\n",
    "train_input6 = train6:narrow(2,1,5)\n",
    "train_output6 = train6:narrow(2,5,1)\n",
    "\n",
    "kag = data6['valid_output']\n",
    "valid = data6['valid']\n",
    "\n",
    "valid_topredict = valid:narrow(2,1,50)\n",
    "valid_input = valid:narrow(2,51,5)\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "nwords = 10001\n",
    "N = 6\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 100\n",
    "dnnlm3 = nn.Sequential()\n",
    "\n",
    "LT2_3 = nn.Sequential()\n",
    "LT1_3 = nn.LookupTable(nwords,hid1)\n",
    "LT2_3:add(LT1_3)\n",
    "LT2_3:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2_3:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm3:add(LT2_3)\n",
    "\n",
    "concat2_3 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2_3 = nn.Sequential()\n",
    "lin_tanh2_3:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2_3:add(nn.Tanh())\n",
    "\n",
    "id2_3 = nn.Identity()\n",
    "\n",
    "concat2_3:add(lin_tanh2_3)\n",
    "concat2_3:add(id2_3)\n",
    "\n",
    "dnnlm3:add(concat2_3)\n",
    "dnnlm3:add(nn.JoinTable(2))\n",
    "dnnlm3:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "dnnlm3:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = dnnlm3\n",
    "param2, gradparam2 = model2:getParameters()\n",
    "batchsize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1completed in (sec): 776.11843895912\t\n",
       "Average Loss on train: 5.6922936051666\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perpelixty on validation: 26.189493239985\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2completed in (sec): 753.64157891273\t\n",
       "Average Loss on train: 4.4914361966547\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perpelixty on validation: 62.840384796315\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3completed in (sec): 750.57159090042\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Average Loss on train: 4.119245002276\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perpelixty on validation: 104.2369303411\t\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e = 1,20 do\n",
    "    timer = torch.Timer()\n",
    "    avLoss = 0\n",
    "    \n",
    "    LT1_3.weight:renorm(2,2,1)\n",
    "    \n",
    "    for t = 1,train6:size(1),batchsize do\n",
    "    -- for t = 1,1,1 do\n",
    "        inputs = torch.zeros(math.min(batchsize,train6:size(1)-t+1),dwin)\n",
    "        targets = torch.zeros(math.min(batchsize,train6:size(1)-t+1))\n",
    "        k = 1\n",
    "\n",
    "        for i = t,math.min(t+batchsize-1,train6:size(1)) do\n",
    "            targets[k] = train_output6[i]\n",
    "            inputs[k] = train_input6[i]\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        function feval(x)\n",
    "            collectgarbage()\n",
    "\n",
    "            if x ~= param2 then\n",
    "                param2:copy(x)\n",
    "            end\n",
    "\n",
    "            gradparam2:zero()\n",
    "\n",
    "            outputs = model2:forward(inputs)\n",
    "            L = criterion:forward(outputs,targets)\n",
    "            dL = criterion:backward(outputs,targets)\n",
    "            model2:backward(inputs,dL)\n",
    "\n",
    "            avLoss = avLoss + L\n",
    "\n",
    "            return L,gradparam2\n",
    "\n",
    "        end\n",
    "\n",
    "        sgdState = {learningRate = 0.01}\n",
    "\n",
    "        optim.sgd(feval,param2,sgdState)\n",
    "\n",
    "    end\n",
    "    print('Epoch '.. e ..'completed in (sec): '..timer:time().real)\n",
    "    print('Average Loss on train: '.. avLoss/math.floor(train6:size(1)/batchsize))\n",
    "    \n",
    "--     preds_valid = model2:forward(valid_input)\n",
    "--     kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "--     for i = 1,preds_valid:size(1) do\n",
    "--         kag_pred_valid[i]:copy(preds_valid[i]:index(1,valid_topredict[i])):exp()\n",
    "--     end\n",
    "--     norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "--     norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "--     kag_pred_valid:cdiv(norm_mat_)\n",
    "--     perp = 0\n",
    "--     for i = 1,preds_valid:size(1) do\n",
    "--         mm,aa = kag[i]:max(1)\n",
    "--         perp = perp + math.log(kag_pred_valid[i][aa[1]])\n",
    "--     end\n",
    "--     perp = math.exp(-perp/preds_valid:size(1))\n",
    "--     print('Perpelixty on validation: '..perp)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag = data6['valid_output']\n",
    "valid = data6['valid']\n",
    "\n",
    "valid_topredict = valid:narrow(2,1,50)\n",
    "valid_input = valid:narrow(2,51,5)\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "nwords = 10001\n",
    "N = 6\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 100\n",
    "dnnlm4 = nn.Sequential()\n",
    "\n",
    "LT2_4 = nn.Sequential()\n",
    "LT1_4 = nn.LookupTable(nwords,hid1)\n",
    "LT2_4:add(LT1_4)\n",
    "LT2_4:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2_4:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm4:add(LT2_4)\n",
    "\n",
    "concat2_4 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2_4 = nn.Sequential()\n",
    "lin_tanh2_4:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2_4:add(nn.Tanh())\n",
    "\n",
    "id2_4 = nn.Identity()\n",
    "\n",
    "concat2_4:add(lin_tanh2_4)\n",
    "concat2_4:add(id2_4)\n",
    "\n",
    "dnnlm4:add(concat2_4)\n",
    "dnnlm4:add(nn.JoinTable(2))\n",
    "dnnlm4:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "dnnlm4:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = dnnlm4\n",
    "param3, gradparam3 = model3:getParameters()\n",
    "batchsize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e = 1,20 do\n",
    "    timer = torch.Timer()\n",
    "    avLoss = 0\n",
    "    \n",
    "    LT1_4.weight:renorm(2,2,1)\n",
    "    \n",
    "    for t = 1,train6:size(1),batchsize do\n",
    "    -- for t = 1,1,1 do\n",
    "        inputs = torch.zeros(math.min(batchsize,train6:size(1)-t+1),dwin)\n",
    "        targets = torch.zeros(math.min(batchsize,train6:size(1)-t+1))\n",
    "        k = 1\n",
    "\n",
    "        for i = t,math.min(t+batchsize-1,train6:size(1)) do\n",
    "            targets[k] = train_output6[i]\n",
    "            inputs[k] = train_input6[i]\n",
    "            k = k + 1\n",
    "        end\n",
    "\n",
    "        function feval(x)\n",
    "            collectgarbage()\n",
    "\n",
    "            if x ~= param3 then\n",
    "                param3:copy(x)\n",
    "            end\n",
    "\n",
    "            gradparam3:zero()\n",
    "\n",
    "            outputs = model3:forward(inputs)\n",
    "            L = criterion:forward(outputs,targets)\n",
    "            dL = criterion:backward(outputs,targets)\n",
    "            model3:backward(inputs,dL)\n",
    "\n",
    "            avLoss = avLoss + L\n",
    "\n",
    "            return L,gradparam3\n",
    "\n",
    "        end\n",
    "\n",
    "        sgdState = {learningRate = 0.01}\n",
    "\n",
    "        optim.sgd(feval,param3,sgdState)\n",
    "\n",
    "    end\n",
    "    print('Epoch '.. e ..'completed in (sec): '..timer:time().real)\n",
    "    print('Average Loss on train: '.. avLoss/math.floor(train6:size(1)/batchsize))\n",
    "    \n",
    "--     preds_valid = model3:forward(valid_input)\n",
    "--     kag_pred_valid = torch.Tensor(preds_valid:size(1),50)\n",
    "--     for i = 1,preds_valid:size(1) do\n",
    "--         kag_pred_valid[i]:copy(preds_valid[i]:index(1,valid_topredict[i])):exp()\n",
    "--     end\n",
    "--     norm_mat_ = torch.zeros(preds_valid:size(1),50)\n",
    "--     norm_mat_:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "--     kag_pred_valid:cdiv(norm_mat_)\n",
    "--     perp = 0\n",
    "--     for i = 1,preds_valid:size(1) do\n",
    "--         mm,aa = kag[i]:max(1)\n",
    "--         perp = perp + math.log(kag_pred_valid[i][aa[1]])\n",
    "--     end\n",
    "--     perp = math.exp(-perp/preds_valid:size(1))\n",
    "--     print('Perpelixty on validation: '..perp)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
