{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('6-grams.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  train_nocounts : DoubleTensor - size: 887522x6\n",
       "  train_1000 : DoubleTensor - size: 887522x6\n",
       "  test : LongTensor - size: 3761x55\n",
       "  train : LongTensor - size: 772670x7\n",
       "  nwords : LongTensor - size: 1\n",
       "  valid : LongTensor - size: 3370x55\n",
       "  train_1000_nocounts : LongTensor - size: 696825x7\n",
       "  valid_output : LongTensor - size: 3370x50\n",
       "}\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = 10001\n",
    "train = data['train_nocounts']:narrow(2,1,5)\n",
    "train_input = train:narrow(2,1,4)\n",
    "train_output = train:narrow(2,5,1)\n",
    "\n",
    "valid_topredict = data['valid']:narrow(2,1,50)\n",
    "valid_input = data['valid']:narrow(2,51,4)\n",
    "valid_output = data['valid_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset[i] = {train_input[i]:view(1,4), train_output[i]}\n",
    "end\n",
    "function dataset:size() return train:size(1) end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 25.\n",
    "hid2 = 80\n",
    "dnnlm = nn.Sequential()\n",
    "\n",
    "LT = nn.Sequential()\n",
    "LT_ = nn.LookupTable(nwords,hid1)\n",
    "LT:add(LT_)\n",
    "LT:add(nn.View(1,-1,hid1*dwin))\n",
    "LT:add(nn.Squeeze()) \n",
    "\n",
    "dnnlm:add(LT)\n",
    "\n",
    "concat = nn.ConcatTable()\n",
    "\n",
    "lin_tanh = nn.Sequential()\n",
    "lin_tanh:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh:add(nn.Tanh())\n",
    "\n",
    "id = nn.Identity()\n",
    "\n",
    "concat:add(lin_tanh)\n",
    "concat:add(id)\n",
    "\n",
    "dnnlm:add(concat)\n",
    "dnnlm:add(nn.JoinTable(1))\n",
    "dnnlm:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "dnnlm:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kag_pred_valid = torch.Tensor(valid_input:size(1),50)\n",
    "norm_mat = torch.zeros(valid_input:size(1),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 6.0318624286766\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 6.0318624286766\t\n",
       "Epoch 1: 3777.7758259773\t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.8055104706363\t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1, 1 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT_.weight:renorm(2,1,1)\n",
    "    \n",
    "    trainer = nn.StochasticGradient(dnnlm, criterion)\n",
    "    trainer.learningRate = 0.005\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "    -- Evaluatin perplexity on validation:\n",
    "    kag_pred_valid:zero()\n",
    "\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        kag_pred_valid[i]:copy(dnnlm:forward(valid_input[i]):index(1, valid_topredict[i])):exp()\n",
    "    end\n",
    "    \n",
    "    norm_mat:zero()\n",
    "    norm_mat:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "    kag_pred_valid:cdiv(norm_mat)\n",
    "    \n",
    "    CE = 0\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        mm,aa = valid_output[i]:max(1)\n",
    "        CE = CE + math.log(kag_pred_valid[i][aa[1]])\n",
    "    end\n",
    "    \n",
    "    val_res = math.exp(-CE/kag_pred_valid:size(1))\n",
    "    print('Perplexity on valid: '..val_res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.5262946470065\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.5262946470065\t\n",
       "Epoch 2: 3650.7690629959\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.367000690273\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.3135841631288\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.3135841631288\t\n",
       "Epoch 3: 3620.9383718967\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.1739799494824\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.1731558547035\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.1731558547035\t\n",
       "Epoch 4: 3621.2016150951\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0952584824508\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 5.0705901211415\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 5.0705901211415\t\n",
       "Epoch 5: 3621.7603421211\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0733376594642\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.990063610058\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.990063610058\t\n",
       "Epoch 6: 3621.431210041\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0518462706023\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.924878490994\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.924878490994\t\n",
       "Epoch 7: 3621.6165070534\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0917286919629\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.8692454295903\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.8692454295903\t\n",
       "Epoch 8: 3622.6675741673\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0872367119564\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.8223222568596\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.8223222568596\t\n",
       "Epoch 9: 3623.1487159729\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 5.0862021600192\t\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 2, 9 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT_.weight:renorm(2,1,1)\n",
    "    \n",
    "    trainer = nn.StochasticGradient(dnnlm, criterion)\n",
    "    trainer.learningRate = 0.005\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "    -- Evaluatin perplexity on validation:\n",
    "    kag_pred_valid:zero()\n",
    "\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        kag_pred_valid[i]:copy(dnnlm:forward(valid_input[i]):index(1, valid_topredict[i])):exp()\n",
    "    end\n",
    "    \n",
    "    norm_mat:zero()\n",
    "    norm_mat:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "    kag_pred_valid:cdiv(norm_mat)\n",
    "    \n",
    "    CE = 0\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        mm,aa = valid_output[i]:max(1)\n",
    "        CE = CE + math.log(kag_pred_valid[i][aa[1]])\n",
    "    end\n",
    "    \n",
    "    val_res = math.exp(-CE/kag_pred_valid:size(1))\n",
    "    print('Perplexity on valid: '..val_res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.7050212120435\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.7050212120435\t\n",
       "Epoch 1: 3821.8381781578\t\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 4.9898126480392\t\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1,1  do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT_.weight:renorm(2,1,1)\n",
    "    \n",
    "    trainer = nn.StochasticGradient(dnnlm, criterion)\n",
    "    trainer.learningRate = 0.001\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "    -- Evaluatin perplexity on validation:\n",
    "    kag_pred_valid:zero()\n",
    "\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        kag_pred_valid[i]:copy(dnnlm:forward(valid_input[i]):index(1, valid_topredict[i])):exp()\n",
    "    end\n",
    "    \n",
    "    norm_mat:zero()\n",
    "    norm_mat:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "    kag_pred_valid:cdiv(norm_mat)\n",
    "    \n",
    "    CE = 0\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        mm,aa = valid_output[i]:max(1)\n",
    "        CE = CE + math.log(kag_pred_valid[i][aa[1]])\n",
    "    end\n",
    "    \n",
    "    val_res = math.exp(-CE/kag_pred_valid:size(1))\n",
    "    print('Perplexity on valid: '..val_res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 25.\n",
    "hid2 = 80\n",
    "nce = nn.Sequential()\n",
    "\n",
    "LTnce = nn.Sequential()\n",
    "LT_nce = nn.LookupTable(nwords,hid1)\n",
    "LTnce:add(LT_nce)\n",
    "LTnce:add(nn.View(1,-1,hid1*dwin))\n",
    "LTnce:add(nn.Squeeze()) \n",
    "\n",
    "nce:add(LTnce)\n",
    "\n",
    "concatnce = nn.ConcatTable()\n",
    "\n",
    "lin_tanhnce = nn.Sequential()\n",
    "lin_tanhnce:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanhnce:add(nn.Tanh())\n",
    "\n",
    "idnce = nn.Identity()\n",
    "\n",
    "concatnce:add(lin_tanhnce)\n",
    "concatnce:add(id)\n",
    "\n",
    "nce:add(concatnce)\n",
    "nce:add(nn.JoinTable(1))\n",
    "final_linear = nn.Linear(hid2+hid1*dwin, nwords)\n",
    "nce:add(final_linear)\n",
    "nce:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwords = 10001\n",
    "train = data['train']:narrow(2,1,6)\n",
    "train_input = train:narrow(2,1,5)\n",
    "train_output = train:narrow(2,6,1)\n",
    "\n",
    "valid_topredict = data['valid']:narrow(2,1,50)\n",
    "valid_input = data['valid']:narrow(2,51,5)\n",
    "valid_output = data['valid_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "N = 6\n",
    "dwin = N-1\n",
    "hid1 = 30.\n",
    "hid2 = 100\n",
    "nnlm = nn.Sequential()\n",
    "\n",
    "LT2 = nn.Sequential()\n",
    "LT_2 = nn.LookupTable(nwords,hid1)\n",
    "LT2:add(LT_2)\n",
    "LT2:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2:add(nn.Squeeze()) \n",
    "\n",
    "nnlm:add(LT2)\n",
    "\n",
    "concat2 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2 = nn.Sequential()\n",
    "lin_tanh2:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2:add(nn.Tanh())\n",
    "\n",
    "id2 = nn.Identity()\n",
    "\n",
    "concat2:add(lin_tanh2)\n",
    "concat2:add(id2)\n",
    "\n",
    "nnlm:add(lin_tanh2)\n",
    "-- nnlm:add(nn.JoinTable(2))\n",
    "nnlm:add(nn.Linear(hid2, nwords))\n",
    "nnlm:add(nn.LogSoftMax())\n",
    "\n",
    "parameters,gradParameters = nnlm:getParameters()\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 1: 432.65068387985\t\n",
       "Average Loss: 6.3998842631204\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 7.231744842634\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2: 466.20021295547\t\n",
       "Average Loss: 5.931770989839\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 6.711158500633\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kag_pred_valid = torch.Tensor(valid_input:size(1),50)\n",
    "norm_mat = torch.zeros(valid_input:size(1),50)\n",
    "\n",
    "for i = 1,5  do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT_2.weight:renorm(2,1,1)\n",
    "    \n",
    "    av_L = 0\n",
    "    for t = 1, train_input:size(1), batchSize do\n",
    "      -- create mini batch\n",
    "        inputs = torch.Tensor(batchSize,dwin)\n",
    "        targets = torch.Tensor(batchSize)\n",
    "        k = 1\n",
    "        for i = t,math.min(t+batchSize-1,train_input:size(1)) do\n",
    "         -- load new sample\n",
    "            inputs[k] = train_input[i]\n",
    "            targets[k] = train_output[i]\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        gradParameters:zero()\n",
    "        outputs = nnlm:forward(inputs:narrow(1,1,k-1))\n",
    "        L = criterion:forward(outputs:narrow(1,1,k-1), targets:narrow(1,1,k-1))\n",
    "        dL = criterion:backward(outputs:narrow(1,1,k-1), targets:narrow(1,1,k-1))\n",
    "        nnlm:backward(inputs:narrow(1,1,k-1), dL)\n",
    "        \n",
    "        nnlm:updateParameters(0.1)\n",
    "        \n",
    "        av_L = av_L + L\n",
    "    end\n",
    "        \n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    print('Average Loss: '..av_L/math.floor(train_input:size(1)/batchSize))\n",
    "    \n",
    "    -- Evaluatin perplexity on validation:\n",
    "    kag_pred_valid:zero()\n",
    "\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        kag_pred_valid[i]:copy(nnlm:forward(valid_input[i]):index(1, valid_topredict[i])):exp()\n",
    "    end\n",
    "    \n",
    "    norm_mat:zero()\n",
    "    norm_mat:copy(torch.expandAs(kag_pred_valid:sum(2), kag_pred_valid))\n",
    "    kag_pred_valid:cdiv(norm_mat)\n",
    "    \n",
    "    CE = 0\n",
    "    for i = 1, valid_input:size(1) do\n",
    "        mm,aa = valid_output[i]:max(1)\n",
    "        CE = CE + math.log(kag_pred_valid[i][aa[1]])\n",
    "    end\n",
    "    \n",
    "    val_res = math.exp(-CE/kag_pred_valid:size(1))\n",
    "    print('Perplexity on valid: '..val_res)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perplexity on valid: 4.9898126480392\t\n"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with stochgrad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "N = 5\n",
    "dwin = N-1\n",
    "hid1 = 25.\n",
    "hid2 = 80\n",
    "nnlm = nn.Sequential()\n",
    "\n",
    "LT2 = nn.Sequential()\n",
    "LT_2 = nn.LookupTable(nwords,hid1)\n",
    "LT2:add(LT_2)\n",
    "LT2:add(nn.View(1,-1,hid1*dwin))\n",
    "LT2:add(nn.Squeeze()) \n",
    "\n",
    "nnlm:add(LT2)\n",
    "\n",
    "concat2 = nn.ConcatTable()\n",
    "\n",
    "lin_tanh2 = nn.Sequential()\n",
    "lin_tanh2:add(nn.Linear(hid1*dwin,hid2))\n",
    "lin_tanh2:add(nn.Tanh())\n",
    "\n",
    "id2 = nn.Identity()\n",
    "\n",
    "concat2:add(lin_tanh2)\n",
    "concat2:add(id2)\n",
    "\n",
    "nnlm:add(concat2)\n",
    "nnlm:add(nn.JoinTable(1))\n",
    "nnlm:add(nn.Linear(hid2+hid1*dwin, nwords))\n",
    "nnlm:add(nn.LogSoftMax())\n",
    "\n",
    "parameters,gradParameters = nnlm:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset2={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset2[i] = {train_input[i]:view(1,4), train_output[i]}\n",
    "end\n",
    "function dataset2:size() return train:size(1) end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 4.450221031528\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 4.450221031528\t\n",
       "Epoch 1: 474.23745799065\t\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1, 1 do\n",
    "    \n",
    "    timer = torch.Timer()\n",
    "    \n",
    "    LT_2.weight:renorm(2,1,1)\n",
    "    \n",
    "    trainer = nn.StochasticGradient(nnlm, criterion)\n",
    "    trainer.learningRate = 0.005\n",
    "    trainer.maxIteration = 1\n",
    "    trainer:train(dataset2)\n",
    "    print('Epoch '..i..': '..timer:time().real)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
