{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  H5Z_FILTER_CONFIG_ENCODE_ENABLED : 1\n",
       "  H5F_ACC_RDWR : 1\n",
       "  _getTorchType : function: 0x0b67ac18\n",
       "  H5F_OBJ_FILE : 1\n",
       "  H5S_ALL : 0\n",
       "  H5F_OBJ_GROUP : 4\n",
       "  C : userdata: 0x0b935790\n",
       "  H5P_DEFAULT : 0\n",
       "  _describeObject : function: 0x0b67ac98\n",
       "  H5Z_FILTER_NBIT : 5\n",
       "  _debugMode : false\n",
       "  _getObjectType : function: 0x0b67ac58\n",
       "  H5F_OBJ_ALL : 31\n",
       "  _getObjectName : function: 0x0b67ac38\n",
       "  version : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 8\n",
       "      3 : 15\n",
       "    }\n",
       "  H5Z_FILTER_SHUFFLE : 2\n",
       "  HDF5Group : table: 0x0b6acf98\n",
       "  open : function: 0x0b6a7da0\n",
       "  H5Z_FILTER_SZIP : 4\n",
       "  H5F_OBJ_ATTR : 16\n",
       "  H5Z_FILTER_FLETCHER32 : 3\n",
       "  H5F_OBJ_DATATYPE : 8\n",
       "  debugMode : function: 0x0b6a7d20\n",
       "  H5F_ACC_EXCL : 4\n",
       "  H5Z_FILTER_NONE : 0\n",
       "  _testUtils : \n",
       "    {\n",
       "      deepAlmostEq : function: 0x0b6a7ce0\n",
       "      withTmpDir : function: 0x0b6a7c40\n",
       "    }\n",
       "  _nativeTypeForTensorType : function: 0x0b6aa398\n",
       "  H5F_ACC_TRUNC : 2\n",
       "  _config : \n",
       "    {\n",
       "      HDF5_INCLUDE_PATH : /Users/virgileaudi/anaconda/include\n",
       "      HDF5_LIBRARIES : /Users/virgileaudi/anaconda/lib/libhdf5.dylib;/Users/virgileaudi/anaconda/lib/libhdf5_hl.dylib;/Users/virgileaudi/anaconda/lib/libhdf5.dylib;/Users/virgileaudi/anaconda/lib/libz.dylib;/usr/lib/libdl.dylib;/usr/lib/libm.dylib\n",
       "    }\n",
       "  _loadObject : function: 0x0b6a7d80\n",
       "  DataSetOptions : table: 0x0b684188\n",
       "  HDF5DataSet : table: 0x0b19e030\n",
       "  H5Z_FILTER_RESERVED : 256\n",
       "  _logger : \n",
       "    {\n",
       "      error : function: 0x0b6d95e8\n",
       "      warn : function: 0x0b6d95e8\n",
       "      debug : function: 0x0b6d9630\n",
       "    }\n",
       "  H5F_ACC_RDONLY : 0\n",
       "  _fletcher32Available : function: 0x0b67acb8\n",
       "  H5Z_FILTER_CONFIG_DECODE_ENABLED : 2\n",
       "  ffi : \n",
       "    {\n",
       "      abi : function: builtin#202\n",
       "      copy : function: builtin#200\n",
       "      errno : function: builtin#198\n",
       "      typeinfo : function: builtin#193\n",
       "      alignof : function: builtin#196\n",
       "      cdef : function: builtin#189\n",
       "      C : userdata: 0x0b25b158\n",
       "      cast : function: builtin#191\n",
       "      load : function: builtin#205\n",
       "      offsetof : function: builtin#197\n",
       "      sizeof : function: builtin#195\n",
       "      string : function: builtin#199\n",
       "      metatype : function: builtin#203\n",
       "      new : function: builtin#190\n",
       "      arch : x64\n",
       "      os : OSX\n",
       "      gc : function: builtin#204\n",
       "      fill : function: builtin#201\n",
       "      istype : function: builtin#194\n",
       "      typeof : function: builtin#192\n",
       "    }\n",
       "  H5Z_FILTER_ERROR : -1\n",
       "  _outputTypeForTensorType : function: 0x0b634e58\n",
       "  H5Z_FILTER_MAX : 65535\n",
       "  h5t : \n",
       "    {\n",
       "      STD_B32LE : 50331728\n",
       "      IEEE_F32BE : 50331703\n",
       "      NATIVE_B16 : 50331694\n",
       "      NATIVE_HSIZE : 50331698\n",
       "      NO_CLASS : -1\n",
       "      NATIVE_UINT_FAST32 : 50331681\n",
       "      STD_B8LE : 50331724\n",
       "      STD_I64BE : 50331715\n",
       "      NATIVE_LONG : 50331662\n",
       "      NATIVE_DOUBLE : 50331691\n",
       "      TIME : 2\n",
       "      NATIVE_INT16 : 50331670\n",
       "      NATIVE_LLONG : 50331688\n",
       "      STD_I8BE : 50331709\n",
       "      STD_B64LE : 50331730\n",
       "      NATIVE_HSSIZE : 50331699\n",
       "      STD_B32BE : 50331729\n",
       "      INTEGER : 0\n",
       "      NATIVE_INT64 : 50331682\n",
       "      STD_I8LE : 50331708\n",
       "      STD_I32LE : 50331712\n",
       "      NATIVE_SCHAR : 50331656\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      NATIVE_INT_FAST16 : 50331674\n",
       "      NATIVE_INT : 50331660\n",
       "      BITFIELD : 4\n",
       "      NATIVE_UINT_LEAST16 : 50331673\n",
       "      NATIVE_INT_LEAST16 : 50331672\n",
       "      IEEE_F64LE : 50331704\n",
       "      NATIVE_INT_FAST64 : 50331686\n",
       "      NATIVE_UINT_FAST64 : 50331687\n",
       "      NATIVE_UINT_LEAST64 : 50331685\n",
       "      NATIVE_INT_LEAST64 : 50331684\n",
       "      ENUM : 8\n",
       "      NATIVE_UINT64 : 50331683\n",
       "      NATIVE_HBOOL : 50331701\n",
       "      NATIVE_ULONG : 50331663\n",
       "      NATIVE_INT_FAST32 : 50331680\n",
       "      NATIVE_HADDR : 50331697\n",
       "      NATIVE_UINT : 50331661\n",
       "      NCLASSES : 11\n",
       "      NATIVE_UINT_LEAST32 : 50331679\n",
       "      NATIVE_INT_LEAST32 : 50331678\n",
       "      STD_U64LE : 50331722\n",
       "      NATIVE_UINT32 : 50331677\n",
       "      NATIVE_SHORT : 50331658\n",
       "      NATIVE_INT32 : 50331676\n",
       "      VLEN : 9\n",
       "      ARRAY : 10\n",
       "      STD_U16LE : 50331718\n",
       "      STD_B16LE : 50331726\n",
       "      STD_I64LE : 50331714\n",
       "      NATIVE_UINT16 : 50331671\n",
       "      NATIVE_UINT_FAST8 : 50331669\n",
       "      STD_B16BE : 50331727\n",
       "      NATIVE_INT_FAST8 : 50331668\n",
       "      FLOAT : 1\n",
       "      REFERENCE : 7\n",
       "      STD_U32LE : 50331720\n",
       "      NATIVE_USHORT : 50331659\n",
       "      NATIVE_ULLONG : 50331689\n",
       "      NATIVE_INT8 : 50331664\n",
       "      IEEE_F32LE : 50331702\n",
       "      STD_U8BE : 50331717\n",
       "      NATIVE_INT_LEAST8 : 50331666\n",
       "      NATIVE_UINT8 : 50331665\n",
       "      NATIVE_B32 : 50331695\n",
       "      NATIVE_HERR : 50331700\n",
       "      NATIVE_OPAQUE : 50331736\n",
       "      NATIVE_LDOUBLE : 50331692\n",
       "      NATIVE_UINT_LEAST8 : 50331667\n",
       "      COMPOUND : 6\n",
       "      STD_REF_OBJ : 50331739\n",
       "      NATIVE_UINT_FAST16 : 50331675\n",
       "      NATIVE_B64 : 50331696\n",
       "      STD_U16BE : 50331719\n",
       "      STD_REF_DSETREG : 50331740\n",
       "      NATIVE_B8 : 50331693\n",
       "      STD_I32BE : 50331713\n",
       "      IEEE_F64BE : 50331705\n",
       "      NATIVE_FLOAT : 50331690\n",
       "      NATIVE_UCHAR : 50331657\n",
       "      STD_U32BE : 50331721\n",
       "      OPAQUE : 5\n",
       "      STD_B64BE : 50331731\n",
       "      STD_U8LE : 50331716\n",
       "      STD_I16BE : 50331711\n",
       "      STD_B8BE : 50331725\n",
       "      STRING : 3\n",
       "      STD_I16LE : 50331710\n",
       "      STD_U64BE : 50331723\n",
       "    }\n",
       "  HDF5File : table: 0x0b6b3c50\n",
       "  H5Z_FILTER_SCALEOFFSET : 6\n",
       "  H5Z_FILTER_DEFLATE : 1\n",
       "  H5F_ACC_CREAT : 16\n",
       "  H5F_UNLIMITED : 18446744073709551615ULL\n",
       "  _deflateAvailable : function: 0x0bbfcbe8\n",
       "  _inDebugMode : function: 0x0b6a7d60\n",
       "  H5F_OBJ_LOCAL : 32\n",
       "  H5S_SELECT_SET : 0\n",
       "  _datatypeName : function: 0x0b67abd8\n",
       "  H5F_ACC_DEBUG : 8\n",
       "  H5F_OBJ_DATASET : 2\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('SST1.hdf5','r')\n",
    "og_train_input = myFile:read('train_input'):all()\n",
    "og_test_input = myFile:read('test_input'):all()\n",
    "nfeatures = myFile:read('nfeatures'):all()\n",
    "og_valid_input = myFile:read('valid_input'):all()\n",
    "og_train_output = myFile:read('train_output'):all()\n",
    "og_valid_output = myFile:read('valid_output'):all()\n",
    "nclasses = myFile:read('nclasses'):all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 17837\n",
       "[torch.IntTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation LogReg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function logreg(Xtrain,Ytrain,nfeatures,ep_max,m,eta,lambda)\n",
    "    \n",
    "    local shuffle = torch.LongTensor(Xtrain:size(1))\n",
    "    \n",
    "    local W = torch.cat(torch.zeros(1,5),torch.ones(nfeatures[1],5),1)\n",
    "    local b = torch.ones(5):view(-1,1)\n",
    "\n",
    "    local grad_W = torch.zeros(nfeatures[1]+1,5)\n",
    "    local grad_b = torch.zeros(5):view(-1,1)\n",
    "\n",
    "    local z = torch.ones(5):view(-1,1)\n",
    "    local yhat = torch.ones(5):view(-1,1)\n",
    "    local grad_L_dz = torch.ones(5):view(-1,1)\n",
    "    local grad_L_W = torch.zeros(nfeatures[1]+1,5)\n",
    "    \n",
    "    local c_s = 1\n",
    "    \n",
    "    for ep = 1,ep_max do\n",
    "        \n",
    "        timer = torch.Timer()\n",
    "\n",
    "        shuffle:copy(torch.randperm(Xtrain:size(1)):type('torch.LongTensor'))\n",
    "        \n",
    "        local tot_Loss = 0\n",
    "        \n",
    "        for it = 1,math.floor(Xtrain:size(1)/m) do\n",
    "\n",
    "            \n",
    "            grad_W:zero()\n",
    "            grad_b:zero()\n",
    "\n",
    "            for i = (m*(it-1)+1),m*it do\n",
    "\n",
    "                --current sentence:\n",
    "                c_s = shuffle[i]\n",
    "\n",
    "                --evaluate z:\n",
    "                z:copy(W:index(1,Xtrain[c_s]:type('torch.LongTensor')):sum(1):add(b)):view(-1,1)\n",
    "\n",
    "                --evaluate y_hat:\n",
    "                yhat = torch.exp(z)/(z:exp():sum())\n",
    "\n",
    "                --evaluate the loss:\n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = tot_Loss - z[Ytrain[c_s]][1] + math.log((z-(z:max())):exp():sum())+z:max()\n",
    "                end\n",
    "                --evaluate the gradients:\n",
    "                -- First with respect to dz (which is equal to db):\n",
    "\n",
    "                grad_L_dz:copy(yhat)\n",
    "                grad_L_dz[Ytrain[c_s]]:csub(1)\n",
    "\n",
    "\n",
    "                --Then with respect to dW:\n",
    "                grad_L_W:zero()\n",
    "                grad_L_W:indexAdd(1,Xtrain[c_s]:type('torch.LongTensor'),torch.expand(grad_L_dz,5,53):t())\n",
    "                grad_L_W[1]:zero()\n",
    "\n",
    "                --Update the gradients and total Loss\n",
    "                grad_W:add(grad_L_W*(1/m))\n",
    "                grad_b:add(grad_L_dz*1/m)\n",
    "                \n",
    "\n",
    "            end\n",
    "\n",
    "            --Update the parameters:\n",
    "            if (it%10) == 0 then\n",
    "                \n",
    "                W:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_W:mul(eta))\n",
    "                b:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_b:mul(eta))\n",
    "                \n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = Xtrain:size(1)*tot_Loss/m  + (0.5)*lambda*(torch.pow(W,2):sum()+torch.pow(b,2):sum())\n",
    "                end\n",
    "                \n",
    "            else\n",
    "                W:csub(grad_W:mul(eta))\n",
    "                b:csub(grad_b:mul(eta))\n",
    "                \n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = Xtrain:size(1)*tot_Loss/m  + (0.5)*lambda*(torch.pow(W,2):sum()+torch.pow(b,2):sum())\n",
    "                end\n",
    "                \n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        print('Time elapsed for epoch ' .. ep ..': ' .. timer:time().real .. ' seconds',\"\\n\")\n",
    "        print('Approximative Loss for the last batch for epoch ' .. ep ..': ' .. tot_Loss,\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return W,b,tot_Loss\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict(Xvalid,W,b,Yvalid)\n",
    "    local Yvalid = Yvalid or Nil\n",
    "    local z = torch.zeros(5):view(-1,1)\n",
    "    local Ypred = torch.IntTensor(Xvalid:size()[1])\n",
    "    local max = torch.zeros(1)\n",
    "    local accu = 0\n",
    "    \n",
    "    for i = 1,Xvalid:size()[1] do\n",
    "        z:copy(W:index(1,Xvalid[i]:type('torch.LongTensor')):sum(1):add(b)):view(-1,1)\n",
    "        max, Ypred[i] = z:max(1)\n",
    "        \n",
    "        if Yvalid then\n",
    "            if Yvalid[i] == Ypred[i] then\n",
    "                accu = accu + 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if Yvalid then\n",
    "        print(\"Accuracy: \" .. accu/Xvalid:size()[1])\n",
    "        return Ypred,accu/Xvalid:size()[1]\n",
    "    else\n",
    "        return Ypred\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hyperparam_ = torch.zeros(27,4)\n",
    "m_  = torch.Tensor({10,20,50})\n",
    "eta_ = torch.Tensor({0.1,1,10})\n",
    "lambda_ = torch.Tensor({0.1,1,10})\n",
    "\n",
    "for i = 0,2 do\n",
    "    for z = 1,9 do\n",
    "        Hyperparam_[9*i+z][1] = m_[i+1]\n",
    "    end\n",
    "end\n",
    "\n",
    "for i = 1,3 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam_[z*9+i][2] = eta_[1]\n",
    "        end\n",
    "end\n",
    "\n",
    "for i = 4,6 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam_[z*9+i][2] = eta_[2]\n",
    "        end\n",
    "end\n",
    "\n",
    "for i = 7,9 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam_[z*9+i][2] = eta_[3]\n",
    "        end\n",
    "end\n",
    "\n",
    "a = torch.Tensor({0.1,1,10})\n",
    "for i =1,8 do\n",
    "    a = torch.cat(a,torch.Tensor({0.1,1,10}),1)\n",
    "end\n",
    "\n",
    "Hyperparam_:narrow(2,3,1):copy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model 1\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 90.170253992081 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 96583231.052828\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.37238873751135\t\n",
       "\n",
       "\t\n",
       "Model 2\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.094061851501 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 273989274.79566\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.39600363306085\t\n",
       "\n",
       "\t\n",
       "Model 3\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 90.135372161865 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 359828878804.67\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.38692098092643\t\n",
       "\n",
       "\t\n",
       "Model 4\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.97724199295 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 549432386.35858\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.39872842870118\t\n",
       "\n",
       "\t\n",
       "Model 5\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.613371133804 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 7201.6681538974\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3969118982743\t\n",
       "\n",
       "\t\n",
       "Model 6\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.314417123795 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 28657053.052252\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.40326975476839\t\n",
       "\n",
       "\t\n",
       "Model 7\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 90.959356784821 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 4.4921173782327e+14\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.34059945504087\t\n",
       "\n",
       "\t\n",
       "Model 8\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.495013952255 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 7258700949.7864\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.37965485921889\t\n",
       "\n",
       "\t\n",
       "Model 9\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 90.077297925949 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 165834.18225976\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3433242506812\t\n",
       "\n",
       "\t\n",
       "Model 10\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 91.049170017242 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 8319497.9832026\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.37057220708447\t\n",
       "\n",
       "\t\n",
       "Model 11\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 88.51426410675 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 3743725179.2258\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.36330608537693\t\n",
       "\n",
       "\t\n",
       "Model 12\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.211131095886 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 19517801965217\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.38147138964578\t\n",
       "\n",
       "\t\n",
       "Model 13\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 90.944530010223 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 291571740702.86\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.39237057220708\t\n",
       "\n",
       "\t\n",
       "Model 14\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 88.403025865555 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 204871439.14933\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.39872842870118\t\n",
       "\n",
       "\t\n",
       "Model 15\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 87.462001085281 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 384082.82816249\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.4141689373297\t\n",
       "\n",
       "\t\n",
       "Model 16\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.259872913361 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 615917173.72596\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.35513169845595\t\n",
       "\n",
       "\t\n",
       "Model 17\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.143746852875 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 10215221222288\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.34604904632153\t\n",
       "\n",
       "\t\n",
       "Model 18\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 87.634598970413 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 2167053.0126602\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.36421435059037\t\n",
       "\n",
       "\t\n",
       "Model 19\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 86.65366601944 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 486000057014.99\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.33514986376022\t\n",
       "\n",
       "\t\n",
       "Model 20\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 87.831337928772 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 168830762.78491\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.34514078110808\t\n",
       "\n",
       "\t\n",
       "Model 21\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 99.856812953949 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 2225834912.1133\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3433242506812\t\n",
       "\n",
       "\t\n",
       "Model 22\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 92.176315784454 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 381038629.01043\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.39237057220708\t\n",
       "\n",
       "\t\n",
       "Model 23\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 89.168220996857 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 6790950361580.1\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3905540417802\t\n",
       "\n",
       "\t\n",
       "Model 24\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 88.528124094009 seconds\t"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 54688809438.579\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.40599455040872\t\n",
       "\n",
       "\t\n",
       "Model 25\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 88.885103940964 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 391665920.07192\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.42415985467757\t\n",
       "\n",
       "\t\n",
       "Model 26\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 93.600172996521 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 2.052267997119e+17\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3905540417802\t\n",
       "\n",
       "\t\n",
       "Model 27\t\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 91.470647096634 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 8067215662769.6\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.38510445049955\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1,27 do\n",
    "    print('Model '..i,'\\n')\n",
    "    math.randomseed(1234)\n",
    "    W, b, L = logreg(og_train_input,og_train_output,nfeatures,1,Hyperparam_[i][1],Hyperparam_[i][2],Hyperparam_[i][3])\n",
    "    Validpred, Hyperparam_[i][4] = predict(og_valid_input,W,b,og_valid_output)\n",
    "    print('\\n')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max,argmax = Hyperparam_:max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 19   7   3  25\n",
       "[torch.LongTensor of size 1x4]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 50.0000\n",
       " 10.0000\n",
       "  0.1000\n",
       "  0.4242\n",
       "[torch.DoubleTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hyperparam_[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 86.669154882431 seconds\t\n",
       "\t\n",
       "Approximative Loss for the last batch for epoch 1: 8.4182306826948e+18\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.randomseed(1234)\n",
    "W, b, L = logreg(og_train_input,og_train_output,nfeatures,1,50,10,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.36512261580381\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.61474840100244\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validpred, acc_val = predict(og_valid_input,W,b,og_valid_output)\n",
    "Trainpred, acc_train  = predict(og_train_input,W,b,og_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math.randomseed(1234)\n",
    "W, b, L = logreg(og_train_input,og_train_output,nfeatures,1,20,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossval SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function linearSVM(Xtrain,Ytrain,nfeatures,ep_max,m,eta,lambda)\n",
    "    local shuffle = torch.LongTensor(Xtrain:size(1))\n",
    "    \n",
    "    local W = torch.cat(torch.zeros(1,5),torch.ones(nfeatures[1],5),1)\n",
    "    local b = torch.ones(5):view(-1,1)\n",
    "\n",
    "    local grad_W = torch.zeros(nfeatures[1]+1,5)\n",
    "    local grad_b = torch.zeros(5):view(-1,1)\n",
    "\n",
    "    local yhat = torch.ones(5):view(-1,1)\n",
    "    local y_temp = torch.zeros(5):view(-1,1)\n",
    "    local grad_L_dy = torch.ones(5):view(-1,1)\n",
    "    local grad_L_W = torch.zeros(nfeatures[1]+1,5)\n",
    "    \n",
    "    local c_s = 1\n",
    "    \n",
    "    for ep = 1,ep_max do\n",
    "        \n",
    "        timer = torch.Timer()\n",
    "\n",
    "        shuffle:copy(torch.randperm(Xtrain:size(1)):type('torch.LongTensor'))\n",
    "        \n",
    "        local tot_Loss = 0\n",
    "        \n",
    "        for it = 1,math.floor(Xtrain:size(1)/m) do\n",
    "\n",
    "            tot_Loss = 0\n",
    "            grad_W:zero()\n",
    "            grad_b:zero()\n",
    "\n",
    "            for i = (m*(it-1)+1),m*it do\n",
    "\n",
    "                --current sentence:\n",
    "                c_s = shuffle[i]\n",
    "\n",
    "                --evaluate y_hat:\n",
    "                y_hat = W:index(1,Xtrain[c_s]:type('torch.LongTensor')):sum(1):add(b):view(-1,1)\n",
    "\n",
    "                --evaluate the loss:\n",
    "                \n",
    "                y_temp:copy(y_hat)\n",
    "                y_temp[Ytrain[c_s]]:fill(-9999)\n",
    "                max_c,argmax_c = y_temp:max(1)\n",
    "                \n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = tot_Loss + math.max(0,1-y_hat[Ytrain[c_s]][1]+max_c[1][1])\n",
    "                end\n",
    "                \n",
    "                -- First with respect to dy (which is equal to db):\n",
    "\n",
    "                grad_L_dy:zero()\n",
    "                if (y_hat[Ytrain[c_s]][1]-max_c[1][1])<1 then\n",
    "                    grad_L_dy[Ytrain[c_s]] = -1\n",
    "                    grad_L_dy[argmax_c[1][1]] = 1\n",
    "                end\n",
    "\n",
    "                --evaluate the gradients:\n",
    "                --Then with respect to dW:\n",
    "                grad_L_W:zero()\n",
    "                grad_L_W:indexAdd(1,Xtrain[c_s]:type('torch.LongTensor'),torch.expand(grad_L_dy,5,53):t())\n",
    "                grad_L_W[1]:zero()\n",
    "\n",
    "                --Update the gradients and total Loss\n",
    "                grad_W:add(grad_L_W*(1/m))\n",
    "                grad_b:add(grad_L_dy*(1/m))\n",
    "\n",
    "            end\n",
    "\n",
    "            --Update the parameters:\n",
    "            \n",
    "            if (it%10) == 0 then \n",
    "                W:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_W:mul(eta))\n",
    "                b:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_b:mul(eta))\n",
    "                \n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = Xtrain:size(1)*tot_Loss/m  + (0.5)*lambda*(torch.pow(W,2):sum()+torch.pow(b,2):sum())\n",
    "                end\n",
    "                \n",
    "            else\n",
    "                W:csub(grad_W:mul(eta))\n",
    "                b:csub(grad_b:mul(eta))\n",
    "                if it == math.floor(Xtrain:size(1)/m) then\n",
    "                    tot_Loss = Xtrain:size(1)*tot_Loss/m + (0.5)*lambda*(torch.pow(W,2):sum()+torch.pow(b,2):sum())\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        print('Time elapsed for epoch ' .. ep ..': ' .. timer:time().real .. ' seconds',\"\\n\")\n",
    "        print('Approximative Loss for epoch ' .. ep ..': ' .. tot_Loss,\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return W,b,tot_Loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hyperparam = torch.zeros(27,4)\n",
    "m_  = torch.Tensor({10,20,50})\n",
    "eta_ = torch.Tensor({0.1,1,10})\n",
    "lambda_ = torch.Tensor({0.1,1,10})\n",
    "\n",
    "for i = 0,2 do\n",
    "    for z = 1,9 do\n",
    "        Hyperparam[9*i+z][1] = m_[i+1]\n",
    "    end\n",
    "end\n",
    "\n",
    "for i = 1,3 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam[z*9+i][2] = eta_[1]\n",
    "        end\n",
    "end\n",
    "\n",
    "for i = 4,6 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam[z*9+i][2] = eta_[2]\n",
    "        end\n",
    "end\n",
    "\n",
    "for i = 7,9 do\n",
    "        for z = 0,2 do\n",
    "            Hyperparam[z*9+i][2] = eta_[3]\n",
    "        end\n",
    "end\n",
    "\n",
    "a = torch.Tensor({0.1,1,10})\n",
    "for i =1,8 do\n",
    "    a = torch.cat(a,torch.Tensor({0.1,1,10}),1)\n",
    "end\n",
    "\n",
    "Hyperparam:narrow(2,3,1):copy(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1,27 do\n",
    "    print('Model '..i,'\\n')\n",
    "    math.randomseed(1234)\n",
    "    Ws, bs, Ls = linearSVM(og_train_input,og_train_output,nfeatures,1,Hyperparam[i][1],Hyperparam[i][2],Hyperparam[i][3])\n",
    "    Validpreds, Hyperparam[i][4] = predict(og_valid_input,Ws,bs,og_valid_output)\n",
    "    print('\\n')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max,argmax = Hyperparam:max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "argmax[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hyperparam[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math.randomseed(1234)\n",
    "Ws, bs, Ls = linearSVM(og_train_input,og_train_output,nfeatures,3,50,1,0.1)\n",
    "Validpreds, accus = predict(og_valid_input,Ws,bs,og_valid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math.randomseed(1234)\n",
    "Ws, bs, Ls = linearSVM(og_train_input,og_train_output,nfeatures,5,50,1,10)\n",
    "Validpreds, accus = predict(og_valid_input,Ws,bs,og_valid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LOGREG on test with best combi from CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elapsed for epoch 1: 88.541203975677 seconds\t\n",
       "\t"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Approximative Loss for the last batch for epoch 1: 2.8294755728662e+14\t\n",
       "\t\n",
       "\n",
       "\t\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "[string \"function predict(Xvalid,W,b,Yvalid)...\"]:4: attempt to index local 'Yvalid' (a nil value)\nstack traceback:\n\t[string \"function predict(Xvalid,W,b,Yvalid)...\"]:4: in function 'predict'\n\t[string \"math.randomseed(1234)...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010a32cb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"function predict(Xvalid,W,b,Yvalid)...\"]:4: attempt to index local 'Yvalid' (a nil value)\nstack traceback:\n\t[string \"function predict(Xvalid,W,b,Yvalid)...\"]:4: in function 'predict'\n\t[string \"math.randomseed(1234)...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010a32cb50"
     ]
    }
   ],
   "source": [
    "math.randomseed(1234)\n",
    "W, b, L = logreg(og_train_input,og_train_output,nfeatures,1,Hyperparam_[25][1],Hyperparam_[25][2],Hyperparam_[25][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Testpred = predict(og_test_input,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('Testpred_1.h5', 'w')\n",
    "myFile:write('Testpred', Testpred)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function logreg(Xtrain, Ytrain, nfeatures, nclasses, ep_max, batch_size, eta, lambda)\n",
    "    \n",
    "    -- Initialization\n",
    "    local nfeatures = nfeatures[1]\n",
    "    local nclasses = nclasses[1]\n",
    "    local shuffle = torch.LongTensor(Xtrain:size(1))\n",
    "    local W = torch.cat(torch.zeros(1,nclasses),torch.ones(nfeatures, nclasses),1)\n",
    "    local b = torch.ones(nclasses, 1)\n",
    "    local grad_W = torch.zeros(nfeatures+1,nclasses)\n",
    "    local grad_b = torch.zeros(nclasses, 1)\n",
    "    local z = torch.ones(nclasses, 1)\n",
    "    local yhat = torch.ones(nclasses, 1)\n",
    "    local grad_L_dz = torch.ones(nclasses, 1)\n",
    "    local grad_L_W = torch.zeros(nfeatures+1,nclasses)\n",
    "    \n",
    "\n",
    "    \n",
    "    local c_s = 1\n",
    "    local it_max = math.floor(Xtrain:size(1)/batch_size)\n",
    "    \n",
    "    for ep = 1,ep_max do\n",
    "        timer = torch.Timer()\n",
    "        shuffle:copy(torch.randperm(Xtrain:size(1)):type('torch.LongTensor'))\n",
    "        tot_Loss = 0\n",
    "        \n",
    "        for it = 1,it_max do\n",
    "            -- Initializing gradient for the current iteration\n",
    "            grad_W:zero()\n",
    "            grad_b:zero()\n",
    "\n",
    "            for i = (batch_size*(it-1)+1),batch_size*it do\n",
    "                --current sentence:\n",
    "                c_s = shuffle[i]\n",
    "                --evaluate z:\n",
    "                z:copy(W:index(1,Xtrain[c_s]:type('torch.LongTensor')):sum(1):add(b)):view(-1,1)\n",
    "                --evaluate y_hat:\n",
    "                yhat:copy(torch.exp(z))\n",
    "                yhat:div(yhat:sum())\n",
    "\n",
    "                 --evaluate the loss (only on the last iteration for the logger)\n",
    "                if it == it_max then\n",
    "                    tot_Loss = tot_Loss - z[Ytrain[c_s]][1] + math.log((z-(z:max())):exp():sum())+z:max()\n",
    "                end\n",
    "                --evaluate the gradients:\n",
    "                -- First with respect to dz (which is equal to db):\n",
    "                grad_L_dz:copy(yhat)\n",
    "                grad_L_dz[Ytrain[c_s]]:csub(1)\n",
    "                --Then with respect to dW:\n",
    "                grad_L_W:zero()\n",
    "                grad_L_W:indexAdd(1,Xtrain[c_s]:type('torch.LongTensor'),torch.expand(grad_L_dz,nclasses,53):t())\n",
    "                grad_L_W[1]:zero()\n",
    "                --Update the gradients\n",
    "                grad_W:add(grad_L_W*(1/batch_size))\n",
    "                grad_b:add(grad_L_dz*(1/batch_size))\n",
    "            end\n",
    "\n",
    "            -- Apply the regularization every 10 iteratin to gain speed (possible because of the dataset sparsity)\n",
    "            if (it%10) == 0 then\n",
    "                W:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_W:mul(eta))\n",
    "                b:mul(1-eta*lambda/(W:nElement()+b:nElement())):csub(grad_b:mul(eta))\n",
    "            else\n",
    "                W:csub(grad_W:mul(eta))\n",
    "                b:csub(grad_b:mul(eta))\n",
    "            end\n",
    "            -- Updating the loss with the regularization\n",
    "            if it == it_max then\n",
    "                tot_Loss = Xtrain:size(1)*tot_Loss/batch_size + (0.5)*lambda*(torch.pow(W,2):sum()+torch.pow(b,2):sum())\n",
    "            end\n",
    "        end      \n",
    "        print('Time elapsed for epoch ' .. ep ..': ' .. timer:time().real .. ' seconds')\n",
    "        print('Approximative Loss for the last batch for epoch ' .. ep ..': ' .. tot_Loss)\n",
    "    end\n",
    "    return W, b, tot_Loss\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 5\n",
       "[torch.IntTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "invalid arguments: number IntTensor \nexpected arguments: [*IntTensor*] (LongStorage | dim1 [dim2...])\nstack traceback:\n\t[C]: at 0x0b3255e0\n\t[C]: in function 'zeros'\n\t[string \"function logreg(Xtrain, Ytrain, nfeatures, nc...\"]:5: in function 'logreg'\n\t[string \"W,b,L = logreg(og_train_input, og_train_outpu...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010af3eb50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "invalid arguments: number IntTensor \nexpected arguments: [*IntTensor*] (LongStorage | dim1 [dim2...])\nstack traceback:\n\t[C]: at 0x0b3255e0\n\t[C]: in function 'zeros'\n\t[string \"function logreg(Xtrain, Ytrain, nfeatures, nc...\"]:5: in function 'logreg'\n\t[string \"W,b,L = logreg(og_train_input, og_train_outpu...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:179: in function <.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t.../virgileaudi/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...rgileaudi/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t.../virgileaudi/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010af3eb50"
     ]
    }
   ],
   "source": [
    "W,b,L = logreg(og_train_input, og_train_output, nfeatures, nclasses, 1, 50, 10, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
