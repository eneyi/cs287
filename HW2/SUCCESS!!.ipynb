{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local Squeeze, parent = torch.class('nn.Squeeze', 'nn.Module')\n",
    "\n",
    "function Squeeze:updateOutput(input)\n",
    "    self.size = input:size()\n",
    "    self.output = input:squeeze()\n",
    "    return self.output\n",
    "end\n",
    "\n",
    "function Squeeze:updateGradInput(input, gradOutput)\n",
    "  self.gradInput = gradOutput:view(self.size)\n",
    "  return self.gradInput  \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('PTB.hdf5','r')\n",
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_embed = torch.Tensor(100002,50)\n",
    "word_embed:copy(data['word_embeddings']:narrow(1,1,100002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_word_windows = data['train_input_word_windows']\n",
    "train_input_cap_windows = data['train_input_cap_windows']\n",
    "\n",
    "train = train_input_word_windows:clone()\n",
    "train_cap = train_input_cap_windows:clone()\n",
    "train_output = data['train_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_hidden = 50\n",
    "dim_hidden2 = 50\n",
    "--Define the module\n",
    "neuralnet = nn.Sequential()\n",
    "\n",
    "--Include the lookup tables\n",
    "neuralnet:add(nn.LookupTable(data['nwords'][1],dim_hidden))\n",
    "neuralnet:add(nn.View(1,-1,5*50))\n",
    "neuralnet:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "neuralnet:add(nn.Linear(5*dim_hidden,dim_hidden2))\n",
    "neuralnet:add(nn.HardTanh())\n",
    "neuralnet:add(nn.Linear(dim_hidden2, data['nclasses'][1]))\n",
    "neuralnet:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset[i] = {train[i]:view(1,5), train_output[i]}\n",
    "end\n",
    "function dataset:size() return train:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.76410843150984\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.49077146420375\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.39363261704525\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.33967493665589\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.30359810450474\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.2785490815371\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.25929846572195\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.24431658769046\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.23182629793747\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.22073000924219\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.22073000924219\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = nn.StochasticGradient(neuralnet, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.maxIteration = 10\n",
    "trainer:train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.93472968205236\t\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_word = data['valid_input_word_windows']:clone()\n",
    "val_output = data['valid_output']:clone()\n",
    "\n",
    "pred_train = neuralnet:forward(train)\n",
    "max,argmax_train = pred_train:max(2)\n",
    "acc_train = 0\n",
    "for i = 1, train_output:size(1) do\n",
    "    if argmax_train[i][1] == train_output[i] then\n",
    "        acc_train = acc_train + 1\n",
    "    end\n",
    "end\n",
    "score_train = acc_train/train_output:size(1)\n",
    "print('Validation Score on Train is '..score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.91536173828599\t\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val = neuralnet:forward(val_word)\n",
    "max,argmax_val = pred_val:max(2)\n",
    "acc_val = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if argmax_val[i][1] == data['valid_output'][i] then\n",
    "        acc_val = acc_val + 1\n",
    "    end\n",
    "end\n",
    "score_val = acc_val/data['valid_output']:size(1)\n",
    "print('Validation Score on Train is '..score_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding the cap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_new = train_input_word_windows:clone()\n",
    "train_cap_new = train_cap:clone()\n",
    "train_cap_new:add(100002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = torch.cat(train_new,train_cap_new,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_hidden = 50\n",
    "dim_hidden2 = 50\n",
    "--Define the module\n",
    "neuralnet_wc = nn.Sequential()\n",
    "\n",
    "--Include the lookup tables\n",
    "neuralnet_wc:add(nn.LookupTable(data['nwords'][1]+4,dim_hidden))\n",
    "neuralnet_wc:add(nn.View(1,-1,10*dim_hidden))\n",
    "neuralnet_wc:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "neuralnet_wc:add(nn.Linear(10*dim_hidden,dim_hidden2))\n",
    "neuralnet_wc:add(nn.HardTanh())\n",
    "neuralnet_wc:add(nn.Linear(dim_hidden2, data['nclasses'][1]))\n",
    "neuralnet_wc:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset2={};\n",
    "for i=1,train:size(1) do \n",
    "  dataset2[i] = {train_new[i]:view(1,10), train_output[i]}\n",
    "end\n",
    "function dataset2:size() return train:size(1) end -- 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.64715155130193\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.4320182739747\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.35041711557732\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.30323407053154\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.27192036041329\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.24901295649474\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.23269701198418\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.21847914232537\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.20689133202205\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.19687390394816\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.19687390394816\t\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2 = nn.StochasticGradient(neuralnet_wc, criterion)\n",
    "trainer2.learningRate = 0.01\n",
    "trainer2.maxIteration = 10\n",
    "trainer2:train(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.94118658961767\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train2 = neuralnet_wc:forward(train_new)\n",
    "max,argmax_train2 = pred_train2:max(2)\n",
    "acc_train2 = 0\n",
    "for i = 1, train_output:size(1) do\n",
    "    if argmax_train2[i][1] == train_output[i] then\n",
    "        acc_train2 = acc_train2 + 1\n",
    "    end\n",
    "end\n",
    "score_train2 = acc_train2/train_output:size(1)\n",
    "print('Validation Score on Train is '..score_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_new = data['valid_input_word_windows']:clone()\n",
    "valid_cap_new = data['valid_input_cap_windows']:clone()\n",
    "valid_cap_new:add(100002)\n",
    "valid_new = torch.cat(valid_new,valid_cap_new,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.92946558630736\t\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val2 = neuralnet_wc:forward(valid_new)\n",
    "max,argmax_val2 = pred_val2:max(2)\n",
    "acc_val2 = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if argmax_val2[i][1] == data['valid_output'][i] then\n",
    "        acc_val2 = acc_val2 + 1\n",
    "    end\n",
    "end\n",
    "score_val2 = acc_val2/data['valid_output']:size(1)\n",
    "print('Validation Score on Train is '..score_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_hidden = 100\n",
    "dim_hidden2 = 60\n",
    "--Define the module\n",
    "neuralnet_wc2 = nn.Sequential()\n",
    "\n",
    "--Include the lookup tables\n",
    "neuralnet_wc2:add(nn.LookupTable(data['nwords'][1]+4,dim_hidden))\n",
    "neuralnet_wc2:add(nn.View(1,-1,10*dim_hidden))\n",
    "neuralnet_wc2:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "neuralnet_wc2:add(nn.Linear(10*dim_hidden,dim_hidden2))\n",
    "neuralnet_wc2:add(nn.HardTanh())\n",
    "neuralnet_wc2:add(nn.Linear(dim_hidden2, data['nclasses'][1]))\n",
    "neuralnet_wc2:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.62711629285765\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.43568069541595\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.36333161950036\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.31800302668997\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.28752132094412\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.26281514316402\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.24360116898639\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.22782280178544\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.21506493770209\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.20377482577506\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.19445889801514\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.18557630721415\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.17792761519416\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.17149989155073\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.16545346801062\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.16545346801062\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer3 = nn.StochasticGradient(neuralnet_wc2, criterion)\n",
    "trainer3.learningRate = 0.01\n",
    "trainer3.maxIteration = 15\n",
    "trainer3:train(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.94907337404921\t\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train3 = neuralnet_wc2:forward(train_new)\n",
    "max,argmax_train3 = pred_train3:max(2)\n",
    "acc_train3 = 0\n",
    "for i = 1, train_output:size(1) do\n",
    "    if argmax_train3[i][1] == train_output[i] then\n",
    "        acc_train3 = acc_train3 + 1\n",
    "    end\n",
    "end\n",
    "score_train3 = acc_train3/train_output:size(1)\n",
    "print('Validation Score on Train is '..score_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Validation is 0.93164299587278\t\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val3 = neuralnet_wc2:forward(valid_new)\n",
    "max,argmax_val3 = pred_val3:max(2)\n",
    "acc_val3 = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if argmax_val3[i][1] == data['valid_output'][i] then\n",
    "        acc_val3 = acc_val3 + 1\n",
    "    end\n",
    "end\n",
    "score_val3 = acc_val3/data['valid_output']:size(1)\n",
    "print('Validation Score on Validation is '..score_val3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('nn1',neuralnet_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('nn2',neuralnet_wc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the last model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  train_output : LongTensor - size: 912666\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  train_input_cap_windows : LongTensor - size: 912666x5\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  test_input_word_windows : LongTensor - size: 129696x5\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  valid_output : LongTensor - size: 131808\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  valid_input_cap_windows : LongTensor - size: 131808x5\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  nwords : IntTensor - size: 1\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  test_input_cap_windows : LongTensor - size: 129696x5\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  train_input_word_windows : LongTensor - size: 912666x5\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  nclasses : IntTensor - size: 1\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  word_embeddings : DoubleTensor - size: 400002x50\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  valid_input_word_windows : LongTensor - size: 131808x5\n",
       "}\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_words = data['test_input_word_windows']:clone()\n",
    "test_cap = data['test_input_cap_windows']:clone()\n",
    "test_cap:add(100002)\n",
    "test_data = torch.cat(test_words,test_cap,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_test = neuralnet_wc2:forward(test_data)\n",
    "max,pred_test_nn2 = output_test:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 129696\n",
       "      1\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_nn2:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('test_nn2.h5', 'w')\n",
    "myFile:write('dataset1', pred_test_nn2)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Word embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_hidden = 50\n",
    "dim_hidden2 = 50\n",
    "--Define the module\n",
    "neuralnet_wc3 = nn.Sequential()\n",
    "\n",
    "LT = nn.LookupTable(data['nwords'][1]+4,dim_hidden)\n",
    "LT.weight:narrow(1,1,data['nwords'][1]):copy(word_embed)\n",
    "--Include the lookup tables\n",
    "neuralnet_wc3:add(LT)\n",
    "neuralnet_wc3:add(nn.View(1,-1,10*dim_hidden))\n",
    "neuralnet_wc3:add(nn.Squeeze()) -- this layer is to go from a 1xAxB tensor to AxB dimensional tensor (https://groups.google.com/forum/#!topic/torch7/u4OEc0GB74k)\n",
    "neuralnet_wc3:add(nn.Linear(10*dim_hidden,dim_hidden2))\n",
    "neuralnet_wc3:add(nn.HardTanh())\n",
    "neuralnet_wc3:add(nn.Linear(dim_hidden2, data['nclasses'][1]))\n",
    "neuralnet_wc3:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.30321519416855\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.16526912050898\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.13882272715113\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.12316241705001\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.11365823466305\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.10569034252408\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.10009360907648\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.094368546652581\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.090007589763883\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.085937003812082\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.082638819089707\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.080688000292496\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.077611036617596\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.074708496370951\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.072265615799489\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.072265615799489\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer4 = nn.StochasticGradient(neuralnet_wc3, criterion)\n",
    "trainer4.learningRate = 0.01\n",
    "trainer4.maxIteration = 15\n",
    "trainer4:train(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Train is 0.97479472227518\t\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train4 = neuralnet_wc3:forward(train_new)\n",
    "max,argmax_train4 = pred_train4:max(2)\n",
    "acc_train4 = 0\n",
    "for i = 1, train_output:size(1) do\n",
    "    if argmax_train4[i][1] == train_output[i] then\n",
    "        acc_train4 = acc_train4 + 1\n",
    "    end\n",
    "end\n",
    "score_train4 = acc_train4/train_output:size(1)\n",
    "print('Validation Score on Train is '..score_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_new = data['valid_input_word_windows']:clone()\n",
    "valid_cap_new = data['valid_input_cap_windows']:clone()\n",
    "valid_cap_new:add(100002)\n",
    "valid_new = torch.cat(valid_new,valid_cap_new,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Validation Score on Validation is 0.95920581451809\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val4 = neuralnet_wc3:forward(valid_new)\n",
    "max,argmax_val4 = pred_val4:max(2)\n",
    "acc_val4 = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if argmax_val4[i][1] == data['valid_output'][i] then\n",
    "        acc_val4 = acc_val4 + 1\n",
    "    end\n",
    "end\n",
    "score_val4 = acc_val4/data['valid_output']:size(1)\n",
    "print('Validation Score on Validation is '..score_val4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_words = data['test_input_word_windows']:clone()\n",
    "test_cap = data['test_input_cap_windows']:clone()\n",
    "test_cap:add(100002)\n",
    "test_data = torch.cat(test_words,test_cap,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_test = neuralnet_wc3:forward(test_data)\n",
    "max,pred_test_nn3 = output_test:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('test_nn3.h5', 'w')\n",
    "myFile:write('dataset1', pred_test_nn3)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
