{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATA AND CONVERTING IT TO LOGREG FW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('PTB.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  train_output : LongTensor - size: 912666\n",
       "  train_input_cap_windows : LongTensor - size: 912666x5\n",
       "  test_input_word_windows : LongTensor - size: 129696x5\n",
       "  valid_output : LongTensor - size: 131808\n",
       "  valid_input_cap_windows : LongTensor - size: 131808x5\n",
       "  nwords : IntTensor - size: 1\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  test_input_cap_windows : LongTensor - size: 129696x5\n",
       "  train_input_word_windows : LongTensor - size: 912666x5\n",
       "  nclasses : IntTensor - size: 1\n",
       "  word_embeddings : DoubleTensor - size: 400002x50\n",
       "  valid_input_word_windows : LongTensor - size: 131808x5\n",
       "}\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_word_windows = data['train_input_word_windows']\n",
    "train_output = data['train_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_input_word_windows:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_cap_windows = data['train_input_cap_windows']\n",
    "train_cap = train_input_cap_windows:clone()\n",
    "for j = 1, 5 do\n",
    "    train:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    train_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par = nn.ParallelTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1])) -- first child\n",
    "par:add(nn.LookupTable(5*4,data['nclasses'][1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg_wc = nn.Sequential()\n",
    "linreg_wc:add(par)\n",
    "linreg_wc:add(nn.CAddTable())\n",
    "linreg_wc:add(nn.Sum(2))\n",
    "linreg_wc:add(nn.Add(45))\n",
    "linreg_wc:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 8\n",
       " -5.6465  -5.6951  -4.2983  -1.0533  -5.5287  -6.9783  -6.2291  -7.3502\n",
       "-10.0926  -3.9553 -12.5193  -4.1540  -8.5605 -12.2119 -10.2922  -5.2241\n",
       "-10.0254  -4.8402  -5.1793  -7.3427 -12.6256  -5.5290  -4.1333  -7.2919\n",
       " -9.7817  -3.9542  -6.6033  -6.0190  -6.6727  -3.1727  -9.7177  -5.1494\n",
       " -6.4982  -4.4847 -11.6914  -2.4095 -11.1386  -6.5371 -12.5252  -6.9464\n",
       " -6.6410  -2.3182  -8.0493  -9.7670  -4.6669  -8.0752  -6.8697 -10.4636\n",
       " -9.5130  -8.3978  -8.0393  -7.2420  -3.6019  -9.8141 -12.0096  -7.1808\n",
       " -8.6173  -6.4630 -10.6641  -7.8914  -5.2317  -6.2426  -4.6619  -4.1182\n",
       "-10.4756  -8.4189  -6.9640  -7.9814  -4.9733  -8.6338  -9.1170  -9.8666\n",
       " -8.2726  -5.8824  -8.1927  -4.0009  -7.1584  -1.9654  -8.3512  -4.7074\n",
       "\n",
       "Columns 9 to 16\n",
       "-10.4010  -6.6609  -3.3827 -10.1941 -10.3003  -9.1887  -6.1947 -11.6716\n",
       " -6.8519  -5.3626  -6.8571 -10.7113  -8.0584 -12.6408 -11.1011 -15.0359\n",
       " -7.7506  -2.9477  -5.7931 -14.8110  -7.3115 -14.5785  -6.5220 -11.0444\n",
       " -5.0817  -6.6109  -4.0170  -9.0330  -5.6174 -15.1119  -4.6429 -11.1147\n",
       "-10.1721 -11.0661  -7.7958 -10.4626  -9.6770 -12.0191  -8.0127 -15.9395\n",
       " -8.3935  -8.0011  -1.0164  -9.1012  -5.0741  -7.0941  -7.7099  -6.6471\n",
       " -7.8802  -9.8870  -3.7713 -10.3280 -10.8536 -10.6793  -8.3819 -11.5134\n",
       " -7.1059  -4.5239  -6.8919 -11.7975  -8.1701  -6.2807 -11.7108  -7.4314\n",
       " -7.2937 -10.4872  -2.6835 -11.0589  -7.1140  -6.8817  -7.8201 -11.1940\n",
       " -7.3400  -4.3750  -4.6063  -5.9995  -2.7220  -9.3353  -7.3296  -9.5978\n",
       "\n",
       "Columns 17 to 24\n",
       " -9.4720  -5.9322  -5.5569  -6.2726  -3.2191  -4.0399  -8.9736  -5.3973\n",
       " -6.6424  -6.2296 -11.6234 -12.8068  -7.1903  -6.8963  -7.6162  -7.6018\n",
       " -9.9050  -8.3626  -9.6399  -8.8587  -8.1260  -6.0027  -5.1489  -4.6919\n",
       "-10.8485  -7.6313  -8.4100  -8.7974  -8.7075  -5.4841  -5.8619  -4.7507\n",
       " -9.6810  -6.4015 -12.4503  -7.4900  -0.2529 -10.1838 -12.7729  -6.9483\n",
       " -7.2673  -2.2484 -11.8889  -7.3992  -2.3490  -5.9411  -7.4568  -8.2676\n",
       "-10.3200  -9.6926 -11.2359  -8.5907  -4.1260  -8.4435  -6.0180  -6.5294\n",
       " -6.3029  -7.8080 -13.9800 -11.8111  -8.5151  -9.1464  -9.5524  -5.4091\n",
       " -9.3304  -1.3192  -9.2392  -4.1392  -2.4275  -5.9722  -4.9910  -1.1731\n",
       " -5.9946  -7.2351  -4.9927  -3.3419  -5.9205  -4.8288  -3.4386  -3.0988\n",
       "\n",
       "Columns 25 to 32\n",
       "-12.7458  -7.9248  -0.8852  -5.2072  -5.1720  -9.8664  -9.3841  -9.0336\n",
       " -9.9247  -0.5387  -7.7672  -3.0528  -5.0671  -3.5405  -7.4136  -8.7375\n",
       "-11.3203  -5.4296  -2.4715  -5.2670  -6.5336 -10.0657  -6.1182  -4.7144\n",
       " -9.7561  -3.6490  -6.1373  -5.3951  -9.1667  -6.8733  -5.3391  -6.6886\n",
       "-10.9156  -7.7397  -5.1551  -4.6540 -10.0667  -7.8755  -9.4833  -6.0444\n",
       "-10.7770  -3.5422  -3.4271  -6.2158  -2.0918  -5.1818  -7.5036  -3.3728\n",
       "-12.5804  -4.1365  -4.3389  -7.8397  -3.5478  -7.1798  -4.3411  -3.1667\n",
       " -7.9359  -5.8524  -0.2693  -4.6503  -7.2733 -10.0266  -8.5543  -7.2193\n",
       " -5.7346  -2.6487  -4.5467  -5.6861  -7.9107  -2.6440  -9.1431  -7.9162\n",
       " -4.7096  -3.0278  -1.3663  -5.9854  -6.0018  -9.8291  -5.6413  -3.0965\n",
       "\n",
       "Columns 33 to 40\n",
       "-10.0216 -10.4916  -5.2570 -11.9443  -9.7947 -13.3741  -8.0638 -11.8653\n",
       "-10.6391 -11.2248  -1.3719 -11.4760  -9.8654  -9.4316 -12.0746  -7.0274\n",
       "-12.1186 -10.8155  -0.2830  -8.1841 -10.9668 -14.8886  -8.7477  -5.9611\n",
       " -7.0844  -7.2015  -1.8031  -4.8799  -9.1416 -10.0731  -7.8045 -11.2973\n",
       " -6.4691 -10.3399  -3.1158  -9.3181  -8.8639 -13.5938 -15.8519 -13.0273\n",
       " -6.1701  -7.3327  -6.1239  -7.7278 -10.5400 -11.0667  -9.4388  -8.8440\n",
       "-10.9158 -10.9942  -0.2180  -6.0341  -9.6272 -12.3039  -7.5936 -10.5844\n",
       " -9.3726  -3.3552  -2.3510  -5.6399  -8.6749 -10.6726 -11.8088  -4.8380\n",
       " -4.4634  -7.1400  -4.1602  -7.5350 -11.1457  -9.5749  -9.5848  -8.8057\n",
       " -7.4079  -3.5279  -6.0190  -6.0902  -6.9454 -10.6631 -12.7071  -3.4102\n",
       "\n",
       "Columns 41 to 45\n",
       " -7.8688  -6.5905  -2.5841  -8.6620  -4.9232\n",
       " -9.5160  -3.7444  -9.6769  -9.6120  -8.6597\n",
       " -6.8706 -10.7582  -5.9989  -4.5475  -4.5157\n",
       " -8.2574 -11.1550  -0.4235  -6.0571 -11.1075\n",
       " -8.4429  -4.7026  -3.2284  -9.5409  -9.4597\n",
       " -6.0152  -5.9384  -3.8218  -2.9743  -7.4486\n",
       " -5.9848  -9.6185  -6.8397  -7.2975  -8.5503\n",
       " -4.4483  -6.3278  -7.0181  -9.5224  -4.9524\n",
       " -3.7161  -9.4455  -4.1627  -8.7"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "781  -7.7232\n",
       " -1.8021  -8.6595  -7.0396  -6.9318  -7.4218\n",
       "[torch.DoubleTensor of size 10x45]\n",
       "\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Sanity check:\n",
    "linreg_wc:forward({train:narrow(1,5, 10),train_cap:narrow(1,5, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- linreg_w:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.Sum(2))\n",
    "-- linreg_w:add(nn.Add(data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EPOCH: 1\t\n"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "EPOCH: 2\t\n"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.01\n",
    "max_e = 15\n",
    "input_w = torch.Tensor(32,5)\n",
    "input_c = torch.Tensor(32,5)\n",
    "output = torch.Tensor(32)\n",
    "\n",
    "loss_tensor = torch.Tensor(57*max_e)\n",
    "\n",
    "for i = 1,max_e do\n",
    "    print(\"EPOCH: \"..i)\n",
    "    k = 1\n",
    "    --28520\n",
    "    for j = 1,28520 do\n",
    "        linreg_wc:zeroGradParameters()\n",
    "        \n",
    "        input_w = train:narrow(1, (j-1)*32+1, 32)\n",
    "        input_c = train_cap:narrow(1, (j-1)*32+1, 32)\n",
    "        preds = linreg_wc:forward({input_w,input_c})\n",
    "        \n",
    "        output = train_output:narrow(1,(j-1)*32+1, 32)\n",
    "        \n",
    "        loss = criterion:forward(preds, output)\n",
    "        \n",
    "        if j % 500 == 0 then\n",
    "            loss_tensor[k] = loss\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        dLdpreds = criterion:backward(preds, output)\n",
    "        \n",
    "        linreg_wc:backward({input_w,input_c}, dLdpreds)\n",
    "        \n",
    "        linreg_wc:updateParameters(eta)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING ACCU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_train = linreg_wc:forward({train,train_cap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m,a = preds_train:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy on train is: 0.49810883718688\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "for i = 1, train:size(1) do\n",
    "    if a[i][1] == train_output[i] then\n",
    "        acc = acc + 1\n",
    "    end\n",
    "end\n",
    "print(\"Accuracy on train is: \"..acc/train:size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_word = data['valid_input_word_windows']:clone()\n",
    "val_cap = data['valid_input_cap_windows']:clone()\n",
    "\n",
    "for j = 1, 5 do\n",
    "    val_word:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "\n",
    "for j = 1, 5 do\n",
    "    val_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_val = linreg_wc:forward({val_word,val_cap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_v,a_v = pred_val:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy on validation is: 0.50381615683418\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_v = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if a_v[i][1] == data['valid_output'][i] then\n",
    "        acc_v = acc_v + 1\n",
    "    end\n",
    "end\n",
    "print(\"Accuracy on validation is: \"..acc_v/val_word:size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp1 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn1 = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par2 = nn.ParallelTable()\n",
    "par2:add(nn.LookupTable(data['nwords'][1],hp1)) -- first child\n",
    "par2:add(nn.LookupTable(4,hp1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn1:add(par2)\n",
    "nn1:add(nn.CAddTable())\n",
    "nn1:add(nn.Sum(2))\n",
    "nn1:add(nn.Add(hp1))\n",
    "nn1:add(nn.HardTanh())\n",
    "nn1:add(nn.Linear(hp1,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion2 = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EPOCH: 1\t\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for 1 epoch: 104.36425614357 seconds\t\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "\n",
    "eta = 0.01\n",
    "max_e = 1\n",
    "hp1 = 50\n",
    "batchsize = 100\n",
    "input_w = torch.Tensor(100,5)\n",
    "input_c = torch.Tensor(100,5)\n",
    "output = torch.Tensor(100)\n",
    "\n",
    "loss_tensor = torch.Tensor(18*max_e)\n",
    "\n",
    "k = 1\n",
    "\n",
    "for i = 1,max_e do\n",
    "    print(\"EPOCH: \"..i)\n",
    "    \n",
    "    for j = 1,torch.floor(train:size(1)/batchsize) do\n",
    "        nn1:zeroGradParameters()\n",
    "        \n",
    "        input_w = train_input_word_windows:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        input_c = train_input_cap_windows:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        preds = nn1:forward({input_w,input_c})\n",
    "        \n",
    "        output = train_output:narrow(1,(j-1)*batchsize+1, batchsize)\n",
    "        \n",
    "        loss = criterion2:forward(preds, output)\n",
    "        \n",
    "        if j % 500 == 0 then\n",
    "            loss_tensor[k] = loss\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        dLdpreds = criterion2:backward(preds, output)\n",
    "        \n",
    "        nn1:backward({input_w,input_c}, dLdpreds)\n",
    "        \n",
    "        nn1:updateParameters(eta)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "print('Time elapsed for 1 epoch: ' .. timer:time().real .. ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " -10.4673\n",
       " -20.1917\n",
       " -40.5038\n",
       " -55.5550\n",
       " -67.3850\n",
       " -94.7285\n",
       "-116.4675\n",
       "-132.2956\n",
       "-146.8417\n",
       "-142.9090\n",
       "-188.5284\n",
       "-211.0211\n",
       "-257.5870\n",
       "-231.1713\n",
       "-217.2197\n",
       "-257.8606\n",
       "-309.2840\n",
       "-330.2755\n",
       "[torch.DoubleTensor of size 18]\n",
       "\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
