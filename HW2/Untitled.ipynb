{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATA AND CONVERTING IT TO LOGREG FW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('PTB.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_word_windows = data['train_input_word_windows']\n",
    "train_output = data['train_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_input_word_windows:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1, train:size(1) do\n",
    "    for j = 1, 5 do\n",
    "        train[i][j] = (j-1)*100002 + train[i][j]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_cap_windows = data['train_input_cap_windows']\n",
    "train_cap = train_input_cap_windows:clone()\n",
    "for i = 1, train:size(1) do\n",
    "    for j = 1, 5 do\n",
    "        train_cap[i][j] = (j-1)*4 + train_cap[i][j]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par = nn.ParallelTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1])) -- first child\n",
    "par:add(nn.LookupTable(5*4,data['nclasses'][1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg_wc = nn.Sequential()\n",
    "linreg_wc:add(par)\n",
    "linreg_wc:add(nn.CAddTable())\n",
    "linreg_wc:add(nn.Sum(2))\n",
    "linreg_wc:add(nn.Add(45))\n",
    "linreg_wc:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 8\n",
       " -0.8186 -11.8379  -5.6438 -14.4388  -7.3078  -8.3703  -8.0455  -0.8975\n",
       " -5.5997 -14.0458  -3.1820  -7.5692  -0.7484 -11.1423 -13.4242  -9.8909\n",
       " -5.4569 -15.7438  -5.2446 -10.3546  -3.5530  -5.3203  -9.6729  -9.7699\n",
       " -1.4952  -7.5692  -5.1844 -15.0385  -2.8423  -4.4383 -13.0080  -6.8295\n",
       " -1.9215 -10.5381  -6.2333 -12.1216  -3.6143  -7.8784 -11.1044  -4.7236\n",
       " -0.5884 -13.6767  -5.3946 -14.6605  -1.9824 -10.0362 -11.6843  -4.7942\n",
       " -4.2065 -14.5070  -5.2114 -14.0529  -3.9096  -6.7314  -9.4918  -9.6309\n",
       " -2.8374  -7.4668  -4.2657  -9.7529  -3.2895  -0.8971  -9.6997  -6.4985\n",
       " -4.1349 -13.2034  -1.0139 -10.0785  -5.6546  -4.6099 -12.5774  -4.5594\n",
       " -0.0757  -6.4610  -6.0134 -10.3878  -5.1925  -7.4950 -10.9558 -11.9017\n",
       "\n",
       "Columns 9 to 16\n",
       " -9.6030 -12.4806  -8.4809  -8.5890  -5.7233  -3.5286 -13.4280  -9.3672\n",
       " -4.9246  -4.1400  -4.8397  -4.9063  -3.4000  -6.1977  -6.7050  -3.9693\n",
       " -9.6097  -7.9021  -5.1130  -8.8636  -4.2414  -6.1091 -13.8390 -12.2487\n",
       " -7.4427  -7.8708  -4.2637 -10.4794  -4.9646  -9.7593  -7.9113  -8.6321\n",
       " -3.4095 -11.5990 -10.6362 -13.0488  -3.9631 -10.9988  -7.1281 -13.7702\n",
       " -7.7528 -10.4075  -5.1259  -9.5339  -3.6563  -5.8850 -11.3965 -13.5568\n",
       "-11.6392 -11.8983  -6.6574  -9.3619  -0.3534  -7.7508 -14.1010 -10.5837\n",
       " -8.5955  -5.6311 -12.4819 -10.1158  -2.3043  -8.4803 -10.1992 -12.7738\n",
       " -8.9687  -9.9798  -9.2058 -11.5278  -5.1511  -8.1053  -7.8023 -14.5380\n",
       "-11.4782 -11.9515 -11.5058  -4.9452  -8.6153 -12.9770 -13.6035 -13.7405\n",
       "\n",
       "Columns 17 to 24\n",
       " -4.2942 -11.8916  -6.6524 -10.4434 -10.8349  -6.4185 -11.8134  -3.6455\n",
       " -4.1979 -12.7778  -6.4830 -13.2943  -5.3080 -12.1243  -8.0308  -5.1220\n",
       " -3.7795  -9.4155  -5.8538 -13.6143  -4.2684 -12.1286  -8.5686  -8.1481\n",
       " -1.5362  -9.0735 -10.7126 -11.6081  -4.5615 -10.7826  -9.9902  -5.9650\n",
       " -2.7970 -10.9965 -12.4757 -18.7761  -5.4920  -9.8355  -8.6115  -5.7337\n",
       " -3.8248 -14.3362  -6.6587 -11.2507  -3.3702  -9.0372  -7.7334  -6.1717\n",
       " -3.1162 -11.5320  -8.1196  -9.5024  -7.8564  -8.3934  -8.2834  -7.4852\n",
       " -6.9059 -11.9575 -12.0471  -8.8211  -5.7019  -8.2310  -9.8752  -3.5843\n",
       " -4.8450  -8.1436  -7.4072 -12.6507  -6.7481 -12.5316  -7.0076  -6.1031\n",
       " -4.9742 -15.3075  -8.8521 -15.0260  -7.6936  -8.0941  -9.0549  -6.3083\n",
       "\n",
       "Columns 25 to 32\n",
       "-12.8947  -5.3690  -4.3382  -3.5364  -9.9580  -9.2660  -9.8143  -5.4374\n",
       " -8.5085  -3.2014  -4.0399  -2.4736  -2.5982  -4.7091  -5.5332  -5.9028\n",
       " -8.7620  -9.1433  -7.7523  -3.4554  -2.7073 -10.8466  -7.7706  -5.8531\n",
       " -8.6661  -9.1392  -1.3953  -2.3359  -6.8792  -7.2009  -4.4845 -10.7427\n",
       "-11.3162  -1.2493  -5.9083  -4.5004  -9.6221 -10.7613  -1.1510  -3.8857\n",
       "-10.7458  -3.8657  -4.3627  -2.2551  -9.0161 -11.3312  -4.1963  -8.1870\n",
       "-11.7200  -3.2083 -10.4690  -5.6537  -4.6437  -6.7124  -8.5900  -4.3957\n",
       " -2.3828  -5.8490  -3.4552  -7.2387  -2.6803  -7.3264  -8.7905  -4.4918\n",
       "-11.0118  -7.3999  -4.4139  -2.6141  -4.1369  -1.5397 -11.0658  -7.0645\n",
       "-11.4057  -5.2731  -6.1174  -4.5830 -10.1814  -9.5051  -6.0599 -16.9061\n",
       "\n",
       "Columns 33 to 40\n",
       " -9.7066  -8.2640  -4.1131 -10.4771 -10.0466 -10.0891  -8.7600  -9.9470\n",
       " -7.5365  -2.1851  -9.6120  -8.5343  -7.0490  -8.8315  -9.3844  -9.6729\n",
       " -9.0582  -0.2465  -6.3773  -8.4387 -11.1431 -14.9054  -8.0691 -12.6519\n",
       " -8.8652  -2.7806  -4.2906 -13.8914  -5.2507  -7.9103  -9.0296 -10.1273\n",
       " -9.6084  -3.1454  -4.4376  -7.5467  -9.6005 -12.6744 -11.9953 -10.1810\n",
       " -9.8895  -3.2001  -7.3124  -6.2825  -8.9221 -14.0331 -14.3949 -10.1263\n",
       "-13.3078  -2.0504  -4.6615 -12.0940  -6.8127 -14.6494  -9.0367 -13.0017\n",
       "-12.8397  -2.2705  -7.6265  -6.6143  -6.8675  -6.2019  -4.6328  -8.2790\n",
       " -6.9743  -1.8968  -3.5029 -11.2527  -6.4461 -11.9713  -8.8055 -11.5537\n",
       "-11.9458  -4.0023 -10.1953 -12.5552  -9.4694 -13.3916 -10.7738 -14.2304\n",
       "\n",
       "Columns 41 to 45\n",
       " -9.5865  -9.9706  -6.5144  -8.4419  -8.2574\n",
       " -9.3319  -8.9703  -7.3948  -5.1249  -5.3269\n",
       " -8.2004  -8.0808  -9.7508 -10.1223  -5.1112\n",
       " -6.7866 -10.8823 -10.0036 -10.6413  -5.0205\n",
       " -7.4907 -10.4972  -9.6033  -9.8134 -13.2936\n",
       " -7.5479 -10.4917 -10.3253  -7.6497  -9.5589\n",
       " -9.2891 -11.1969 -10.6191  -7.8245  -7.6309\n",
       " -8.0285  -4.1290 -11.9998  -7.1662  -9.1557\n",
       "-10.7181  -2.5670 -11.4422  -8.8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "946  -9.0741\n",
       " -9.0156  -8.2138 -12.1546  -9.6799  -5.0514\n",
       "[torch.DoubleTensor of size 10x45]\n",
       "\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Sanity check:\n",
    "linreg_wc:forward({train:narrow(1,5, 10),train_cap:narrow(1,5, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- linreg_w:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.Sum(2))\n",
    "-- linreg_w:add(nn.Add(data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912666\t\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output:size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "input_w = torch.Tensor(100,5)\n",
    "input_c = torch.Tensor(100,5)\n",
    "output = torch.Tensor(100)\n",
    "\n",
    "for i = 1,1 do\n",
    "   \n",
    "    --28520\n",
    "    for j = 1,9126 do\n",
    "        linreg_wc:zeroGradParameters()\n",
    "        \n",
    "        input_w = train:narrow(1, (j-1)*100+1, 100)\n",
    "        input_c = train_cap:narrow(1, (j-1)*100+1, 100)\n",
    "        preds = linreg_wc:forward({input_w,input_c})\n",
    "        \n",
    "        output = train_output:narrow(1,(j-1)*100+1, 100)\n",
    "        \n",
    "        loss = criterion:forward(preds, output)\n",
    "        \n",
    "        if j % 500 == 0 then\n",
    "            print(loss)\n",
    "        end\n",
    "        \n",
    "        dLdpreds = criterion:backward(preds, output)\n",
    "        \n",
    "        linreg_wc:backward({input_w,input_c}, dLdpreds)\n",
    "        \n",
    "        linreg:updateParameters(eta)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = data['valid_input_word_windows']:clone()\n",
    "for i = 1, val:size(1) do\n",
    "    for j = 1, 5 do\n",
    "        val[i][j] = (j-1)*100002 + val[i][j]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_val = linreg:forward(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m,a = pred_val:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if a[i] == data['valid_output'][i] then\n",
    "        acc = acc + 1\n",
    "    end\n",
    "end\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minibatch =  torch.range((j-1)*32+1, j*32):type('torch.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = linreg:forward(train:index(1,minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = mse:forward(preds, train_output:index(1,minibatch))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dLdpreds = mse:backward(preds, train_output:index(1,minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg:backward(X, dLdpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = torch.LongTensor({1,2,5})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
