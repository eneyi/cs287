{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATA AND CONVERTING IT TO LOGREG FW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('PTB.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = myFile:all()\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  train_output : LongTensor - size: 912666\n",
       "  train_input_cap_windows : LongTensor - size: 912666x5\n",
       "  test_input_word_windows : LongTensor - size: 129696x5\n",
       "  valid_output : LongTensor - size: 131808\n",
       "  valid_input_cap_windows : LongTensor - size: 131808x5\n",
       "  nwords : IntTensor - size: 1\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  test_input_cap_windows : LongTensor - size: 129696x5\n",
       "  train_input_word_windows : LongTensor - size: 912666x5\n",
       "  nclasses : IntTensor - size: 1\n",
       "  word_embeddings : DoubleTensor - size: 400002x50\n",
       "  valid_input_word_windows : LongTensor - size: 131808x5\n",
       "}\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_word_windows = data['train_input_word_windows']\n",
    "train_output = data['train_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train_input_word_windows:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_cap_windows = data['train_input_cap_windows']\n",
    "train_cap = train_input_cap_windows:clone()\n",
    "for j = 1, 5 do\n",
    "    train:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    train_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par = nn.ParallelTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "par:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1])) -- first child\n",
    "par:add(nn.LookupTable(5*4,data['nclasses'][1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg_wc = nn.Sequential()\n",
    "linreg_wc:add(par)\n",
    "linreg_wc:add(nn.CAddTable())\n",
    "linreg_wc:add(nn.Sum(2))\n",
    "linreg_wc:add(nn.Add(45))\n",
    "linreg_wc:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 8\n",
       " -9.4556  -9.0840  -9.1315  -6.5516  -6.7180  -9.7721  -5.2577  -4.9102\n",
       " -5.2287  -2.2692  -8.3143  -9.3451  -7.0764  -4.7653  -9.5746  -9.7060\n",
       " -1.9097 -10.2818  -9.5193  -8.5484  -6.1988 -11.7294  -4.8129  -6.0074\n",
       " -6.0959  -6.8740  -7.0861  -3.9074  -3.3044 -13.0307  -6.0800  -1.8501\n",
       " -6.6274  -6.9709 -10.3367 -10.9805  -3.8520  -9.9096  -9.7327  -9.6333\n",
       " -3.9007 -10.0580  -4.2999  -5.2826  -1.2004  -6.2150  -8.8340  -7.0047\n",
       " -7.2727  -9.6507  -7.1163  -6.6166  -6.0662 -11.5380  -5.1602  -5.9396\n",
       " -6.2306  -9.3752  -7.4906  -7.3687  -9.2647  -8.5895  -6.3623  -6.4497\n",
       " -9.5701  -7.8016  -5.1224 -11.1787  -4.3156 -10.3472  -7.7270  -8.0237\n",
       " -7.2037 -10.6715 -10.0518  -7.5502  -0.4954 -11.1519  -6.4436  -6.7654\n",
       "\n",
       "Columns 9 to 16\n",
       "-11.5083  -9.1985  -1.7827  -7.7293 -10.0467  -7.8615  -7.8726 -11.5432\n",
       " -9.3059  -6.2154  -7.4380 -11.2678  -6.1378 -10.6858  -8.7199  -7.6150\n",
       " -7.3944  -6.5481  -5.6413  -8.7201  -9.8178  -7.4246  -9.8617  -6.8240\n",
       " -7.7495  -2.9847  -5.8901  -7.5761  -5.6130  -6.1945  -3.8644  -4.8302\n",
       " -8.6683 -10.4822 -11.0558  -8.6915  -8.5116  -2.3250  -7.5828  -8.4581\n",
       " -4.5676  -5.8154  -5.2007 -10.5551  -4.0897  -9.6323  -7.9417 -10.4408\n",
       " -2.7878  -5.8783  -5.5882 -10.4726  -7.1823  -9.2393  -9.8832  -8.1569\n",
       " -1.9382  -8.5307  -8.7080  -9.0519  -6.1635  -4.0132  -6.6125  -3.8708\n",
       " -4.9679  -1.2088  -7.1735  -9.2371  -9.6486  -9.8674  -5.6987  -5.9415\n",
       " -3.0208  -7.9018  -6.5922 -12.7453  -8.9650 -13.5904 -12.5604  -9.2961\n",
       "\n",
       "Columns 17 to 24\n",
       " -4.6635  -8.6273  -5.7369  -6.3467  -7.0935 -13.8070 -10.0919  -8.1814\n",
       " -3.6357  -6.6128 -12.1130 -10.2196  -9.7483  -7.4400  -7.4891 -12.5419\n",
       " -3.8228  -4.0819  -4.3214  -7.2216  -8.9308  -9.7871  -7.6321 -11.1975\n",
       " -5.1788  -6.3841  -3.1539  -4.2123  -7.7687  -6.2945  -5.9045 -12.0024\n",
       " -6.9604 -11.9846  -9.7652  -8.7438  -9.2542  -9.8467  -6.9947 -13.3044\n",
       " -4.8949  -6.1624  -6.6596  -5.2364  -8.6311 -10.3551 -10.5909 -12.8422\n",
       " -3.3298  -1.6519  -4.9225  -7.9896  -7.2209 -11.2295  -4.0599 -10.0064\n",
       " -6.2702  -6.2408 -10.6615  -8.4463  -5.4853  -9.6197  -3.3406  -9.6576\n",
       " -8.2564  -8.3551  -5.8034  -6.9623  -9.8894  -4.7764  -5.4740 -10.0242\n",
       " -8.0444  -5.8864  -8.6671  -6.0898  -8.2249  -6.6458  -7.9925 -15.2943\n",
       "\n",
       "Columns 25 to 32\n",
       " -2.3953  -5.8420  -4.5963 -11.2170 -10.6698 -11.6479 -14.0139  -0.4742\n",
       " -6.2034  -4.5872  -2.7055 -11.1947 -14.1855 -12.3830  -8.3872  -6.3271\n",
       " -6.5747  -5.6029  -0.7083  -7.9070 -11.0042  -7.4336  -3.2396  -4.8512\n",
       " -1.6014  -7.7562  -2.9671  -7.2743  -8.1150  -4.6896  -9.2703  -2.1115\n",
       " -5.5578 -11.7945  -6.6586  -9.8763 -15.7534 -11.1382  -9.9924  -0.8976\n",
       " -1.5023  -7.3175  -2.0879 -12.6265  -9.6308  -7.5661  -8.8199  -6.0023\n",
       " -4.4549  -9.0274  -3.9333  -5.8809  -9.9801  -4.1282 -10.1618  -3.7666\n",
       " -5.5666  -6.1361  -4.1241 -10.2881  -9.0114  -6.0234 -10.7272 -11.6651\n",
       " -3.9450  -5.3502  -4.9478  -7.4291 -10.8626  -9.5869  -9.6450  -7.8615\n",
       " -3.4406  -5.6035  -7.8199 -11.5242 -13.8776 -12.1001 -13.9267  -7.5377\n",
       "\n",
       "Columns 33 to 40\n",
       " -6.7717  -4.4008  -4.3845  -8.1599 -13.5979  -3.2423  -5.7013  -6.0585\n",
       " -3.0112  -7.3915  -0.7929  -2.0683  -9.6249  -3.4497 -12.1378  -6.2915\n",
       "-10.1915 -10.7823  -9.6316  -3.6821 -10.5518  -1.6544 -10.8674  -6.7421\n",
       " -5.4365  -7.2641  -5.3126  -5.3744  -4.2772  -3.1454  -5.4591  -6.4358\n",
       " -5.9352  -7.4927  -0.8378  -7.4123 -13.4259  -4.3601 -13.2015  -6.4851\n",
       " -5.4984  -8.4973  -1.8835  -7.0790  -4.4164  -5.2900  -7.9657  -6.0904\n",
       " -9.7556  -8.8698  -0.7628  -4.8773  -8.0588  -6.7850 -10.2533  -5.8061\n",
       " -9.2911  -6.3254  -4.5584 -10.0463  -7.4573  -5.7924  -6.5265  -7.2725\n",
       " -8.6270  -4.0851  -3.2201  -7.4072  -6.3483  -1.2867 -10.9529  -8.3674\n",
       "-11.3780  -7.2585  -4.3262  -3.6808  -6.2028 -10.3101  -8.9823  -7.2980\n",
       "\n",
       "Columns 41 to 45\n",
       "-12.9016 -11.0699 -10.0334  -6.9964  -7.9706\n",
       "-11.4900  -4.7710  -2.3646  -7.2762 -11.7741\n",
       "-14.6723 -12.6884  -6.1411  -4.9979  -5.2056\n",
       "-10.4554  -6.3107  -4.6387  -1.9455  -5.5266\n",
       "-11.0074  -7.1701  -5.4449  -5.5890  -6.0853\n",
       "-11.7654  -6.7731  -8.6940  -4.2692  -2.7882\n",
       " -7.9851  -8.2122  -6.1686  -4.3508  -2.3443\n",
       "-13.2520  -0.4535  -7.1877  -3.0841  -3.2887\n",
       "-10.7024  -7.4734  -8.9924  -2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "977  -1.8450\n",
       "-12.2412  -9.7217  -8.9921  -9.7677  -1.3894\n",
       "[torch.DoubleTensor of size 10x45]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Sanity check:\n",
    "linreg_wc:forward({train:narrow(1,5, 10),train_cap:narrow(1,5, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- linreg_w:add(nn.LookupTable(5*data['nwords'][1],data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.Sum(2))\n",
    "-- linreg_w:add(nn.Add(data['nclasses'][1]))\n",
    "-- linreg_w:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EPOCH: 1\t\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "\n",
    "max_e = 15\n",
    "\n",
    "batchsize = 32\n",
    "\n",
    "input_w = torch.Tensor(batchsize,5)\n",
    "input_c = torch.Tensor(batchsize,5)\n",
    "output = torch.Tensor(batchsize)\n",
    "\n",
    "loss_tensor = torch.Tensor(90)\n",
    "k = 1\n",
    "\n",
    "for i = 1,max_e do\n",
    "    print(\"EPOCH: \"..i)\n",
    "    \n",
    "    for j = 1,torch.floor(train:size(1)/batchsize) do\n",
    "        linreg_wc:zeroGradParameters()\n",
    "        \n",
    "        input_w = train:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        input_c = train_cap:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        preds = linreg_wc:forward({input_w,input_c})\n",
    "        \n",
    "        output = train_output:narrow(1,(j-1)*batchsize+1, batchsize)\n",
    "        \n",
    "        loss = criterion:forward(preds, output)\n",
    "        \n",
    "        if j % 500 == 0 then\n",
    "            loss_tensor[k] = loss\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        dLdpreds = criterion:backward(preds, output)\n",
    "        \n",
    "        linreg_wc:backward({input_w,input_c}, dLdpreds)\n",
    "        \n",
    "        linreg_wc:updateParameters(eta)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING ACCU: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_train = linreg_wc:forward({train,train_cap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m,a = preds_train:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy on train is: 0.49810883718688\t\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = 0\n",
    "for i = 1, train:size(1) do\n",
    "    if a[i][1] == train_output[i] then\n",
    "        acc = acc + 1\n",
    "    end\n",
    "end\n",
    "print(\"Accuracy on train is: \"..acc/train:size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_word = data['valid_input_word_windows']:clone()\n",
    "val_cap = data['valid_input_cap_windows']:clone()\n",
    "\n",
    "for j = 1, 5 do\n",
    "    val_word:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "\n",
    "for j = 1, 5 do\n",
    "    val_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_val = linreg_wc:forward({val_word,val_cap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_v,a_v = pred_val:max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy on validation is: 0.50381615683418\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_v = 0\n",
    "for i = 1, data['valid_output']:size(1) do\n",
    "    if a_v[i][1] == data['valid_output'][i] then\n",
    "        acc_v = acc_v + 1\n",
    "    end\n",
    "end\n",
    "print(\"Accuracy on validation is: \"..acc_v/val_word:size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp1 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn1 = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par2 = nn.ParallelTable()\n",
    "par2:add(nn.LookupTable(data['nwords'][1],hp1)) -- first child\n",
    "par2:add(nn.LookupTable(4,hp1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn1:add(par2)\n",
    "nn1:add(nn.CAddTable())\n",
    "nn1:add(nn.Sum(2))\n",
    "nn1:add(nn.Add(hp1))\n",
    "nn1:add(nn.HardTanh())\n",
    "nn1:add(nn.Linear(hp1,45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion2 = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EPOCH: 1\t\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for 1 epoch: 104.36425614357 seconds\t\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "\n",
    "eta = 0.01\n",
    "max_e = 1\n",
    "hp1 = 50\n",
    "batchsize = 100\n",
    "input_w = torch.Tensor(100,5)\n",
    "input_c = torch.Tensor(100,5)\n",
    "output = torch.Tensor(100)\n",
    "\n",
    "loss_tensor = torch.Tensor(18*max_e)\n",
    "\n",
    "k = 1\n",
    "\n",
    "for i = 1,max_e do\n",
    "    print(\"EPOCH: \"..i)\n",
    "    \n",
    "    for j = 1,torch.floor(train:size(1)/batchsize) do\n",
    "        nn1:zeroGradParameters()\n",
    "        \n",
    "        input_w = train_input_word_windows:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        input_c = train_input_cap_windows:narrow(1, (j-1)*batchsize+1, batchsize)\n",
    "        preds = nn1:forward({input_w,input_c})\n",
    "        \n",
    "        output = train_output:narrow(1,(j-1)*batchsize+1, batchsize)\n",
    "        \n",
    "        loss = criterion2:forward(preds, output)\n",
    "        \n",
    "        if j % 500 == 0 then\n",
    "            loss_tensor[k] = loss\n",
    "            k = k + 1\n",
    "        end\n",
    "        \n",
    "        dLdpreds = criterion2:backward(preds, output)\n",
    "        \n",
    "        nn1:backward({input_w,input_c}, dLdpreds)\n",
    "        \n",
    "        nn1:updateParameters(eta)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "print('Time elapsed for 1 epoch: ' .. timer:time().real .. ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " -10.4673\n",
       " -20.1917\n",
       " -40.5038\n",
       " -55.5550\n",
       " -67.3850\n",
       " -94.7285\n",
       "-116.4675\n",
       "-132.2956\n",
       "-146.8417\n",
       "-142.9090\n",
       "-188.5284\n",
       "-211.0211\n",
       "-257.5870\n",
       "-231.1713\n",
       "-217.2197\n",
       "-257.8606\n",
       "-309.2840\n",
       "-330.2755\n",
       "[torch.DoubleTensor of size 18]\n",
       "\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
