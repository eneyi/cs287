{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  H5Z_FILTER_CONFIG_ENCODE_ENABLED : 1\n",
       "  H5F_ACC_RDWR : 1\n",
       "  _getTorchType : function: 0x070194e8\n",
       "  H5F_OBJ_FILE : 1\n",
       "  H5S_ALL : 0\n",
       "  H5F_OBJ_GROUP : 4\n",
       "  C : userdata: 0x073b3748\n",
       "  H5P_DEFAULT : 0\n",
       "  _describeObject : function: 0x07019568\n",
       "  H5Z_FILTER_NBIT : 5\n",
       "  _debugMode : false\n",
       "  _getObjectType : function: 0x07019528\n",
       "  H5F_OBJ_ALL : 31\n",
       "  _getObjectName : function: 0x07019508\n",
       "  version : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 8\n",
       "      3 : 15\n",
       "    }\n",
       "  H5Z_FILTER_SHUFFLE : 2\n",
       "  HDF5Group : table: 0x07056180\n",
       "  open : function: 0x0701fc98\n",
       "  H5Z_FILTER_SZIP : 4\n",
       "  H5F_OBJ_ATTR : 16\n",
       "  H5Z_FILTER_FLETCHER32 : 3\n",
       "  H5F_OBJ_DATATYPE : 8\n",
       "  debugMode : function: 0x0701fc18\n",
       "  H5F_ACC_EXCL : 4\n",
       "  H5Z_FILTER_NONE : 0\n",
       "  _testUtils : \n",
       "    {\n",
       "      deepAlmostEq : function: 0x07010ac8\n",
       "      withTmpDir : function: 0x07000410\n",
       "    }\n",
       "  _nativeTypeForTensorType : function: 0x073b3940\n",
       "  H5F_ACC_TRUNC : 2\n",
       "  _config : \n",
       "    {\n",
       "      HDF5_INCLUDE_PATH : /Users/nicolasdrizard/anaconda/include\n",
       "      HDF5_LIBRARIES : /Users/nicolasdrizard/anaconda/lib/libhdf5.dylib;/Users/nicolasdrizard/anaconda/lib/libhdf5_hl.dylib;/Users/nicolasdrizard/anaconda/lib/libhdf5.dylib;/Users/nicolasdrizard/anaconda/lib/libz.dylib;/usr/lib/libdl.dylib;/usr/lib/libm.dylib\n",
       "    }\n",
       "  _loadObject : function: 0x0701fc78\n",
       "  DataSetOptions : table: 0x06fdd868\n",
       "  HDF5DataSet : table: 0x06fc3cb8\n",
       "  H5Z_FILTER_RESERVED : 256\n",
       "  _logger : \n",
       "    {\n",
       "      error : function: 0x070524a8\n",
       "      warn : function: 0x070524a8\n",
       "      debug : function: 0x070524f0\n",
       "    }\n",
       "  H5F_ACC_RDONLY : 0\n",
       "  _fletcher32Available : function: 0x07019588\n",
       "  H5Z_FILTER_CONFIG_DECODE_ENABLED : 2\n",
       "  ffi : \n",
       "    {\n",
       "      abi : function: builtin#202\n",
       "      copy : function: builtin#200\n",
       "      errno : function: builtin#198\n",
       "      typeinfo : function: builtin#193\n",
       "      alignof : function: builtin#196\n",
       "      cdef : function: builtin#189\n",
       "      C : userdata: 0x06bd0170\n",
       "      cast : function: builtin#191\n",
       "      load : function: builtin#205\n",
       "      offsetof : function: builtin#197\n",
       "      sizeof : function: builtin#195\n",
       "      string : function: builtin#199\n",
       "      metatype : function: builtin#203\n",
       "      new : function: builtin#190\n",
       "      arch : x64\n",
       "      os : OSX\n",
       "      gc : function: builtin#204\n",
       "      fill : function: builtin#201\n",
       "      istype : function: builtin#194\n",
       "      typeof : function: builtin#192\n",
       "    }\n",
       "  H5Z_FILTER_ERROR : -1\n",
       "  _outputTypeForTensorType : function: 0x07677dd0\n",
       "  H5Z_FILTER_MAX : 65535\n",
       "  h5t : \n",
       "    {\n",
       "      STD_B32LE : 50331728\n",
       "      IEEE_F32BE : 50331703\n",
       "      NATIVE_B16 : 50331694\n",
       "      NATIVE_HSIZE : 50331698\n",
       "      NO_CLASS : -1\n",
       "      NATIVE_UINT_FAST32 : 50331681\n",
       "      STD_B8LE : 50331724\n",
       "      STD_I64BE : 50331715\n",
       "      NATIVE_LONG : 50331662\n",
       "      NATIVE_DOUBLE : 50331691\n",
       "      TIME : 2\n",
       "      NATIVE_INT16 : 50331670\n",
       "      NATIVE_LLONG : 50331688\n",
       "      STD_I8BE : 50331709\n",
       "      STD_B64LE : 50331730\n",
       "      NATIVE_HSSIZE : 50331699\n",
       "      STD_B32BE : 50331729\n",
       "      INTEGER : 0\n",
       "      NATIVE_INT64 : 50331682\n",
       "      STD_I8LE : 50331708\n",
       "      STD_I32LE : 50331712\n",
       "      NATIVE_SCHAR : 50331656\n",
       "      NATIVE_INT_FAST16 : 50331674\n",
       " "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "     NATIVE_INT : 50331660\n",
       "      BITFIELD : 4\n",
       "      NATIVE_UINT_LEAST16 : 50331673\n",
       "      NATIVE_INT_LEAST16 : 50331672\n",
       "      IEEE_F64LE : 50331704\n",
       "      NATIVE_INT_FAST64 : 50331686\n",
       "      NATIVE_UINT_FAST64 : 50331687\n",
       "      NATIVE_UINT_LEAST64 : 50331685\n",
       "      NATIVE_INT_LEAST64 : 50331684\n",
       "      ENUM : 8\n",
       "      NATIVE_UINT64 : 50331683\n",
       "      NATIVE_HBOOL : 50331701\n",
       "      NATIVE_ULONG : 50331663\n",
       "      NATIVE_INT_FAST32 : 50331680\n",
       "      NATIVE_HADDR : 50331697\n",
       "      NATIVE_UINT : 50331661\n",
       "      NCLASSES : 11\n",
       "      NATIVE_UINT_LEAST32 : 50331679\n",
       "      NATIVE_INT_LEAST32 : 50331678\n",
       "      STD_U64LE : 50331722\n",
       "      NATIVE_UINT32 : 50331677\n",
       "      NATIVE_SHORT : 50331658\n",
       "      NATIVE_INT32 : 50331676\n",
       "      VLEN : 9\n",
       "      ARRAY : 10\n",
       "      STD_U16LE : 50331718\n",
       "      STD_B16LE : 50331726\n",
       "      STD_I64LE : 50331714\n",
       "      NATIVE_UINT16 : 50331671\n",
       "      NATIVE_UINT_FAST8 : 50331669\n",
       "      STD_B16BE : 50331727\n",
       "      NATIVE_INT_FAST8 : 50331668\n",
       "      FLOAT : 1\n",
       "      REFERENCE : 7\n",
       "      STD_U32LE : 50331720\n",
       "      NATIVE_USHORT : 50331659\n",
       "      NATIVE_ULLONG : 50331689\n",
       "      NATIVE_INT8 : 50331664\n",
       "      IEEE_F32LE : 50331702\n",
       "      STD_U8BE : 50331717\n",
       "      NATIVE_INT_LEAST8 : 50331666\n",
       "      NATIVE_UINT8 : 50331665\n",
       "      NATIVE_B32 : 50331695\n",
       "      NATIVE_HERR : 50331700\n",
       "      NATIVE_OPAQUE : 50331736\n",
       "      NATIVE_LDOUBLE : 50331692\n",
       "      NATIVE_UINT_LEAST8 : 50331667\n",
       "      COMPOUND : 6\n",
       "      STD_REF_OBJ : 50331739\n",
       "      NATIVE_UINT_FAST16 : 50331675\n",
       "      NATIVE_B64 : 50331696\n",
       "      STD_U16BE : 50331719\n",
       "      STD_REF_DSETREG : 50331740\n",
       "      NATIVE_B8 : 50331693\n",
       "      STD_I32BE : 50331713\n",
       "      IEEE_F64BE : 50331705\n",
       "      NATIVE_FLOAT : 50331690\n",
       "      NATIVE_UCHAR : 50331657\n",
       "      STD_U32BE : 50331721\n",
       "      OPAQUE : 5\n",
       "      STD_B64BE : 50331731\n",
       "      STD_U8LE : 50331716\n",
       "      STD_I16BE : 50331711\n",
       "      STD_B8BE : 50331725\n",
       "      STRING : 3\n",
       "      STD_I16LE : 50331710\n",
       "      STD_U64BE : 50331723\n",
       "    }\n",
       "  HDF5File : table: 0x0701bc60\n",
       "  H5Z_FILTER_SCALEOFFSET : 6\n",
       "  H5Z_FILTER_DEFLATE : 1\n",
       "  H5F_ACC_CREAT : 16\n",
       "  H5F_UNLIMITED : 18446744073709551615ULL\n",
       "  _deflateAvailable : function: 0x07045238\n",
       "  _inDebugMode : function: 0x0701fc58\n",
       "  H5F_OBJ_LOCAL : 32\n",
       "  H5S_SELECT_SET : 0\n",
       "  _datatypeName : function: 0x070194a8\n",
       "  H5F_ACC_DEBUG : 8\n",
       "  H5F_OBJ_DATASET : 2\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myFile = hdf5.open('PTB.hdf5','r')\n",
    "train_input_word_windows = myFile:read('train_input_word_windows'):all()\n",
    "train_input_cap_windows = myFile:read('train_input_cap_windows'):all()\n",
    "valid_input_word_windows = myFile:read('valid_input_word_windows'):all()\n",
    "valid_input_cap_windows = myFile:read('valid_input_cap_windows'):all()\n",
    "train_output = myFile:read('train_output'):all()\n",
    "valid_output = myFile:read('valid_output'):all()\n",
    "nclasses = myFile:read('nclasses'):all()[1]\n",
    "nwords = myFile:read('nwords'):all()[1]\n",
    "ncap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function NaiveBayes(Xtrain_words, Xtrain_cap, Ytrain, nwords, ncap, nclasses, alpha)\n",
    "    local n = Ytrain:size(1)\n",
    "    local window_size = Xtrain_words:size(2)\n",
    "    \n",
    "    -- Building the prior\n",
    "    local prior = torch.zeros(nclasses)\n",
    "    for i = 1, n do\n",
    "        c = Ytrain[i]\n",
    "        prior[c] = prior[c] + 1\n",
    "    end\n",
    "    prior:div(n)\n",
    "\n",
    "    -- Building the count matrix for words and caps with alpha as smoothing parameter\n",
    "    \n",
    "    local F_word = torch.zeros(nwords, nclasses)\n",
    "    local F_cap = torch.zeros(ncap, nclasses)\n",
    "    local x_word = torch.DoubleTensor(window_size)\n",
    "    local x_cap = torch.DoubleTensor(window_size)\n",
    "    -- Alpha smoothing parameter only use for the words features\n",
    "    F_word:fill(alpha)\n",
    "    for i = 1, n do\n",
    "        c = Ytrain[i]\n",
    "        x_word:copy(Xtrain_words[i])\n",
    "        F_word:narrow(2,c,1):indexAdd(1, x_word:type('torch.LongTensor'), torch.ones(window_size,1))\n",
    "        x_cap:copy(Xtrain_cap[i])\n",
    "        F_cap:narrow(2,c,1):indexAdd(1, x_cap:type('torch.LongTensor'), torch.ones(window_size,1))\n",
    "    end\n",
    "\n",
    "    -- Building p(x|y) (same memory loc as F_word)\n",
    "    local x_conditional_y_word = F_word\n",
    "    -- Normalization\n",
    "    x_conditional_y_word:cdiv(torch.expand(x_conditional_y_word:sum(1), nwords, nclasses))\n",
    "\n",
    "    -- Building p(x|y) (same memory loc as F_cap)\n",
    "    local x_conditional_y_cap = F_cap\n",
    "    -- Normalization\n",
    "    x_conditional_y_cap:cdiv(torch.expand(x_conditional_y_cap:sum(1), ncap, nclasses))\n",
    "    \n",
    "    return prior, x_conditional_y_word, x_conditional_y_cap\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict_NB(Xword, Xcap, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, Y)\n",
    "    local n = Xword:size(1)\n",
    "    local window_size = Xword:size(2)\n",
    "    -- Building the conditional p(y|x)\n",
    "    local y_conditional_x = torch.ones(n, nclasses)\n",
    "    local x_word = torch.DoubleTensor(window_size)\n",
    "    local x_cap = torch.DoubleTensor(window_size)\n",
    "    for i = 1, n do\n",
    "        x_word:copy(Xword[i])\n",
    "        x_cap:copy(Xcap[i])\n",
    "        for j=1, window_size do\n",
    "            y_conditional_x[i]:cmul(x_conditional_y_word:narrow(1, x_word[j], 1))\n",
    "            y_conditional_x[i]:cmul(x_conditional_y_cap:narrow(1, x_cap[j], 1))\n",
    "        end\n",
    "        -- Multiplying with the prior\n",
    "        y_conditional_x[i]:cmul(prior)\n",
    "    end\n",
    "    -- Predicting\n",
    "    max, Ypred = y_conditional_x:max(2)\n",
    "    -- Computing accuracy if Y provided\n",
    "    if Y then\n",
    "        right = 0\n",
    "        for i = 1, n do\n",
    "            if Y[i] == Ypred[i][1] then\n",
    "                right = right + 1\n",
    "            end\n",
    "        end\n",
    "        accuracy = right / n\n",
    "        print(\"Accuracy: \" .. accuracy)\n",
    "        return Ypred, accuracy\n",
    "    else\n",
    "        return Ypred\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.37055615088105\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.3549556931294\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Script to train and test the NB\n",
    "alpha = 1.\n",
    "prior, x_conditional_y_word, x_conditional_y_cap = NaiveBayes(train_input_word_windows, train_input_cap_windows, train_output, nwords, ncap, nclasses, alpha)\n",
    "Ypred_train, accuracy_train = predict_NB(train_input_word_windows, train_input_cap_windows, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, train_output)\n",
    "Ypred_validate, accuracy_validate = predict_NB(valid_input_word_windows, valid_input_cap_windows, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, valid_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- We add to the features here the position of the type feature in the window\n",
    "train_word = myFile:read('train_input_word_windows'):all()\n",
    "train_cap = myFile:read('train_input_cap_windows'):all()\n",
    "valid_word = myFile:read('valid_input_word_windows'):all()\n",
    "valid_cap = myFile:read('valid_input_cap_windows'):all()\n",
    "test_word = myFile:read('test_input_word_windows'):all()\n",
    "test_cap = myFile:read('test_input_cap_windows'):all()\n",
    "\n",
    "for j = 1, 5 do\n",
    "    train_word:narrow(2,j,1):add((j-1)*100002)\n",
    "    valid_word:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    train_cap:narrow(2,j,1):add((j-1)*4)\n",
    "    valid_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    test_word:narrow(2,j,1):add((j-1)*4)\n",
    "    test_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end\n",
    "\n",
    "nwords_bis = nwords * 5\n",
    "ncap_bis = 4 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.90317925725293\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.885302864773\t\n",
       "Time elapsed for NB 77.999620914459 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Script to train and test the NB\n",
    "alpha = 1.\n",
    "\n",
    "timer = torch.Timer()\n",
    "\n",
    "prior, x_conditional_y_word, x_conditional_y_cap = NaiveBayes(train_word, train_cap, train_output, nwords_bis, ncap_bis, nclasses, alpha)\n",
    "Ypred_train, accuracy_train = predict_NB(train_word, train_cap, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, train_output)\n",
    "Ypred_validate, accuracy_validate = predict_NB(valid_word, valid_cap, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, valid_output)\n",
    "\n",
    "print('Time elapsed for NB ' .. timer:time().real .. ' seconds',\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Parameter\n",
    "alphas = torch.DoubleTensor({0, 0.5, 0.75, 1., 1.25, 1.5, 1.75, 2, 2.5, 3.})\n",
    "num_parameters2 = alphas:size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- We add to the features here the position of the type feature in the window\n",
    "train_word = myFile:read('train_input_word_windows'):all()\n",
    "train_cap = myFile:read('train_input_cap_windows'):all()\n",
    "valid_word = myFile:read('valid_input_word_windows'):all()\n",
    "valid_cap = myFile:read('valid_input_cap_windows'):all()\n",
    "test_word = myFile:read('test_input_word_windows'):all()\n",
    "test_cap = myFile:read('test_input_cap_windows'):all()\n",
    "\n",
    "for j = 1, 5 do\n",
    "    train_word:narrow(2,j,1):add((j-1)*100002)\n",
    "    valid_word:narrow(2,j,1):add((j-1)*100002)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    train_cap:narrow(2,j,1):add((j-1)*4)\n",
    "    valid_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end\n",
    "for j = 1, 5 do\n",
    "    test_word:narrow(2,j,1):add((j-1)*4)\n",
    "    test_cap:narrow(2,j,1):add((j-1)*4)\n",
    "end\n",
    "\n",
    "nwords_bis = nwords * 5\n",
    "ncap_bis = 4 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Metric storage\n",
    "\n",
    "-- Initialization\n",
    "training_accuracy2 = torch.zeros(num_parameters2)\n",
    "valid_accuracy2 = torch.zeros(num_parameters2)\n",
    "training_time2 = torch.zeros(num_parameters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 35.085270881653 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.97311502784151\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.73702658412236\t\n",
       "Time elapsed for predicting NB 35.085270881653 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 30.807815074921 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.92764932625955\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.90605274338432\t\n",
       "Time elapsed for predicting NB 30.807815074921 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 31.384006977081 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.91439255981925\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.89506706724933\t\n",
       "Time elapsed for predicting NB 31.384006977081 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 30.411576986313 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.90317925725293\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.885302864773\t\n",
       "Time elapsed for predicting NB 30.411576986313 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 27.528131961823 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.89341774537454\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.8763201019665\t\n",
       "Time elapsed for predicting NB 27.528131961823 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 27.064613103867 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.88469056588062\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.86874848264142\t\n",
       "Time elapsed for predicting NB 27.064613103867 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 27.263186216354 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.87708975682232\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.86172311240592\t\n",
       "Time elapsed for predicting NB 27.263186216354 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 26.814904928207 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.87047178266748\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.85619992716679\t\n",
       "Time elapsed for predicting NB 26.814904928207 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 27.608752012253 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.85880376830078\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.84595775673707\t\n",
       "Time elapsed for predicting NB 27.608752012253 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Time elapsed for training NB 26.461882829666 seconds\t\n",
       "\t"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.84907293577278\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.83739985433358\t\n",
       "Time elapsed for predicting NB 26.461882829666 seconds\t\n",
       "\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Script to tune the hyperparameter alpha\n",
    "for i=1, num_parameters2 do\n",
    "    alpha = alphas[i]\n",
    "    timer = torch.Timer()\n",
    "\n",
    "    prior, x_conditional_y_word, x_conditional_y_cap = NaiveBayes(train_word, train_cap, train_output, nwords_bis, ncap_bis, nclasses, alpha)\n",
    "    training_time2[i] = timer:time().real\n",
    "    timer2 = torch.Timer()\n",
    "    print('Time elapsed for training NB ' .. training_time2[i] .. ' seconds',\"\\n\")\n",
    "    Ypred_train, training_accuracy2[i] = predict_NB(train_word, train_cap, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, train_output)\n",
    "    Ypred_validate, valid_accuracy2[i] = predict_NB(valid_word, valid_cap, prior, x_conditional_y_word, x_conditional_y_cap, nclasses, valid_output)\n",
    "    print('Time elapsed for predicting NB ' .. training_time2[i] .. ' seconds',\"\\n\")\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Saving (rewriting the files with update at each iteration)\n",
    "filename = '../data/nb_hyperparameter.f5'\n",
    "myFile = hdf5.open(filename, 'w')\n",
    "myFile:write('valid_accuracy2', valid_accuracy2)\n",
    "myFile:write('training_accuracy2', training_accuracy2)\n",
    "myFile:write('training_time2', training_time2)\n",
    "myFile:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7370\n",
       " 0.9061\n",
       " 0.8951\n",
       " 0.8853\n",
       " 0.8763\n",
       " 0.8687\n",
       " 0.8617\n",
       " 0.8562\n",
       " 0.8460\n",
       " 0.8374\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
